<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.242">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jake Gehri">
<meta name="dcterms.date" content="2022-12-09">
<meta name="description" content="The first in a series of paper replications that will collectively lay the foundation for a full replication of the stable diffusion model from scratch.">

<title>Jake Gehri - Paper Replication: Vision Transformer</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jake Gehri</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Paper Replication: Vision Transformer</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Python</div>
    <div class="quarto-category">Deep Learning</div>
    <div class="quarto-category">Computer Vision</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>The first in a series of paper replications that will collectively lay the foundation for a full replication of the stable diffusion model from scratch.</p>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jake Gehri </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 9, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="311">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> ToTensor</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchmetrics <span class="im">import</span> Accuracy</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="252">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>train_split_len <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> torchvision.datasets.CIFAR10(root <span class="op">=</span> <span class="st">'data'</span>, train <span class="op">=</span> <span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform <span class="op">=</span> ToTensor())</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>part_train <span class="op">=</span> torch.utils.data.random_split(trainset, [train_split_len, <span class="bu">len</span>(trainset)<span class="op">-</span>train_split_len])[<span class="dv">0</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>trainloader <span class="op">=</span> DataLoader(part_train, batch_size<span class="op">=</span><span class="dv">25</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified</code></pre>
</div>
</div>
<div class="cell" data-execution_count="254">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>test_split_len <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>testset <span class="op">=</span> torchvision.datasets.CIFAR10(root <span class="op">=</span> <span class="st">'data'</span>, train <span class="op">=</span> <span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform <span class="op">=</span> ToTensor())</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>part_test <span class="op">=</span> torch.utils.data.random_split(testset, [test_split_len, <span class="bu">len</span>(testset)<span class="op">-</span>test_split_len])[<span class="dv">0</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>testloader <span class="op">=</span> DataLoader(part_test, batch_size<span class="op">=</span><span class="dv">25</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified</code></pre>
</div>
</div>
<div class="cell" data-execution_count="255">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> testset.class_to_idx</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>classes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="255">
<pre><code>{'airplane': 0,
 'automobile': 1,
 'bird': 2,
 'cat': 3,
 'deer': 4,
 'dog': 5,
 'frog': 6,
 'horse': 7,
 'ship': 8,
 'truck': 9}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="256">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>dataiter <span class="op">=</span> <span class="bu">iter</span>(trainloader)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>images, labels <span class="op">=</span> <span class="bu">next</span>(dataiter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="257">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>images.shape, labels.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="257">
<pre><code>(torch.Size([25, 3, 32, 32]), torch.Size([25]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="258">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(classes.keys()) [<span class="bu">list</span>(classes.values()).index(<span class="dv">1</span>)])</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(images[<span class="dv">1</span>].permute(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>).numpy())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>automobile</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="258">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f28e9e29700&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="vision-transformer_files/figure-html/cell-8-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="260">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinearProjectionBlock(nn.Module):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels <span class="op">=</span> <span class="dv">3</span>, patch_size <span class="op">=</span> <span class="dv">2</span>, embedding_dim <span class="op">=</span> <span class="dv">768</span>, batch_size<span class="op">=</span><span class="dv">25</span>, num_patches<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.patch <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span>in_channels, out_channels<span class="op">=</span>embedding_dim, kernel_size<span class="op">=</span>patch_size, stride<span class="op">=</span>patch_size)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten(start_dim<span class="op">=</span><span class="dv">2</span>, end_dim<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.class_token <span class="op">=</span> nn.Parameter(torch.rand(batch_size, <span class="dv">1</span>, embedding_dim), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positional <span class="op">=</span> nn.Parameter(torch.rand(batch_size, num_patches<span class="op">+</span><span class="dv">1</span>, embedding_dim), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.patch(x)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat((<span class="va">self</span>.class_token, x), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.positional <span class="op">+</span> x</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="261">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MSABlock(nn.Module):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embedding_dim <span class="op">=</span> <span class="dv">768</span>, num_heads<span class="op">=</span><span class="dv">12</span>):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.normalize <span class="op">=</span> nn.LayerNorm(normalized_shape<span class="op">=</span>embedding_dim)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.msa <span class="op">=</span> nn.MultiheadAttention(embed_dim<span class="op">=</span>embedding_dim, num_heads <span class="op">=</span> num_heads, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.normalize(x)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        x, _ <span class="op">=</span> <span class="va">self</span>.msa(query<span class="op">=</span>x, key<span class="op">=</span>x, value<span class="op">=</span>x, need_weights<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="262">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>lin_projs <span class="op">=</span> LinearProjectionBlock(in_channels<span class="op">=</span><span class="dv">3</span>, patch_size<span class="op">=</span><span class="dv">2</span>, embedding_dim<span class="op">=</span><span class="dv">768</span>, batch_size<span class="op">=</span><span class="dv">25</span>, num_patches<span class="op">=</span><span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="263">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>projs <span class="op">=</span> lin_projs(images)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="264">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>projs.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="264">
<pre><code>torch.Size([25, 257, 768])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="265">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>msa_block <span class="op">=</span> MSABlock(embedding_dim<span class="op">=</span><span class="dv">768</span>, num_heads<span class="op">=</span><span class="dv">12</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="266">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> msa_block(projs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="267">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>out.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="267">
<pre><code>torch.Size([25, 257, 768])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="268">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLPBlock(nn.Module):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embedding_dim <span class="op">=</span> <span class="dv">768</span>, mlp_size <span class="op">=</span> <span class="dv">3072</span>):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.normalize <span class="op">=</span> nn.LayerNorm(embedding_dim)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> nn.Sequential(</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span>embedding_dim, out_features<span class="op">=</span>mlp_size),</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.1</span>),</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span>mlp_size, out_features<span class="op">=</span>embedding_dim),</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.1</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.normalize(x)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mlp(x)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="269">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TrasformerEncoderBlock(nn.Module):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embedding_dim <span class="op">=</span> <span class="dv">768</span>, num_heads<span class="op">=</span><span class="dv">12</span>, mlp_size<span class="op">=</span><span class="dv">3072</span>):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.msa_block <span class="op">=</span> MSABlock(embedding_dim <span class="op">=</span> embedding_dim, num_heads<span class="op">=</span>num_heads)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp_block <span class="op">=</span> MLPBlock(embedding_dim <span class="op">=</span> embedding_dim, mlp_size <span class="op">=</span> mlp_size)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.msa_block(x)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mlp_block(x)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="270">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>mlp <span class="op">=</span> MLPBlock(embedding_dim<span class="op">=</span><span class="dv">768</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="271">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>fout <span class="op">=</span> mlp(out)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="317">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ViT(nn.Module):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, img_size <span class="op">=</span> <span class="dv">32</span>, in_channels <span class="op">=</span> <span class="dv">3</span>, patch_size <span class="op">=</span> <span class="dv">2</span>, embedding_dim <span class="op">=</span> <span class="dv">768</span>, </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>                 batch_size<span class="op">=</span><span class="dv">25</span>, num_patches<span class="op">=</span><span class="dv">256</span>, mlp_size <span class="op">=</span> <span class="dv">3072</span>, layers <span class="op">=</span> <span class="dv">12</span>, num_heads<span class="op">=</span><span class="dv">12</span>, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.projections <span class="op">=</span> LinearProjectionBlock(in_channels<span class="op">=</span>in_channels, patch_size<span class="op">=</span>patch_size, embedding_dim<span class="op">=</span>embedding_dim, batch_size<span class="op">=</span>batch_size, num_patches<span class="op">=</span>num_patches)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transformer_encoder <span class="op">=</span> nn.TransformerEncoderLayer(d_model<span class="op">=</span>embedding_dim, </span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>                                                             nhead<span class="op">=</span>num_heads, </span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>                                                             dim_feedforward<span class="op">=</span>mlp_size, </span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>                                                             dropout<span class="op">=</span><span class="fl">0.1</span>, </span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>                                                             activation<span class="op">=</span><span class="st">"gelu"</span>, </span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>                                                             batch_first<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>                                                             norm_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder_layer <span class="op">=</span> nn.TransformerEncoder(<span class="va">self</span>.transformer_encoder, num_layers<span class="op">=</span>layers)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(normalized_shape<span class="op">=</span>embedding_dim),</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span>embedding_dim, out_features<span class="op">=</span>num_classes)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, layers<span class="op">=</span><span class="dv">12</span>):</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.projections(x)</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.encoder_layer(x)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.classifier(x[:, <span class="dv">0</span>])</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="318">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>vit <span class="op">=</span> ViT(in_channels <span class="op">=</span> <span class="dv">3</span>, patch_size <span class="op">=</span> <span class="dv">4</span>, embedding_dim <span class="op">=</span> <span class="dv">768</span>, batch_size<span class="op">=</span><span class="dv">25</span>, num_patches<span class="op">=</span><span class="dv">64</span>, mlp_size <span class="op">=</span> <span class="dv">2048</span>).to(<span class="st">'cuda'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="319">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>summary(vit, input_size<span class="op">=</span>(<span class="dv">25</span>, <span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>),col_names<span class="op">=</span>[<span class="st">"input_size"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="319">
<pre><code>======================================================================
Layer (type:depth-idx)                        Input Shape
======================================================================
ViT                                           [25, 3, 32, 32]
├─LinearProjectionBlock: 1-1                  [25, 3, 32, 32]
│    └─Conv2d: 2-1                            [25, 3, 32, 32]
│    └─Flatten: 2-2                           [25, 768, 8, 8]
├─TransformerEncoder: 1-2                     [25, 65, 768]
│    └─ModuleList: 2-3                        --
│    │    └─TransformerEncoderLayer: 3-1      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-2      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-3      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-4      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-5      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-6      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-7      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-8      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-9      [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-10     [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-11     [25, 65, 768]
│    │    └─TransformerEncoderLayer: 3-12     [25, 65, 768]
├─Sequential: 1-3                             [25, 768]
│    └─LayerNorm: 2-4                         [25, 768]
│    └─Linear: 2-5                            [25, 768]
======================================================================
Total params: 72,995,850
Trainable params: 72,995,850
Non-trainable params: 0
Total mult-adds (G): 1.01
======================================================================
Input size (MB): 0.31
Forward/backward pass size (MB): 688.90
Params size (MB): 151.47
Estimated Total Size (MB): 840.67
======================================================================</code></pre>
</div>
</div>
<div class="cell" data-execution_count="320">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>test_output <span class="op">=</span> vit(images.to(<span class="st">'cuda'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="321">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>test_output.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="321">
<pre><code>torch.Size([25, 10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="322">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>torch.argmax(test_output[<span class="dv">1</span>]), labels[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="322">
<pre><code>(tensor(0, device='cuda:0'), tensor(9))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="323">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(vit.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>, betas<span class="op">=</span>(<span class="fl">0.9</span>, <span class="fl">0.999</span>), weight_decay<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> Accuracy(task<span class="op">=</span><span class="st">"multiclass"</span>, num_classes<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="324">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_step(model, dataloader, loss_fn, optimizer):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    train_loss, train_acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch, (X, y) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>        X, y <span class="op">=</span> X.to(<span class="st">'cuda'</span>), y.to(<span class="st">'cuda'</span>)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(y_pred, y)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss.item() </span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>        y_pred_class <span class="op">=</span> torch.argmax(torch.softmax(y_pred, dim<span class="op">=</span><span class="dv">1</span>), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>        train_acc <span class="op">+=</span> (y_pred_class <span class="op">==</span> y).<span class="bu">sum</span>().item()<span class="op">/</span><span class="bu">len</span>(y_pred)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> train_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>    train_acc <span class="op">=</span> train_acc <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loss, train_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="325">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_step(model, dataloader, loss_fn):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>() </span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    test_loss, test_acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.inference_mode():</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch, (X, y) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>            X, y <span class="op">=</span> X.to(<span class="st">'cuda'</span>), y.to(<span class="st">'cuda'</span>)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>            test_pred_logits <span class="op">=</span> model(X)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(test_pred_logits, y)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss.item()</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>            test_pred_labels <span class="op">=</span> test_pred_logits.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>            test_acc <span class="op">+=</span> ((test_pred_labels <span class="op">==</span> y).<span class="bu">sum</span>().item()<span class="op">/</span><span class="bu">len</span>(test_pred_labels))</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">=</span> test_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    test_acc <span class="op">=</span> test_acc <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> test_loss, test_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model,train_dataloader,test_dataloader, optimizer, loss_fn, epochs <span class="op">=</span> <span class="dv">50</span>):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {<span class="st">"train_loss"</span>: [],</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_acc"</span>: [],</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"test_loss"</span>: [],</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"test_acc"</span>: []</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>        train_loss, train_acc <span class="op">=</span> train_step(model<span class="op">=</span>model,</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>                                           dataloader<span class="op">=</span>train_dataloader,</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>                                           loss_fn<span class="op">=</span>loss_fn,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>                                           optimizer<span class="op">=</span>optimizer)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>        test_loss, test_acc <span class="op">=</span> test_step(model<span class="op">=</span>model,</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>            dataloader<span class="op">=</span>test_dataloader,</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>            loss_fn<span class="op">=</span>loss_fn)</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> | "</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"train_loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss"> | "</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"train_acc: </span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss"> | "</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"test_loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss"> | "</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"test_acc: </span><span class="sc">{</span>test_acc<span class="sc">:.4f}</span><span class="ss">"</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">"train_loss"</span>].append(train_loss)</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">"train_acc"</span>].append(train_acc)</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">"test_loss"</span>].append(test_loss)</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">"test_acc"</span>].append(test_acc)</span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="328">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> train(model<span class="op">=</span>vit, train_dataloader<span class="op">=</span>trainloader, test_dataloader<span class="op">=</span>testloader, optimizer<span class="op">=</span>optimizer, loss_fn<span class="op">=</span>loss_fn, epochs<span class="op">=</span><span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ab2d364746904daeb339ce6afa71ddf7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 1 | train_loss: 2.3983 | train_acc: 0.1070 | test_loss: 2.3546 | test_acc: 0.0750
Epoch: 2 | train_loss: 2.4793 | train_acc: 0.1120 | test_loss: 2.4665 | test_acc: 0.1100
Epoch: 3 | train_loss: 2.4430 | train_acc: 0.1060 | test_loss: 2.3757 | test_acc: 0.0900
Epoch: 4 | train_loss: 2.3699 | train_acc: 0.1010 | test_loss: 2.3697 | test_acc: 0.1050
Epoch: 5 | train_loss: 2.3734 | train_acc: 0.1100 | test_loss: 2.3556 | test_acc: 0.1450
Epoch: 6 | train_loss: 2.3820 | train_acc: 0.0850 | test_loss: 2.3614 | test_acc: 0.0800
Epoch: 7 | train_loss: 2.3696 | train_acc: 0.0810 | test_loss: 2.3599 | test_acc: 0.1000
Epoch: 8 | train_loss: 2.3491 | train_acc: 0.0960 | test_loss: 2.3836 | test_acc: 0.1200
Epoch: 9 | train_loss: 2.3625 | train_acc: 0.1030 | test_loss: 2.3677 | test_acc: 0.0500
Epoch: 10 | train_loss: 2.3425 | train_acc: 0.1120 | test_loss: 2.3327 | test_acc: 0.1100
Epoch: 11 | train_loss: 2.3501 | train_acc: 0.1020 | test_loss: 2.3617 | test_acc: 0.1050
Epoch: 12 | train_loss: 2.3455 | train_acc: 0.0840 | test_loss: 2.3424 | test_acc: 0.0800
Epoch: 13 | train_loss: 2.3293 | train_acc: 0.1050 | test_loss: 2.3220 | test_acc: 0.1400
Epoch: 14 | train_loss: 2.3237 | train_acc: 0.0930 | test_loss: 2.3216 | test_acc: 0.1150
Epoch: 15 | train_loss: 2.3416 | train_acc: 0.0970 | test_loss: 2.3089 | test_acc: 0.1350
Epoch: 16 | train_loss: 2.3387 | train_acc: 0.0750 | test_loss: 2.3197 | test_acc: 0.0900
Epoch: 17 | train_loss: 2.3219 | train_acc: 0.0990 | test_loss: 2.3107 | test_acc: 0.0900
Epoch: 18 | train_loss: 2.3260 | train_acc: 0.1070 | test_loss: 2.3100 | test_acc: 0.1100
Epoch: 19 | train_loss: 2.3187 | train_acc: 0.1010 | test_loss: 2.3043 | test_acc: 0.1000
Epoch: 20 | train_loss: 2.3256 | train_acc: 0.1060 | test_loss: 2.3108 | test_acc: 0.1300
Epoch: 21 | train_loss: 2.3152 | train_acc: 0.1050 | test_loss: 2.3279 | test_acc: 0.1150
Epoch: 22 | train_loss: 2.3160 | train_acc: 0.1070 | test_loss: 2.3138 | test_acc: 0.1100
Epoch: 23 | train_loss: 2.3145 | train_acc: 0.1120 | test_loss: 2.3058 | test_acc: 0.0800
Epoch: 24 | train_loss: 2.3119 | train_acc: 0.0900 | test_loss: 2.3030 | test_acc: 0.1450
Epoch: 25 | train_loss: 2.3168 | train_acc: 0.0940 | test_loss: 2.3119 | test_acc: 0.0950
Epoch: 26 | train_loss: 2.3111 | train_acc: 0.0950 | test_loss: 2.3132 | test_acc: 0.0650
Epoch: 27 | train_loss: 2.3035 | train_acc: 0.1120 | test_loss: 2.3098 | test_acc: 0.0700
Epoch: 28 | train_loss: 2.3060 | train_acc: 0.1150 | test_loss: 2.3021 | test_acc: 0.1250
Epoch: 29 | train_loss: 2.3059 | train_acc: 0.1050 | test_loss: 2.3005 | test_acc: 0.0950
Epoch: 30 | train_loss: 2.3072 | train_acc: 0.1010 | test_loss: 2.3023 | test_acc: 0.0800
Epoch: 31 | train_loss: 2.3089 | train_acc: 0.0980 | test_loss: 2.3047 | test_acc: 0.0950
Epoch: 32 | train_loss: 2.3053 | train_acc: 0.1050 | test_loss: 2.3046 | test_acc: 0.0850
Epoch: 33 | train_loss: 2.3035 | train_acc: 0.1070 | test_loss: 2.3072 | test_acc: 0.0600
Epoch: 34 | train_loss: 2.3030 | train_acc: 0.1120 | test_loss: 2.3081 | test_acc: 0.1000
Epoch: 35 | train_loss: 2.3018 | train_acc: 0.1110 | test_loss: 2.2997 | test_acc: 0.1250
Epoch: 36 | train_loss: 2.3030 | train_acc: 0.1090 | test_loss: 2.3014 | test_acc: 0.1000
Epoch: 37 | train_loss: 2.3032 | train_acc: 0.0990 | test_loss: 2.2988 | test_acc: 0.1000
Epoch: 38 | train_loss: 2.3023 | train_acc: 0.1120 | test_loss: 2.3021 | test_acc: 0.1000
Epoch: 39 | train_loss: 2.3024 | train_acc: 0.1140 | test_loss: 2.3017 | test_acc: 0.1000
Epoch: 40 | train_loss: 2.3012 | train_acc: 0.1140 | test_loss: 2.3006 | test_acc: 0.1000
Epoch: 41 | train_loss: 2.3017 | train_acc: 0.1170 | test_loss: 2.3014 | test_acc: 0.1000
Epoch: 42 | train_loss: 2.3007 | train_acc: 0.1140 | test_loss: 2.3011 | test_acc: 0.1000
Epoch: 43 | train_loss: 2.3022 | train_acc: 0.1110 | test_loss: 2.3002 | test_acc: 0.1000
Epoch: 44 | train_loss: 2.3013 | train_acc: 0.1140 | test_loss: 2.3010 | test_acc: 0.1000
Epoch: 45 | train_loss: 2.3013 | train_acc: 0.1140 | test_loss: 2.3011 | test_acc: 0.1000
Epoch: 46 | train_loss: 2.3014 | train_acc: 0.1140 | test_loss: 2.3008 | test_acc: 0.1000
Epoch: 47 | train_loss: 2.3011 | train_acc: 0.1140 | test_loss: 2.3010 | test_acc: 0.1000
Epoch: 48 | train_loss: 2.3013 | train_acc: 0.1140 | test_loss: 2.3011 | test_acc: 0.1000
Epoch: 49 | train_loss: 2.3013 | train_acc: 0.1140 | test_loss: 2.3012 | test_acc: 0.1000
Epoch: 50 | train_loss: 2.3009 | train_acc: 0.1140 | test_loss: 2.3014 | test_acc: 0.1000</code></pre>
</div>
</div>
<div class="cell" data-execution_count="329">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>plt.plot(results[<span class="st">'train_loss'</span>])</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>plt.plot(results[<span class="st">'test_loss'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vision-transformer_files/figure-html/cell-32-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="330">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>plt.plot(results[<span class="st">'train_acc'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vision-transformer_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>