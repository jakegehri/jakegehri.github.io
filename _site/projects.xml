<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Jake Gehri</title>
<link>https://jakegehri.github.io/projects.html</link>
<atom:link href="https://jakegehri.github.io/projects.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.2.242</generator>
<lastBuildDate>Tue, 06 Dec 2022 05:00:00 GMT</lastBuildDate>
<item>
  <title>Stable Diffusion From Scratch</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/Stable Diffusion/stable-diffusion-from-scratch.html</link>
  <description><![CDATA[ 



<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-tags="[]" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span> pip install diffusers</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: diffusers in /usr/local/lib/python3.9/dist-packages (0.9.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers) (4.12.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from diffusers) (3.7.1)
Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from diffusers) (2.28.1)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from diffusers) (2022.7.9)
Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from diffusers) (9.2.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from diffusers) (1.23.1)
Requirement already satisfied: huggingface-hub&gt;=0.10.0 in /usr/local/lib/python3.9/dist-packages (from diffusers) (0.11.1)
Requirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub&gt;=0.10.0-&gt;diffusers) (21.3)
Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from huggingface-hub&gt;=0.10.0-&gt;diffusers) (4.64.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub&gt;=0.10.0-&gt;diffusers) (4.3.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub&gt;=0.10.0-&gt;diffusers) (5.4.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata-&gt;diffusers) (3.8.1)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests-&gt;diffusers) (1.26.10)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/lib/python3/dist-packages (from requests-&gt;diffusers) (2.8)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/lib/python3/dist-packages (from requests-&gt;diffusers) (2019.11.28)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/lib/python3.9/dist-packages (from requests-&gt;diffusers) (2.1.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging&gt;=20.9-&gt;huggingface-hub&gt;=0.10.0-&gt;diffusers) (3.0.9)
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</code></pre>
</div>
</div>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;">from</span> huggingface_hub <span class="im" style="color: #00769E;">import</span> notebook_login</span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> CLIPTokenizer, CLIPTextModel</span>
<span id="cb3-3"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> AutoencoderKL, UNet2DConditionModel</span>
<span id="cb3-4"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> LMSDiscreteScheduler</span>
<span id="cb3-5"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb3-6"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb3-7"><span class="im" style="color: #00769E;">from</span> tqdm.auto <span class="im" style="color: #00769E;">import</span> tqdm</span>
<span id="cb3-8"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">notebook_login()</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3782af2798bc4cf2812b917c15d15c50","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">clip_model_cp <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'openai/clip-vit-large-patch14'</span></span>
<span id="cb5-2">vae_cp <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'stabilityai/sd-vae-ft-ema'</span></span>
<span id="cb5-3">unet_cp <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'CompVis/stable-diffusion-v1-4'</span></span>
<span id="cb5-4">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">'cpu'</span></span>
<span id="cb5-5">beta_start, beta_end <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.00085</span>, <span class="fl" style="color: #AD0000;">0.012</span></span></code></pre></div>
</div>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-tags="[]" data-execution_count="65">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">tokenizer <span class="op" style="color: #5E5E5E;">=</span> CLIPTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"openai/clip-vit-large-patch14"</span>)</span>
<span id="cb6-2">text_encoder <span class="op" style="color: #5E5E5E;">=</span> CLIPTextModel.from_pretrained(<span class="st" style="color: #20794D;">"openai/clip-vit-large-patch14"</span>).to(device)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.
Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'text_projection.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'logit_scale', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight']
- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</code></pre>
</div>
</div>
<div class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-tags="[]" data-execution_count="70">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">vae <span class="op" style="color: #5E5E5E;">=</span> AutoencoderKL.from_pretrained(vae_cp).to(device)</span>
<span id="cb8-2">unet <span class="op" style="color: #5E5E5E;">=</span> UNet2DConditionModel.from_pretrained(unet_cp, subfolder <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'unet'</span>).to(device)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: </code></pre>
<p>pip install accelerate</p>
<pre><code>.
Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: </code></pre>
<p>pip install accelerate</p>
<pre><code>.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">scheduler <span class="op" style="color: #5E5E5E;">=</span> LMSDiscreteScheduler(beta_start<span class="op" style="color: #5E5E5E;">=</span>beta_start, beta_end<span class="op" style="color: #5E5E5E;">=</span>beta_end, beta_schedule<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'scaled_linear'</span>, num_train_timesteps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1000</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="266">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">prompt <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'a painting of George Washington and Steve Jobs'</span>]</span>
<span id="cb13-2"></span>
<span id="cb13-3">height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span></span>
<span id="cb13-4">width <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span></span>
<span id="cb13-5">num_inference_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb13-6">guidence_scale <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb13-7">batch_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="267">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">text_input <span class="op" style="color: #5E5E5E;">=</span> tokenizer(prompt, padding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"max_length"</span>, max_length<span class="op" style="color: #5E5E5E;">=</span>tokenizer.model_max_length, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>)</span>
<span id="cb14-2">text_input[<span class="st" style="color: #20794D;">'input_ids'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="267">
<pre><code>tensor([[49406,   320,  3086,   539,  3296,  4365,   537,  3803,  3735, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="268">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">text_input[<span class="st" style="color: #20794D;">'attention_mask'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="268">
<pre><code>tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="269">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">tokenizer.decode(text_input[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="269">
<pre><code>'&lt;|startoftext|&gt;a painting of george washington and steve jobs &lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="270">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">text_embeddings <span class="op" style="color: #5E5E5E;">=</span> text_encoder(text_input.input_ids.to(device))[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb20-2">text_embeddings.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="270">
<pre><code>torch.Size([1, 77, 768])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="271">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">max_length <span class="op" style="color: #5E5E5E;">=</span> text_input.input_ids.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb22-2">uncond_input <span class="op" style="color: #5E5E5E;">=</span> tokenizer([<span class="st" style="color: #20794D;">""</span>]<span class="op" style="color: #5E5E5E;">*</span>batch_size, padding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'max_length'</span>, max_length<span class="op" style="color: #5E5E5E;">=</span>max_length, return_tensors <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'pt'</span>)</span>
<span id="cb22-3">uncond_embeddings <span class="op" style="color: #5E5E5E;">=</span> text_encoder(uncond_input.input_ids.to(device))[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb22-4">uncond_embeddings.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="271">
<pre><code>torch.Size([1, 77, 768])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="272">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">embeddings <span class="op" style="color: #5E5E5E;">=</span> torch.cat([uncond_embeddings, text_embeddings])</span>
<span id="cb24-2">embeddings.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="272">
<pre><code>torch.Size([2, 77, 768])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="273">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">latents <span class="op" style="color: #5E5E5E;">=</span> torch.randn((batch_size, unet.in_channels, height<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">8</span>, width<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">8</span>)).to(device)</span>
<span id="cb26-2">latents.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="273">
<pre><code>torch.Size([1, 4, 64, 64])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="274">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">scheduler.set_timesteps(num_inference_steps)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="275">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">latents <span class="op" style="color: #5E5E5E;">=</span> latents <span class="op" style="color: #5E5E5E;">*</span> scheduler.init_noise_sigma</span></code></pre></div>
</div>
<div class="cell" data-execution_count="276">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">scheduler.timesteps</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="276">
<pre><code>tensor([999.0000, 978.6122, 958.2245, 937.8367, 917.4490, 897.0612, 876.6735,
        856.2857, 835.8980, 815.5102, 795.1224, 774.7347, 754.3469, 733.9592,
        713.5714, 693.1837, 672.7959, 652.4082, 632.0204, 611.6327, 591.2449,
        570.8571, 550.4694, 530.0816, 509.6939, 489.3061, 468.9184, 448.5306,
        428.1429, 407.7551, 387.3673, 366.9796, 346.5918, 326.2041, 305.8163,
        285.4286, 265.0408, 244.6531, 224.2653, 203.8776, 183.4898, 163.1020,
        142.7143, 122.3265, 101.9388,  81.5510,  61.1633,  40.7755,  20.3878,
          0.0000], dtype=torch.float64)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="277">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">scheduler.sigmas</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="277">
<pre><code>tensor([14.6146, 12.9368, 11.4916, 10.2429,  9.1604,  8.2187,  7.3972,  6.6780,
         6.0465,  5.4903,  4.9989,  4.5633,  4.1761,  3.8308,  3.5221,  3.2451,
         2.9958,  2.7709,  2.5673,  2.3825,  2.2143,  2.0606,  1.9199,  1.7907,
         1.6716,  1.5617,  1.4598,  1.3651,  1.2768,  1.1944,  1.1171,  1.0444,
         0.9759,  0.9112,  0.8497,  0.7913,  0.7355,  0.6820,  0.6306,  0.5809,
         0.5328,  0.4858,  0.4397,  0.3940,  0.3483,  0.3019,  0.2535,  0.2012,
         0.1393,  0.0292,  0.0000])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="278">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="cf" style="color: #003B4F;">for</span> i, t <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(tqdm(scheduler.timesteps)):</span>
<span id="cb34-2">    inp <span class="op" style="color: #5E5E5E;">=</span> torch.cat([latents] <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb34-3">    inp <span class="op" style="color: #5E5E5E;">=</span> scheduler.scale_model_input(inp, t)</span>
<span id="cb34-4">    </span>
<span id="cb34-5">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb34-6">        pred <span class="op" style="color: #5E5E5E;">=</span> unet(inp, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;">=</span>embeddings).sample</span>
<span id="cb34-7">        </span>
<span id="cb34-8">    pred_uncond, pred_text <span class="op" style="color: #5E5E5E;">=</span> pred.chunk(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb34-9">    pred <span class="op" style="color: #5E5E5E;">=</span> pred_uncond <span class="op" style="color: #5E5E5E;">+</span> guidence_scale <span class="op" style="color: #5E5E5E;">*</span> (pred_text <span class="op" style="color: #5E5E5E;">-</span> pred_uncond)</span>
<span id="cb34-10">    </span>
<span id="cb34-11">    latents <span class="op" style="color: #5E5E5E;">=</span> scheduler.step(pred, t, latents).prev_sample</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"48074d183c864dfa83f7bf1d725e06f1","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution_count="279">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">plt.imshow(pred.squeeze(<span class="dv" style="color: #AD0000;">0</span>).permute(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">0</span>).cpu().numpy())</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="279">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f825e0d4b20&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Stable Diffusion/stable-diffusion-from-scratch_files/figure-html/cell-22-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="280">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">plt.imshow(latents.squeeze(<span class="dv" style="color: #AD0000;">0</span>).permute(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">0</span>).cpu().numpy())</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="280">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f825e046a90&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Stable Diffusion/stable-diffusion-from-scratch_files/figure-html/cell-23-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="281">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb41-2">    image <span class="op" style="color: #5E5E5E;">=</span> vae.decode(<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="fl" style="color: #AD0000;">0.18215</span> <span class="op" style="color: #5E5E5E;">*</span> latents).sample</span></code></pre></div>
</div>
<div class="cell" data-execution_count="282">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">image <span class="op" style="color: #5E5E5E;">=</span> (image <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="fl" style="color: #AD0000;">0.5</span>).clamp(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb42-2">image <span class="op" style="color: #5E5E5E;">=</span> image[<span class="dv" style="color: #AD0000;">0</span>].detach().cpu().permute(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>).numpy()</span>
<span id="cb42-3">image <span class="op" style="color: #5E5E5E;">=</span> (image <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">255</span>).<span class="bu" style="color: null;">round</span>().astype(<span class="st" style="color: #20794D;">'uint8'</span>)</span>
<span id="cb42-4">Image.fromarray(image)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="282">
<p><img src="https://jakegehri.github.io/projects/Stable Diffusion/stable-diffusion-from-scratch_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>



 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <guid>https://jakegehri.github.io/projects/Stable Diffusion/stable-diffusion-from-scratch.html</guid>
  <pubDate>Tue, 06 Dec 2022 05:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/Stable Diffusion/GW_SJ.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Syllogism Conclusion Generator with GPT-2</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/Syllogism Finisher/conclusion_writer.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset, Dataset</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> GPT2Tokenizer, GPT2LMHeadModel</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> TrainingArguments, Trainer, DataCollatorForLanguageModeling</span></code></pre></div>
</div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook will be an extension of the last notebook that was working to classify whether two premises could be used to generate a valid conclusion. That model used the a BERT architecture and was fine-tuned on the Avicenna syllogism dataset. This notebook will use the same dataset, but instead fine-tune a GPT-2 model to take in two premises as input and generate the corresponding conclusion.</p>
<p>I had to write custome start, end and pad tokens in order to properly pad each input as to be forced to randomly chop up syllogisms into pieced and create input blocks of equal size.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">'cpu'</span></span>
<span id="cb2-2">file_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Avicenna_Train.csv'</span></span>
<span id="cb2-3">model_cp <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"gpt2"</span></span>
<span id="cb2-4">max_length <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">200</span></span>
<span id="cb2-5">tokenizer <span class="op" style="color: #5E5E5E;">=</span> GPT2Tokenizer.from_pretrained(model_cp, bos_token <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'&lt;startoftext&gt;'</span>, </span>
<span id="cb2-6">                                          eos_token<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'&lt;endoftext&gt;'</span>, pad_token<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'&lt;pad&gt;'</span>)</span>
<span id="cb2-7">data_collator <span class="op" style="color: #5E5E5E;">=</span> DataCollatorForLanguageModeling(tokenizer, mlm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pt'</span>)</span>
<span id="cb2-8">model <span class="op" style="color: #5E5E5E;">=</span> GPT2LMHeadModel.from_pretrained(model_cp).to(device)</span>
<span id="cb2-9">model.resize_token_embeddings(<span class="bu" style="color: null;">len</span>(tokenizer))</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"255d8effb8d945c6965a214a72620efe","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8b689146ce2e43259e7f8816ebfb6af9","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"be4cab5f774a457d8608823a23001366","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"16b103ab121e4abbb48c049bbd66a6db","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>Embedding(50260, 768)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">def</span> tokenize(batch):</span>
<span id="cb5-2">    <span class="cf" style="color: #003B4F;">return</span> tokenizer(batch[<span class="st" style="color: #20794D;">'text'</span>], truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, max_length<span class="op" style="color: #5E5E5E;">=</span>max_length, padding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'max_length'</span>)</span></code></pre></div>
</div>
<p>The data came in a csv file containing premise 1, premise 2, validity and conclusion. I needed to filter the dataset removing all invalid syllogisms and then combine the premises and conclusions into a single string for fine-tuning. I found out that telling the model which premise was which and where the conclusion started improved training. Additionally, adding a $ after the last premise slightly imporved training, but this was moreso done to replicate what as done in the original GPT paper.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;">def</span> prepare_dataset(file_name):</span>
<span id="cb6-2">    dataset <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">'csv'</span>, data_files<span class="op" style="color: #5E5E5E;">=</span>file_name, sep <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">','</span>, encoding <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'ISO-8859-1'</span>)</span>
<span id="cb6-3">    dataset.set_format(<span class="bu" style="color: null;">type</span><span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pandas'</span>)</span>
<span id="cb6-4">    df <span class="op" style="color: #5E5E5E;">=</span> dataset[<span class="st" style="color: #20794D;">'train'</span>][:]</span>
<span id="cb6-5">    df <span class="op" style="color: #5E5E5E;">=</span> df[df[<span class="st" style="color: #20794D;">'Syllogistic relation'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'yes'</span>]</span>
<span id="cb6-6">    df[<span class="st" style="color: #20794D;">'text'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'&lt;startoftext&gt;'</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'Premise 1: '</span> <span class="op" style="color: #5E5E5E;">+</span> df[<span class="st" style="color: #20794D;">'Premise 1'</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'Premise 2:'</span> <span class="op" style="color: #5E5E5E;">+</span> df[<span class="st" style="color: #20794D;">'Premise 2'</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'$'</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'Conclusion:'</span> <span class="op" style="color: #5E5E5E;">+</span> df[<span class="st" style="color: #20794D;">'Conclusion'</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'&lt;endoftext&gt;'</span></span>
<span id="cb6-7">    df.reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, inplace<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb6-8">    df <span class="op" style="color: #5E5E5E;">=</span> df[[<span class="st" style="color: #20794D;">'text'</span>]]</span>
<span id="cb6-9">    dataset <span class="op" style="color: #5E5E5E;">=</span> Dataset.from_pandas(df)</span>
<span id="cb6-10">    dataset <span class="op" style="color: #5E5E5E;">=</span> dataset.<span class="bu" style="color: null;">map</span>(tokenize, batched<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, num_proc<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>, remove_columns<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">"text"</span>])</span>
<span id="cb6-11">    <span class="cf" style="color: #003B4F;">return</span> dataset</span></code></pre></div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">train_dataset <span class="op" style="color: #5E5E5E;">=</span> prepare_dataset(<span class="st" style="color: #20794D;">'Avicenna_Train.csv'</span>)</span>
<span id="cb7-2">test_dataset <span class="op" style="color: #5E5E5E;">=</span> prepare_dataset(<span class="st" style="color: #20794D;">'Avicenna_Test.csv'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using custom data configuration default-9e35c2288d530357
Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-9e35c2288d530357/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b2b5bb41dd5b49f0988b2204bd1a751d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>       </code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1206f18026244e6093596c5213272a1c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"140fbce558d843f4a09c6f24019c9762","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> </code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0db6c5fc150d46dd93240e153414e576","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7fbf3b0566364421809a41a495e6b2af","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Using custom data configuration default-80959f65edc13f7a
Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-80959f65edc13f7a/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ec743c282bb84dc0872e6461014edbe5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>        </code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fd2cc281914d454fa5b9f4103c4a0460","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"caecf74dec534c278bdc66c4ccd7f02b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d0a2302ba5944aa6872be398266c2c55","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dc13db456ed6430abe86da7dd206c87d","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">tokenizer.decode(train_dataset[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>'&lt;startoftext&gt; Premise 1: Chronic diseases are heart attacks and stroke, cancer such as breast and colon cancer, diabetes, epilepsy and seizures, obesity, and oral health problems.Premise 2:In populations that eat a regular high-fiber diet of more than 50 grams of fiber per dayTrusted Source, like rural South Africans, chronic diseases are very low.$Conclusion:In populations that eat a regular high-fiber diet of more than 50 grams of fiber per dayTrusted Source, like rural South Africans, heart attacks and stroke, cancer such as breast and colon cancer, diabetes, epilepsy and seizures, obesity, and oral health problems are very low. &lt;endoftext&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;'</code></pre>
</div>
</div>
</section>
<section id="training" class="level1">
<h1>Training</h1>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">model_name <span class="op" style="color: #5E5E5E;">=</span> model_cp.split(<span class="st" style="color: #20794D;">"/"</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb15-2">training_args <span class="op" style="color: #5E5E5E;">=</span> TrainingArguments(</span>
<span id="cb15-3">    <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>model_cp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-finetuned-syllogism"</span>,</span>
<span id="cb15-4">    evaluation_strategy <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"epoch"</span>,</span>
<span id="cb15-5">    learning_rate<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2e-5</span>,</span>
<span id="cb15-6">    weight_decay<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.01</span>,</span>
<span id="cb15-7">    push_to_hub<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb15-8">)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>PyTorch: setting up devices
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).</code></pre>
</div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">trainer <span class="op" style="color: #5E5E5E;">=</span> Trainer(</span>
<span id="cb17-2">    model<span class="op" style="color: #5E5E5E;">=</span>model,</span>
<span id="cb17-3">    args<span class="op" style="color: #5E5E5E;">=</span>training_args,</span>
<span id="cb17-4">    train_dataset<span class="op" style="color: #5E5E5E;">=</span>train_dataset,</span>
<span id="cb17-5">    eval_dataset<span class="op" style="color: #5E5E5E;">=</span>test_dataset,</span>
<span id="cb17-6">    data_collator<span class="op" style="color: #5E5E5E;">=</span>data_collator</span>
<span id="cb17-7">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">trainer.train()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2427
  Num Epochs = 3
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed &amp; accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 912</code></pre>
</div>
<div class="cell-output cell-output-display">


    <div>
      
      <progress value="912" max="912" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [912/912 04:18, Epoch 3/3]
    </div>
    <table class="dataframe table table-sm table-striped">
  <thead>
 <tr>
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>No log</td>
      <td>2.311477</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.267000</td>
      <td>2.312688</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.267000</td>
      <td>2.314481</td>
    </tr>
  </tbody>
</table><p>
</p></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Evaluation *****
  Num examples = 630
  Batch size = 8
Saving model checkpoint to gpt2-finetuned-syllogism/checkpoint-500
Configuration saved in gpt2-finetuned-syllogism/checkpoint-500/config.json
Model weights saved in gpt2-finetuned-syllogism/checkpoint-500/pytorch_model.bin
***** Running Evaluation *****
  Num examples = 630
  Batch size = 8
***** Running Evaluation *****
  Num examples = 630
  Batch size = 8


Training completed. Do not forget to share your model on huggingface.co/models =)

</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>TrainOutput(global_step=912, training_loss=2.215385637785259, metrics={'train_runtime': 258.8719, 'train_samples_per_second': 28.126, 'train_steps_per_second': 3.523, 'total_flos': 743151283200000.0, 'train_loss': 2.215385637785259, 'epoch': 3.0})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="im" style="color: #00769E;">import</span> math</span>
<span id="cb22-2">eval_results <span class="op" style="color: #5E5E5E;">=</span> trainer.evaluate()</span>
<span id="cb22-3"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Perplexity: </span><span class="sc" style="color: #5E5E5E;">{</span>math<span class="sc" style="color: #5E5E5E;">.</span>exp(eval_results[<span class="st" style="color: #20794D;">'eval_loss'</span>])<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Evaluation *****
  Num examples = 630
  Batch size = 8</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="79" max="79" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [79/79 00:05]
    </div>
    
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Perplexity: 10.12</code></pre>
</div>
</div>
</section>
<section id="testing" class="level1">
<h1>Testing</h1>
<p>First a classic example</p>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">test <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Premise 1: All men are mortal. Premise 2: Socrates is a man. $ Conclusion: '</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">input_ids <span class="op" style="color: #5E5E5E;">=</span> tokenizer(test, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pt'</span>)[<span class="st" style="color: #20794D;">'input_ids'</span>].to(device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">output_greedy <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">25</span>)</span>
<span id="cb27-2">tokenizer.decode(output_greedy[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>'Premise 1: All men are mortal. Premise 2: Socrates is a man. $ Conclusion:  Socrates is mortal'</code></pre>
</div>
</div>
<p>I dont know why it is generating this error, I believe it has something to do with me changing the models innate tokens in the beginning. But we can see that the model was able to accurately generate the conclusion for this syllogism. This first example is using greedy search, where our model simply makes a next word prediction based on the our probability distribution over the vocabulary.</p>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">output_beam <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">25</span>, num_beams<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb30-2">tokenizer.decode(output_beam[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>'Premise 1: All men are mortal. Premise 2: Socrates is a man. $ Conclusion:  Socrates is mortal'</code></pre>
</div>
</div>
<p>Beam search is when the model generates n number of beams or full sentence predictions (in this case 5) and then a word is decided based on highest probability and we continue moving down the rest of the sentence, not going back to earlier ones. This model also looks good. Beam will usually outperform greedy.</p>
</section>
<section id="the-end" class="level1">
<h1>The End</h1>
<p>See below for more tests and search methods.</p>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">output_temp <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">25</span>, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, temperature <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span>)</span>
<span id="cb33-2">tokenizer.decode(output_temp[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>'Premise 1: All men are mortal. Premise 2: Socrates is a man. $ Conclusion:  Socrates is mortal'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">output_topk <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">25</span>, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, top_k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>)</span>
<span id="cb36-2">tokenizer.decode(output_topk[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>'Premise 1: All men are mortal. Premise 2: Socrates is a man. $ Conclusion:  Socrates is a'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">output_topp <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">25</span>, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, top_p<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.90</span>)</span>
<span id="cb39-2">tokenizer.decode(output_topp[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>'Premise 1: All men are mortal. Premise 2: Socrates is a man. $ Conclusion:  Socrates is mortal'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">test2 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Premise 1: All mammals are animals. Premise 2: All elephants are mammals. $ Conclusion: '</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">input_ids <span class="op" style="color: #5E5E5E;">=</span> tokenizer(test2, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pt'</span>)[<span class="st" style="color: #20794D;">'input_ids'</span>].to(device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">output_greedy <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>)</span>
<span id="cb44-2">tokenizer.decode(output_greedy[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>'Premise 1: All mammals are animals. Premise 2: All elephants are mammals. $ Conclusion:  All elephants are animals. &lt;endoftext&gt;                       '</code></pre>
</div>
</div>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">output_beam <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>, num_beams<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb47-2">tokenizer.decode(output_beam[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>'Premise 1: All mammals are animals. Premise 2: All elephants are mammals. $ Conclusion:  All elephants are animals. &lt;endoftext&gt;                       '</code></pre>
</div>
</div>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">test3 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'Premise 1: All mammals are warm-blooded. Premise 2: All black dogs are mammals. $ Conclusion: '</span></span>
<span id="cb50-2">input_ids <span class="op" style="color: #5E5E5E;">=</span> tokenizer(test3, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pt'</span>)[<span class="st" style="color: #20794D;">'input_ids'</span>].to(device)</span>
<span id="cb50-3">output_beam <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">40</span>, num_beams <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb50-4">tokenizer.decode(output_beam[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>'Premise 1: All mammals are warm-blooded. Premise 2: All black dogs are mammals. $ Conclusion:  All black dogs are warm-blooded. &lt;endoftext&gt;   &lt;endoftext&gt;  animal is warm-'</code></pre>
</div>
</div>


</section>

 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <category>NLP</category>
  <guid>https://jakegehri.github.io/projects/Syllogism Finisher/conclusion_writer.html</guid>
  <pubDate>Tue, 29 Nov 2022 05:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/Syllogism Finisher/syllogism_conclusion.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Syllogism Validation with BERT</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/Syllogism Classification/syllogism_classification.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> nn</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch.nn.functional <span class="im" style="color: #00769E;">as</span> F</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> transformers</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> DistilBertTokenizer</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> DistilBertForSequenceClassification</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> Trainer, TrainingArguments</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_metric</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">df <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(<span class="st" style="color: #20794D;">'Avicenna_Train.csv'</span>, encoding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ISO-8859-1'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Premise 1</th>
      <th>Premise 2</th>
      <th>Syllogistic relation</th>
      <th>Conclusion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>unchecked imbalances in the society, will see ...</td>
      <td>correct these imbalances requires in-depth kno...</td>
      <td>no</td>
      <td>No conclusion</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Chronic diseases are heart attacks and stroke,...</td>
      <td>In populations that eat a regular high-fiber d...</td>
      <td>yes</td>
      <td>In populations that eat a regular high-fiber d...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Formative assessment encourages children to en...</td>
      <td>An ideal learning environment uses formative a...</td>
      <td>yes</td>
      <td>An ideal learning environment encourages child...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Underrepresented female labor force in some pr...</td>
      <td>Job discrimination comes with underrepresented...</td>
      <td>yes</td>
      <td>Job discrimination comes with not being able t...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>damaged mentality in an individual brings seri...</td>
      <td>Aggression harms the mentality of person.</td>
      <td>yes</td>
      <td>Aggression brings brings serious health proble...</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">df[<span class="st" style="color: #20794D;">'label'</span>] <span class="op" style="color: #5E5E5E;">=</span> df[<span class="st" style="color: #20794D;">'Syllogistic relation'</span>].eq(<span class="st" style="color: #20794D;">'yes'</span>).mul(<span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df[<span class="st" style="color: #20794D;">'text'</span>] <span class="op" style="color: #5E5E5E;">=</span> (df[<span class="st" style="color: #20794D;">'Premise 1'</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">" : "</span> <span class="op" style="color: #5E5E5E;">+</span> df[<span class="st" style="color: #20794D;">'Premise 2'</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">df[<span class="st" style="color: #20794D;">'label'</span>].value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>1    2427
0    2373
Name: label, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="bu" style="color: null;">int</span>(<span class="bu" style="color: null;">len</span>(df) <span class="op" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">0.8</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>3840</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">train_texts <span class="op" style="color: #5E5E5E;">=</span> df.iloc[:<span class="dv" style="color: #AD0000;">3840</span>][<span class="st" style="color: #20794D;">'text'</span>].values</span>
<span id="cb10-2">train_labels <span class="op" style="color: #5E5E5E;">=</span> df.iloc[:<span class="dv" style="color: #AD0000;">3840</span>][<span class="st" style="color: #20794D;">'label'</span>].values</span>
<span id="cb10-3"></span>
<span id="cb10-4">valid_texts <span class="op" style="color: #5E5E5E;">=</span> df.iloc[<span class="dv" style="color: #AD0000;">3840</span>:][<span class="st" style="color: #20794D;">'text'</span>].values</span>
<span id="cb10-5">valid_labels <span class="op" style="color: #5E5E5E;">=</span> df.iloc[<span class="dv" style="color: #AD0000;">3840</span>:][<span class="st" style="color: #20794D;">'label'</span>].values</span></code></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">tokenizer <span class="op" style="color: #5E5E5E;">=</span> DistilBertTokenizer.from_pretrained(<span class="st" style="color: #20794D;">'distilbert-base-uncased'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"09ccdf1223994ae1ac64845bdb38934c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4365658d6fc34ef4bbc0eda5ac75da01","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1a60fa098b7d438a8d32e8e014b0bd24","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">train_encodings <span class="op" style="color: #5E5E5E;">=</span> tokenizer(<span class="bu" style="color: null;">list</span>(train_texts), truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb12-2">valid_encodings <span class="op" style="color: #5E5E5E;">=</span> tokenizer(<span class="bu" style="color: null;">list</span>(valid_texts), truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;">class</span> SyllogismDataset(torch.utils.data.Dataset):</span>
<span id="cb13-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, encodings, labels):</span>
<span id="cb13-3">        <span class="va" style="color: #111111;">self</span>.encodings <span class="op" style="color: #5E5E5E;">=</span> encodings</span>
<span id="cb13-4">        <span class="va" style="color: #111111;">self</span>.labels <span class="op" style="color: #5E5E5E;">=</span> labels</span>
<span id="cb13-5">    </span>
<span id="cb13-6">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__getitem__</span>(<span class="va" style="color: #111111;">self</span>, idx):</span>
<span id="cb13-7">        item <span class="op" style="color: #5E5E5E;">=</span> {key: torch.tensor(val[idx]) <span class="cf" style="color: #003B4F;">for</span> key, val <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.encodings.items()}</span>
<span id="cb13-8">        item[<span class="st" style="color: #20794D;">'labels'</span>] <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(<span class="va" style="color: #111111;">self</span>.labels[idx])</span>
<span id="cb13-9">        <span class="cf" style="color: #003B4F;">return</span> item</span>
<span id="cb13-10">    </span>
<span id="cb13-11">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__len__</span>(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb13-12">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.labels)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">train_dataset <span class="op" style="color: #5E5E5E;">=</span> SyllogismDataset(train_encodings, train_labels)</span>
<span id="cb14-2">valid_dataset <span class="op" style="color: #5E5E5E;">=</span> SyllogismDataset(valid_encodings, valid_labels)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">train_dataloader <span class="op" style="color: #5E5E5E;">=</span> torch.utils.data.DataLoader2(train_dataset, batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>, shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb15-2">valid_dataloader <span class="op" style="color: #5E5E5E;">=</span> torch.utils.data.DataLoader2(valid_dataset, batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>, shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">model <span class="op" style="color: #5E5E5E;">=</span> DistilBertForSequenceClassification.from_pretrained(<span class="st" style="color: #20794D;">'distilbert-base-uncased'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8706ae5d5d604bd7b65afdeaae8848e4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">DEVICE <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">model.train()</span>
<span id="cb19-2"></span>
<span id="cb19-3">metrics <span class="op" style="color: #5E5E5E;">=</span> load_metric(<span class="st" style="color: #20794D;">'accuracy'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1d859cac4f774fffa82fcecb871d79d8","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="kw" style="color: #003B4F;">def</span> compute_metrics(eval_pred):</span>
<span id="cb20-2">    logits, labels <span class="op" style="color: #5E5E5E;">=</span> eval_pred</span>
<span id="cb20-3">    </span>
<span id="cb20-4">    predictions <span class="op" style="color: #5E5E5E;">=</span> np.argmax(logits, axis<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb20-5">    <span class="cf" style="color: #003B4F;">return</span> metrics.compute(predictions<span class="op" style="color: #5E5E5E;">=</span>predictions, references<span class="op" style="color: #5E5E5E;">=</span>labels)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">training_args <span class="op" style="color: #5E5E5E;">=</span> TrainingArguments(output_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'./results'</span>, num_train_epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, per_device_train_batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>,</span>
<span id="cb21-2">                                 per_device_eval_batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>, logging_dir<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'./logs'</span>, logging_steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">72</span>)</span>
<span id="cb21-3"></span>
<span id="cb21-4">trainer <span class="op" style="color: #5E5E5E;">=</span> Trainer(model<span class="op" style="color: #5E5E5E;">=</span>model, </span>
<span id="cb21-5">                  args<span class="op" style="color: #5E5E5E;">=</span>training_args, </span>
<span id="cb21-6">                  train_dataset<span class="op" style="color: #5E5E5E;">=</span>train_dataset, </span>
<span id="cb21-7">                  eval_dataset<span class="op" style="color: #5E5E5E;">=</span>valid_dataset,</span>
<span id="cb21-8">                  compute_metrics<span class="op" style="color: #5E5E5E;">=</span>compute_metrics</span>
<span id="cb21-9">                 )</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">trainer.train()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 3840
  Num Epochs = 3
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed &amp; accumulation) = 16
  Gradient Accumulation steps = 1
  Total optimization steps = 720</code></pre>
</div>
<div class="cell-output cell-output-display">


    <div>
      
      <progress value="720" max="720" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [720/720 01:36, Epoch 3/3]
    </div>
    <table class="dataframe table table-sm table-striped">
  <thead>
 <tr>
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>72</td>
      <td>0.658500</td>
    </tr>
    <tr>
      <td>144</td>
      <td>0.492300</td>
    </tr>
    <tr>
      <td>216</td>
      <td>0.413400</td>
    </tr>
    <tr>
      <td>288</td>
      <td>0.298300</td>
    </tr>
    <tr>
      <td>360</td>
      <td>0.253200</td>
    </tr>
    <tr>
      <td>432</td>
      <td>0.216700</td>
    </tr>
    <tr>
      <td>504</td>
      <td>0.178600</td>
    </tr>
    <tr>
      <td>576</td>
      <td>0.106900</td>
    </tr>
    <tr>
      <td>648</td>
      <td>0.106800</td>
    </tr>
    <tr>
      <td>720</td>
      <td>0.091800</td>
    </tr>
  </tbody>
</table><p>
</p></div>
<div class="cell-output cell-output-stderr">
<pre><code>Saving model checkpoint to ./results/checkpoint-500
Configuration saved in ./results/checkpoint-500/config.json
Model weights saved in ./results/checkpoint-500/pytorch_model.bin


Training completed. Do not forget to share your model on huggingface.co/models =)

</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>TrainOutput(global_step=720, training_loss=0.281636557314131, metrics={'train_runtime': 97.56, 'train_samples_per_second': 118.081, 'train_steps_per_second': 7.38, 'total_flos': 289110097566720.0, 'train_loss': 0.281636557314131, 'epoch': 3.0})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">trainer.evaluate()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Evaluation *****
  Num examples = 960
  Batch size = 16</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="143" max="60" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [60/60 02:07]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>{'eval_loss': 0.4387502670288086,
 'eval_accuracy': 0.88125,
 'eval_runtime': 2.2301,
 'eval_samples_per_second': 430.476,
 'eval_steps_per_second': 26.905,
 'epoch': 3.0}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">df_test <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(<span class="st" style="color: #20794D;">'Avicenna_Test.csv'</span>, encoding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ISO-8859-1'</span>)</span>
<span id="cb29-2"></span>
<span id="cb29-3">df_test[<span class="st" style="color: #20794D;">'label'</span>] <span class="op" style="color: #5E5E5E;">=</span> df_test[<span class="st" style="color: #20794D;">'Syllogistic relation'</span>].eq(<span class="st" style="color: #20794D;">'yes'</span>).mul(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb29-4">df_test[<span class="st" style="color: #20794D;">'text'</span>] <span class="op" style="color: #5E5E5E;">=</span> (df_test[<span class="st" style="color: #20794D;">'Premise 1'</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">" : "</span> <span class="op" style="color: #5E5E5E;">+</span> df_test[<span class="st" style="color: #20794D;">'Premise 2'</span>])</span>
<span id="cb29-5"></span>
<span id="cb29-6">test_texts <span class="op" style="color: #5E5E5E;">=</span> df_test[<span class="st" style="color: #20794D;">'text'</span>].values</span>
<span id="cb29-7">test_labels <span class="op" style="color: #5E5E5E;">=</span> df_test[<span class="st" style="color: #20794D;">'label'</span>].values</span>
<span id="cb29-8"></span>
<span id="cb29-9">test_encodings <span class="op" style="color: #5E5E5E;">=</span> tokenizer(<span class="bu" style="color: null;">list</span>(test_texts), truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb29-10"></span>
<span id="cb29-11">test_dataset <span class="op" style="color: #5E5E5E;">=</span> SyllogismDataset(test_encodings, test_labels)</span>
<span id="cb29-12"></span>
<span id="cb29-13">test_dataloader <span class="op" style="color: #5E5E5E;">=</span> torch.utils.data.DataLoader(test_dataset, batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>, shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">trainer.evaluate(test_dataset)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Evaluation *****
  Num examples = 1200
  Batch size = 16</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>{'eval_loss': 0.5759531855583191,
 'eval_accuracy': 0.8525,
 'eval_runtime': 2.8515,
 'eval_samples_per_second': 420.837,
 'eval_steps_per_second': 26.302,
 'epoch': 3.0}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">sample_text <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'Socrates is a man : all men are mortal'</span>]</span>
<span id="cb33-2">sample_label <span class="op" style="color: #5E5E5E;">=</span> [<span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">sample_encoded <span class="op" style="color: #5E5E5E;">=</span> tokenizer(sample_text, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">sample_dataset <span class="op" style="color: #5E5E5E;">=</span> SyllogismDataset(sample_encoded, sample_label)</span>
<span id="cb35-2">sample_dataset</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>&lt;__main__.SyllogismDataset at 0x7f63a4fccd60&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">trainer.predict(sample_dataset).label_ids</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Prediction *****
  Num examples = 1
  Batch size = 16</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>array([1])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">sample_text_2 <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'If the streets are wet, it has rained recently : The streets are wet.'</span>]</span>
<span id="cb40-2">sample_label_2 <span class="op" style="color: #5E5E5E;">=</span> [<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb40-3"></span>
<span id="cb40-4">sample_encoded_2 <span class="op" style="color: #5E5E5E;">=</span> tokenizer(sample_text_2, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb40-5"></span>
<span id="cb40-6">sample_dataset_2 <span class="op" style="color: #5E5E5E;">=</span> SyllogismDataset(sample_encoded_2, sample_label_2)</span>
<span id="cb40-7"></span>
<span id="cb40-8">trainer.predict(sample_dataset_2).label_ids</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Prediction *****
  Num examples = 1
  Batch size = 16</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>array([0])</code></pre>
</div>
</div>



 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <category>NLP</category>
  <guid>https://jakegehri.github.io/projects/Syllogism Classification/syllogism_classification.html</guid>
  <pubDate>Sun, 27 Nov 2022 05:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/Syllogism Classification/syllogism.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Counting Cards: Computer vision classifier for playing cards</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/Counting Cards/counting_cards.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> nn</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> torchvision.transforms <span class="im" style="color: #00769E;">as</span> transforms</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> torchvision</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> torch.utils.data <span class="im" style="color: #00769E;">import</span> DataLoader</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> torchvision.utils <span class="im" style="color: #00769E;">import</span> make_grid</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> torchvision.utils <span class="im" style="color: #00769E;">import</span> save_image</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">from</span> torchvision <span class="im" style="color: #00769E;">import</span> datasets</span>
<span id="cb1-12"><span class="op" style="color: #5E5E5E;">!</span>pip install torchmetrics</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">from</span> torchmetrics <span class="im" style="color: #00769E;">import</span> Accuracy</span>
<span id="cb1-14"><span class="op" style="color: #5E5E5E;">!</span>pip install path</span>
<span id="cb1-15"><span class="im" style="color: #00769E;">from</span> path <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-16"><span class="cf" style="color: #003B4F;">try</span>: </span>
<span id="cb1-17">    <span class="im" style="color: #00769E;">import</span> torchinfo</span>
<span id="cb1-18"><span class="cf" style="color: #003B4F;">except</span>:</span>
<span id="cb1-19">    <span class="op" style="color: #5E5E5E;">!</span>pip install torchinfo</span>
<span id="cb1-20">    <span class="im" style="color: #00769E;">import</span> torchinfo</span>
<span id="cb1-21">    </span>
<span id="cb1-22"><span class="im" style="color: #00769E;">from</span> torchinfo <span class="im" style="color: #00769E;">import</span> summary</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (0.10.3)
Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.23.1)
Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (21.3)
Requirement already satisfied: torch&gt;=1.3.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.12.0+cu116)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch&gt;=1.3.1-&gt;torchmetrics) (4.3.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging-&gt;torchmetrics) (3.0.9)
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Requirement already satisfied: path in /usr/local/lib/python3.9/dist-packages (16.5.0)
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">creds <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'{"username":"jakegehri","key":"3d0213a52bd1816d21037e941bc77569"}'</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">cred_path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'~/.kaggle/kaggle.json'</span>).expanduser()</span>
<span id="cb4-2"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> cred_path.exists(): </span>
<span id="cb4-3">    cred_path.parent.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>) </span>
<span id="cb4-4">    cred_path.write_text(creds) </span>
<span id="cb4-5">    cred_path.chmod(<span class="bn" style="color: #AD0000;">0o600</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">train_dir <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'train'</span>)</span>
<span id="cb5-2">valid_dir <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'valid'</span>)</span>
<span id="cb5-3">test_dir <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'test'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">img <span class="op" style="color: #5E5E5E;">=</span> (train_dir <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">'ace of clubs'</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">'001.jpg'</span>)</span>
<span id="cb6-2">img <span class="op" style="color: #5E5E5E;">=</span> Image.<span class="bu" style="color: null;">open</span>(img)</span>
<span id="cb6-3">img</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">img.size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>(224, 224)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">data_transforms <span class="op" style="color: #5E5E5E;">=</span> transforms.Compose([</span>
<span id="cb9-2">    transforms.Resize(<span class="dv" style="color: #AD0000;">64</span>),</span>
<span id="cb9-3">    transforms.RandomVerticalFlip(<span class="fl" style="color: #AD0000;">0.5</span>),</span>
<span id="cb9-4">    transforms.RandomRotation(<span class="dv" style="color: #AD0000;">90</span>),</span>
<span id="cb9-5">    transforms.ToTensor()</span>
<span id="cb9-6"></span>
<span id="cb9-7">])</span>
<span id="cb9-8"></span>
<span id="cb9-9"></span>
<span id="cb9-10">test_transforms <span class="op" style="color: #5E5E5E;">=</span> transforms.Compose([</span>
<span id="cb9-11">    transforms.Resize(<span class="dv" style="color: #AD0000;">64</span>),</span>
<span id="cb9-12">    transforms.ToTensor()</span>
<span id="cb9-13">])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">train_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>train_dir,</span>
<span id="cb10-2">                                  transform<span class="op" style="color: #5E5E5E;">=</span>data_transforms,</span>
<span id="cb10-3">                                  target_transform<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb10-4"></span>
<span id="cb10-5">valid_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>valid_dir,</span>
<span id="cb10-6">                                  transform<span class="op" style="color: #5E5E5E;">=</span>data_transforms)</span>
<span id="cb10-7"></span>
<span id="cb10-8">test_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>test_dir,</span>
<span id="cb10-9">                                  transform<span class="op" style="color: #5E5E5E;">=</span>test_transforms)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">ex <span class="op" style="color: #5E5E5E;">=</span> train_data[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb11-2">plt.imshow(ex.permute(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f3aefa8d8b0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">class_names <span class="op" style="color: #5E5E5E;">=</span> train_data.classes</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="bu" style="color: null;">len</span>(train_data.samples)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>7518</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">train_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>train_data,</span>
<span id="cb16-2">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb16-3">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb16-4"></span>
<span id="cb16-5">valid_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>valid_data,</span>
<span id="cb16-6">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb16-7">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb16-8"></span>
<span id="cb16-9">test_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>test_data,</span>
<span id="cb16-10">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb16-11">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<section id="small-vgg-model" class="level1">
<h1>Small VGG Model</h1>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">'cpu'</span></span>
<span id="cb17-2"></span>
<span id="cb17-3"><span class="kw" style="color: #003B4F;">class</span> TinyVGG(nn.Module):</span>
<span id="cb17-4">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, input_shape, hidden_units, output_shape):</span>
<span id="cb17-5">        <span class="bu" style="color: null;">super</span>().<span class="fu" style="color: #4758AB;">__init__</span>()</span>
<span id="cb17-6">        <span class="va" style="color: #111111;">self</span>.conv_block_1 <span class="op" style="color: #5E5E5E;">=</span> nn.Sequential(</span>
<span id="cb17-7">            nn.Conv2d(in_channels<span class="op" style="color: #5E5E5E;">=</span>input_shape, out_channels<span class="op" style="color: #5E5E5E;">=</span>hidden_units, kernel_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, stride<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb17-8">            nn.ReLU(),</span>
<span id="cb17-9">            nn.Conv2d(in_channels<span class="op" style="color: #5E5E5E;">=</span>hidden_units, out_channels<span class="op" style="color: #5E5E5E;">=</span>hidden_units, kernel_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, stride<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb17-10">            nn.ReLU(),</span>
<span id="cb17-11">            nn.MaxPool2d(kernel_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb17-12">        )</span>
<span id="cb17-13">        </span>
<span id="cb17-14">        <span class="va" style="color: #111111;">self</span>.conv_block_2 <span class="op" style="color: #5E5E5E;">=</span> nn.Sequential(</span>
<span id="cb17-15">            nn.Conv2d(in_channels<span class="op" style="color: #5E5E5E;">=</span>hidden_units, out_channels<span class="op" style="color: #5E5E5E;">=</span>hidden_units, kernel_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, stride<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb17-16">            nn.ReLU(),</span>
<span id="cb17-17">            nn.Conv2d(in_channels<span class="op" style="color: #5E5E5E;">=</span>hidden_units, out_channels<span class="op" style="color: #5E5E5E;">=</span>hidden_units, kernel_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, stride<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, padding<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb17-18">            nn.ReLU(),</span>
<span id="cb17-19">            nn.MaxPool2d(kernel_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)   </span>
<span id="cb17-20">        )</span>
<span id="cb17-21">        </span>
<span id="cb17-22">        <span class="va" style="color: #111111;">self</span>.classifier <span class="op" style="color: #5E5E5E;">=</span> nn.Sequential(</span>
<span id="cb17-23">            nn.Flatten(),</span>
<span id="cb17-24">            nn.Linear(in_features<span class="op" style="color: #5E5E5E;">=</span>hidden_units<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">16</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">16</span>, out_features<span class="op" style="color: #5E5E5E;">=</span>output_shape)</span>
<span id="cb17-25">        )</span>
<span id="cb17-26">        </span>
<span id="cb17-27"></span>
<span id="cb17-28">    <span class="kw" style="color: #003B4F;">def</span> forward(<span class="va" style="color: #111111;">self</span>, x):</span>
<span id="cb17-29">        x <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.conv_block_1(x)</span>
<span id="cb17-30">        x <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.conv_block_2(x)</span>
<span id="cb17-31">        x <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.classifier(x)</span>
<span id="cb17-32">        <span class="cf" style="color: #003B4F;">return</span> x</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">model_0 <span class="op" style="color: #5E5E5E;">=</span> TinyVGG(input_shape<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, hidden_units<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>, output_shape<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">len</span>(train_data.classes)).to(device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">model_0</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>TinyVGG(
  (conv_block_1): Sequential(
    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv_block_2): Sequential(
    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=2560, out_features=52, bias=True)
  )
)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">summary(model_0, input_size<span class="op" style="color: #5E5E5E;">=</span>[<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">64</span>, <span class="dv" style="color: #AD0000;">64</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TinyVGG                                  [1, 52]                   --
Sequential: 1-1                        [1, 10, 32, 32]           --
    Conv2d: 2-1                       [1, 10, 64, 64]           280
    ReLU: 2-2                         [1, 10, 64, 64]           --
    Conv2d: 2-3                       [1, 10, 64, 64]           910
    ReLU: 2-4                         [1, 10, 64, 64]           --
    MaxPool2d: 2-5                    [1, 10, 32, 32]           --
Sequential: 1-2                        [1, 10, 16, 16]           --
    Conv2d: 2-6                       [1, 10, 32, 32]           910
    ReLU: 2-7                         [1, 10, 32, 32]           --
    Conv2d: 2-8                       [1, 10, 32, 32]           910
    ReLU: 2-9                         [1, 10, 32, 32]           --
    MaxPool2d: 2-10                   [1, 10, 16, 16]           --
Sequential: 1-3                        [1, 52]                   --
    Flatten: 2-11                     [1, 2560]                 --
    Linear: 2-12                      [1, 52]                   133,172
==========================================================================================
Total params: 136,182
Trainable params: 136,182
Non-trainable params: 0
Total mult-adds (M): 6.87
==========================================================================================
Input size (MB): 0.05
Forward/backward pass size (MB): 0.82
Params size (MB): 0.54
Estimated Total Size (MB): 1.41
==========================================================================================</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">img_batch, label_batch <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">next</span>(<span class="bu" style="color: null;">iter</span>(train_dl))</span>
<span id="cb23-2"></span>
<span id="cb23-3">img_single, label_single <span class="op" style="color: #5E5E5E;">=</span> img_batch[<span class="dv" style="color: #AD0000;">0</span>].unsqueeze(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>), label_batch[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb23-4"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Single image shape: </span><span class="sc" style="color: #5E5E5E;">{</span>img_single<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb23-5"></span>
<span id="cb23-6">model_0.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb23-7"><span class="cf" style="color: #003B4F;">with</span> torch.inference_mode():</span>
<span id="cb23-8">    pred <span class="op" style="color: #5E5E5E;">=</span> model_0(img_single.to(device))</span>
<span id="cb23-9"></span>
<span id="cb23-10"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Output logits:</span><span class="ch" style="color: #20794D;">\n</span><span class="sc" style="color: #5E5E5E;">{</span>pred<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb23-11"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Output prediction probabilities:</span><span class="ch" style="color: #20794D;">\n</span><span class="sc" style="color: #5E5E5E;">{</span>torch<span class="sc" style="color: #5E5E5E;">.</span>softmax(pred, dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb23-12"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Output prediction label:</span><span class="ch" style="color: #20794D;">\n</span><span class="sc" style="color: #5E5E5E;">{</span>torch<span class="sc" style="color: #5E5E5E;">.</span>argmax(torch.softmax(pred, dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)<span class="sc" style="color: #5E5E5E;">}</span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb23-13"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Actual label:</span><span class="ch" style="color: #20794D;">\n</span><span class="sc" style="color: #5E5E5E;">{</span>label_single<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Single image shape: torch.Size([1, 3, 64, 64])

Output logits:
tensor([[-0.0280, -0.0261,  0.0380, -0.0245, -0.0023, -0.0061, -0.0346,  0.0206,
          0.0212,  0.0360, -0.0263,  0.0042, -0.0558,  0.0214,  0.0385,  0.0275,
         -0.0160, -0.0569,  0.0222,  0.0187,  0.0538,  0.0149, -0.0417, -0.0173,
          0.0052, -0.0290,  0.0435,  0.0482, -0.0220, -0.0251, -0.0198,  0.0114,
          0.0214, -0.0082, -0.0052,  0.0327, -0.0327,  0.0152, -0.0507,  0.0004,
         -0.0974, -0.0024, -0.0002,  0.0110,  0.0223,  0.0388,  0.0207, -0.0025,
          0.0742,  0.0031, -0.0055, -0.0171]], device='cuda:0')

Output prediction probabilities:
tensor([[0.0187, 0.0187, 0.0200, 0.0188, 0.0192, 0.0191, 0.0186, 0.0196, 0.0196,
         0.0199, 0.0187, 0.0193, 0.0182, 0.0196, 0.0200, 0.0198, 0.0189, 0.0182,
         0.0196, 0.0196, 0.0203, 0.0195, 0.0184, 0.0189, 0.0193, 0.0187, 0.0201,
         0.0202, 0.0188, 0.0187, 0.0188, 0.0194, 0.0196, 0.0191, 0.0191, 0.0199,
         0.0186, 0.0195, 0.0183, 0.0192, 0.0174, 0.0192, 0.0192, 0.0194, 0.0197,
         0.0200, 0.0196, 0.0192, 0.0207, 0.0193, 0.0191, 0.0189]],
       device='cuda:0')

Output prediction label:
tensor([48], device='cuda:0')

Actual label:
35</code></pre>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="kw" style="color: #003B4F;">def</span> train_step(model: torch.nn.Module, </span>
<span id="cb25-2">               dataloader: torch.utils.data.DataLoader, </span>
<span id="cb25-3">               loss_fn: torch.nn.Module, </span>
<span id="cb25-4">               optimizer: torch.optim.Optimizer,</span>
<span id="cb25-5">               accuracy):</span>
<span id="cb25-6">    </span>
<span id="cb25-7">    model.train()</span>
<span id="cb25-8">    </span>
<span id="cb25-9">    train_loss, train_acc <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb25-10"></span>
<span id="cb25-11">    <span class="cf" style="color: #003B4F;">for</span> batch, (X, y) <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(dataloader):</span>
<span id="cb25-12"></span>
<span id="cb25-13">        X, y <span class="op" style="color: #5E5E5E;">=</span> X.to(device), y.to(device)</span>
<span id="cb25-14"></span>
<span id="cb25-15">        y_pred <span class="op" style="color: #5E5E5E;">=</span> model(X)</span>
<span id="cb25-16"></span>
<span id="cb25-17">        loss <span class="op" style="color: #5E5E5E;">=</span> loss_fn(y_pred, y)</span>
<span id="cb25-18">        train_loss <span class="op" style="color: #5E5E5E;">+=</span> loss.item() </span>
<span id="cb25-19"></span>
<span id="cb25-20">        optimizer.zero_grad()</span>
<span id="cb25-21"></span>
<span id="cb25-22">        loss.backward()</span>
<span id="cb25-23"></span>
<span id="cb25-24">        optimizer.step()</span>
<span id="cb25-25"></span>
<span id="cb25-26">        y_pred_class <span class="op" style="color: #5E5E5E;">=</span> torch.argmax(torch.softmax(y_pred, dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb25-27">        train_acc <span class="op" style="color: #5E5E5E;">+=</span> accuracy(y_pred_class, y)</span>
<span id="cb25-28"></span>
<span id="cb25-29">    train_loss <span class="op" style="color: #5E5E5E;">/=</span> <span class="bu" style="color: null;">len</span>(dataloader)</span>
<span id="cb25-30">    train_acc <span class="op" style="color: #5E5E5E;">/=</span> <span class="bu" style="color: null;">len</span>(dataloader)</span>
<span id="cb25-31">    <span class="cf" style="color: #003B4F;">return</span> train_loss, train_acc</span></code></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;">def</span> valid_step(model, dataloader, loss_fn, accuracy):</span>
<span id="cb26-2">    </span>
<span id="cb26-3">    model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb26-4">    </span>
<span id="cb26-5">    valid_loss, valid_acc <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb26-6">    </span>
<span id="cb26-7">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb26-8">        <span class="cf" style="color: #003B4F;">for</span> batch, (X, y) <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(dataloader):</span>
<span id="cb26-9">            X, y <span class="op" style="color: #5E5E5E;">=</span> X.to(device), y.to(device)</span>
<span id="cb26-10"></span>
<span id="cb26-11">            y_pred <span class="op" style="color: #5E5E5E;">=</span> model(X)</span>
<span id="cb26-12">            </span>
<span id="cb26-13">            valid_loss <span class="op" style="color: #5E5E5E;">+=</span> loss_fn(y_pred, y)</span>
<span id="cb26-14">            </span>
<span id="cb26-15">            valid_pred_labels <span class="op" style="color: #5E5E5E;">=</span> y_pred.argmax(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb26-16">            </span>
<span id="cb26-17">            valid_acc <span class="op" style="color: #5E5E5E;">+=</span> accuracy(valid_pred_labels, y)</span>
<span id="cb26-18">            </span>
<span id="cb26-19">    valid_loss <span class="op" style="color: #5E5E5E;">/=</span> <span class="bu" style="color: null;">len</span>(dataloader)</span>
<span id="cb26-20">    valid_acc <span class="op" style="color: #5E5E5E;">/=</span> <span class="bu" style="color: null;">len</span>(dataloader)</span>
<span id="cb26-21">    </span>
<span id="cb26-22">    <span class="cf" style="color: #003B4F;">return</span> valid_loss, valid_acc</span></code></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="kw" style="color: #003B4F;">def</span> train(model, train_dataloader, valid_dataloader, optimizer, loss_fn, accuracy, epochs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb27-2">    </span>
<span id="cb27-3">    results <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">"train_loss"</span>: [],</span>
<span id="cb27-4">               <span class="st" style="color: #20794D;">"train_accuracy"</span>: [],</span>
<span id="cb27-5">               <span class="st" style="color: #20794D;">"valid_loss"</span>: [],</span>
<span id="cb27-6">               <span class="st" style="color: #20794D;">"valid_accuracy"</span>: []</span>
<span id="cb27-7">              }</span>
<span id="cb27-8">    </span>
<span id="cb27-9">    <span class="cf" style="color: #003B4F;">for</span> epoch <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(epochs):</span>
<span id="cb27-10">        train_loss, train_acc <span class="op" style="color: #5E5E5E;">=</span> train_step(model, train_dataloader, loss_fn, optimizer, accuracy)</span>
<span id="cb27-11">        </span>
<span id="cb27-12">        valid_loss, valid_acc <span class="op" style="color: #5E5E5E;">=</span> valid_step(model, valid_dataloader, loss_fn, accuracy)</span>
<span id="cb27-13">        </span>
<span id="cb27-14">        <span class="bu" style="color: null;">print</span>(</span>
<span id="cb27-15">            <span class="ss" style="color: #20794D;">f"Epoch: </span><span class="sc" style="color: #5E5E5E;">{</span>epoch<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> | "</span></span>
<span id="cb27-16">            <span class="ss" style="color: #20794D;">f"train_loss: </span><span class="sc" style="color: #5E5E5E;">{</span>train_loss<span class="sc" style="color: #5E5E5E;">:.4f}</span><span class="ss" style="color: #20794D;"> | "</span></span>
<span id="cb27-17">            <span class="ss" style="color: #20794D;">f"train_accuracy: </span><span class="sc" style="color: #5E5E5E;">{</span>train_acc<span class="sc" style="color: #5E5E5E;">:.4f}</span><span class="ss" style="color: #20794D;"> | "</span></span>
<span id="cb27-18">            <span class="ss" style="color: #20794D;">f"valid_loss: </span><span class="sc" style="color: #5E5E5E;">{</span>valid_loss<span class="sc" style="color: #5E5E5E;">:.4f}</span><span class="ss" style="color: #20794D;"> | "</span></span>
<span id="cb27-19">            <span class="ss" style="color: #20794D;">f"valid_accuracy: </span><span class="sc" style="color: #5E5E5E;">{</span>valid_acc<span class="sc" style="color: #5E5E5E;">:.4f}</span><span class="ss" style="color: #20794D;"> | "</span></span>
<span id="cb27-20">        )</span>
<span id="cb27-21">        </span>
<span id="cb27-22">        <span class="co" style="color: #5E5E5E;"># 5. Update results dictionary</span></span>
<span id="cb27-23">        results[<span class="st" style="color: #20794D;">"train_loss"</span>].append(train_loss)</span>
<span id="cb27-24">        results[<span class="st" style="color: #20794D;">"train_accuracy"</span>].append(train_acc)</span>
<span id="cb27-25">        results[<span class="st" style="color: #20794D;">"valid_loss"</span>].append(valid_loss)</span>
<span id="cb27-26">        results[<span class="st" style="color: #20794D;">"valid_accuracy"</span>].append(valid_acc)</span>
<span id="cb27-27">        </span>
<span id="cb27-28">    <span class="cf" style="color: #003B4F;">return</span> results</span></code></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>) </span>
<span id="cb28-2">torch.cuda.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb28-3"></span>
<span id="cb28-4">NUM_EPOCHS <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb28-5"></span>
<span id="cb28-6"><span class="co" style="color: #5E5E5E;"># Recreate an instance of TinyVGG</span></span>
<span id="cb28-7">model_0 <span class="op" style="color: #5E5E5E;">=</span> TinyVGG(input_shape<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, hidden_units<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>, output_shape<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">len</span>(train_data.classes)).to(device)</span>
<span id="cb28-8"></span>
<span id="cb28-9"><span class="co" style="color: #5E5E5E;"># Setup loss function and optimizer</span></span>
<span id="cb28-10">loss_fn <span class="op" style="color: #5E5E5E;">=</span> nn.CrossEntropyLoss()</span>
<span id="cb28-11">optimizer <span class="op" style="color: #5E5E5E;">=</span> torch.optim.SGD(params<span class="op" style="color: #5E5E5E;">=</span>model_0.parameters(), lr<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">.01</span>)</span>
<span id="cb28-12">accuracy <span class="op" style="color: #5E5E5E;">=</span> Accuracy().to(device)</span>
<span id="cb28-13"></span>
<span id="cb28-14">model_0_results <span class="op" style="color: #5E5E5E;">=</span> train(model_0, train_dl, valid_dl, optimizer, loss_fn, accuracy, epochs<span class="op" style="color: #5E5E5E;">=</span>NUM_EPOCHS)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 1 | train_loss: 3.9513 | train_accuracy: 0.0199 | valid_loss: 3.9559 | valid_accuracy: 0.0156 | 
Epoch: 2 | train_loss: 3.9487 | train_accuracy: 0.0200 | valid_loss: 3.9526 | valid_accuracy: 0.0156 | 
Epoch: 3 | train_loss: 3.9473 | train_accuracy: 0.0219 | valid_loss: 3.9492 | valid_accuracy: 0.0188 | 
Epoch: 4 | train_loss: 3.9466 | train_accuracy: 0.0215 | valid_loss: 3.9470 | valid_accuracy: 0.0156 | 
Epoch: 5 | train_loss: 3.9462 | train_accuracy: 0.0238 | valid_loss: 3.9452 | valid_accuracy: 0.0156 | 
Epoch: 6 | train_loss: 3.9460 | train_accuracy: 0.0240 | valid_loss: 3.9445 | valid_accuracy: 0.0156 | 
Epoch: 7 | train_loss: 3.9459 | train_accuracy: 0.0240 | valid_loss: 3.9439 | valid_accuracy: 0.0156 | 
Epoch: 8 | train_loss: 3.9459 | train_accuracy: 0.0239 | valid_loss: 3.9436 | valid_accuracy: 0.0156 | 
Epoch: 9 | train_loss: 3.9457 | train_accuracy: 0.0241 | valid_loss: 3.9426 | valid_accuracy: 0.0156 | 
Epoch: 10 | train_loss: 3.9457 | train_accuracy: 0.0240 | valid_loss: 3.9432 | valid_accuracy: 0.0156 | </code></pre>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">torch.tensor(model_0_results[<span class="st" style="color: #20794D;">'valid_loss'</span>]).cpu().numpy()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>array([3.9559014, 3.9525807, 3.949228 , 3.9469597, 3.9452446, 3.9445374,
       3.9439054, 3.9435685, 3.9426103, 3.9431756], dtype=float32)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="kw" style="color: #003B4F;">def</span> plot_loss_curves(results):</span>
<span id="cb32-2">    loss <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(results[<span class="st" style="color: #20794D;">'train_loss'</span>]).cpu()</span>
<span id="cb32-3">    valid_loss <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(results[<span class="st" style="color: #20794D;">'valid_loss'</span>]).cpu()</span>
<span id="cb32-4">    accuracy <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(results[<span class="st" style="color: #20794D;">'train_accuracy'</span>]).cpu()</span>
<span id="cb32-5">    valid_accuracy <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(results[<span class="st" style="color: #20794D;">'valid_accuracy'</span>]).cpu()</span>
<span id="cb32-6"></span>
<span id="cb32-7">    <span class="co" style="color: #5E5E5E;"># Figure out how many epochs there were</span></span>
<span id="cb32-8">    epochs <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(results[<span class="st" style="color: #20794D;">'train_loss'</span>]))</span>
<span id="cb32-9"></span>
<span id="cb32-10">    <span class="co" style="color: #5E5E5E;"># Setup a plot </span></span>
<span id="cb32-11">    plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">15</span>, <span class="dv" style="color: #AD0000;">7</span>))</span>
<span id="cb32-12"></span>
<span id="cb32-13">    <span class="co" style="color: #5E5E5E;"># Plot loss</span></span>
<span id="cb32-14">    plt.subplot(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb32-15">    plt.plot(epochs, loss, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train_loss'</span>)</span>
<span id="cb32-16">    plt.plot(epochs, valid_loss, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'valid_loss'</span>)</span>
<span id="cb32-17">    plt.title(<span class="st" style="color: #20794D;">'Loss'</span>)</span>
<span id="cb32-18">    plt.xlabel(<span class="st" style="color: #20794D;">'Epochs'</span>)</span>
<span id="cb32-19">    plt.legend()</span>
<span id="cb32-20"></span>
<span id="cb32-21">    <span class="co" style="color: #5E5E5E;"># Plot accuracy</span></span>
<span id="cb32-22">    plt.subplot(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb32-23">    plt.plot(epochs, accuracy, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'train_accuracy'</span>)</span>
<span id="cb32-24">    plt.plot(epochs, valid_accuracy, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'valid_accuracy'</span>)</span>
<span id="cb32-25">    plt.title(<span class="st" style="color: #20794D;">'Accuracy'</span>)</span>
<span id="cb32-26">    plt.xlabel(<span class="st" style="color: #20794D;">'Epochs'</span>)</span>
<span id="cb32-27">    plt.legend()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">plot_loss_curves(model_0_results)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/1f2346a6-2a80-440b-b492-a37e1d809e8c-1-8d9e1c19-9ec7-4665-8749-0f26cf8385c0.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
<section id="try-transfer-learning" class="level1">
<h1>Try transfer learning</h1>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">weights <span class="op" style="color: #5E5E5E;">=</span> torchvision.models.EfficientNet_B1_Weights.DEFAULT</span>
<span id="cb34-2">weights</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>EfficientNet_B1_Weights.IMAGENET1K_V2</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">auto_transforms <span class="op" style="color: #5E5E5E;">=</span> weights.transforms()</span>
<span id="cb36-2">auto_transforms</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>ImageClassification(
    crop_size=[240]
    resize_size=[255]
    mean=[0.485, 0.456, 0.406]
    std=[0.229, 0.224, 0.225]
    interpolation=InterpolationMode.BILINEAR
)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">train_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>train_dir,</span>
<span id="cb38-2">                                  transform<span class="op" style="color: #5E5E5E;">=</span>auto_transforms,</span>
<span id="cb38-3">                                  target_transform<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb38-4"></span>
<span id="cb38-5">valid_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>valid_dir,</span>
<span id="cb38-6">                                  transform<span class="op" style="color: #5E5E5E;">=</span>auto_transforms)</span>
<span id="cb38-7"></span>
<span id="cb38-8">test_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>test_dir,</span>
<span id="cb38-9">                                  transform<span class="op" style="color: #5E5E5E;">=</span>auto_transforms)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">train_data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>Dataset ImageFolder
    Number of datapoints: 7518
    Root location: train
    StandardTransform
Transform: ImageClassification(
               crop_size=[240]
               resize_size=[255]
               mean=[0.485, 0.456, 0.406]
               std=[0.229, 0.224, 0.225]
               interpolation=InterpolationMode.BILINEAR
           )</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">train_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>train_data,</span>
<span id="cb41-2">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb41-3">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb41-4"></span>
<span id="cb41-5">valid_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>valid_data,</span>
<span id="cb41-6">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb41-7">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb41-8"></span>
<span id="cb41-9">test_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>test_data,</span>
<span id="cb41-10">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb41-11">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">'cpu'</span></span>
<span id="cb42-2">model_1 <span class="op" style="color: #5E5E5E;">=</span> torchvision.models.efficientnet_b1(weights<span class="op" style="color: #5E5E5E;">=</span>weights).to(device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">summary(model_1, input_size<span class="op" style="color: #5E5E5E;">=</span>[<span class="dv" style="color: #AD0000;">32</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">224</span>, <span class="dv" style="color: #AD0000;">224</span>], col_names <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"input_size"</span>, <span class="st" style="color: #20794D;">"output_size"</span>, <span class="st" style="color: #20794D;">"num_params"</span>, <span class="st" style="color: #20794D;">"trainable"</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>===========================================================================================================================================================
Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable
===========================================================================================================================================================
EfficientNet                                            [32, 3, 224, 224]         [32, 1000]                --                        True
Sequential: 1-1                                       [32, 3, 224, 224]         [32, 1280, 7, 7]          --                        True
    Conv2dNormActivation: 2-1                        [32, 3, 224, 224]         [32, 32, 112, 112]        --                        True
        Conv2d: 3-1                                 [32, 3, 224, 224]         [32, 32, 112, 112]        864                       True
        BatchNorm2d: 3-2                            [32, 32, 112, 112]        [32, 32, 112, 112]        64                        True
        SiLU: 3-3                                   [32, 32, 112, 112]        [32, 32, 112, 112]        --                        --
    Sequential: 2-2                                  [32, 32, 112, 112]        [32, 16, 112, 112]        --                        True
        MBConv: 3-4                                 [32, 32, 112, 112]        [32, 16, 112, 112]        1,448                     True
        MBConv: 3-5                                 [32, 16, 112, 112]        [32, 16, 112, 112]        612                       True
    Sequential: 2-3                                  [32, 16, 112, 112]        [32, 24, 56, 56]          --                        True
        MBConv: 3-6                                 [32, 16, 112, 112]        [32, 24, 56, 56]          6,004                     True
        MBConv: 3-7                                 [32, 24, 56, 56]          [32, 24, 56, 56]          10,710                    True
        MBConv: 3-8                                 [32, 24, 56, 56]          [32, 24, 56, 56]          10,710                    True
    Sequential: 2-4                                  [32, 24, 56, 56]          [32, 40, 28, 28]          --                        True
        MBConv: 3-9                                 [32, 24, 56, 56]          [32, 40, 28, 28]          15,350                    True
        MBConv: 3-10                                [32, 40, 28, 28]          [32, 40, 28, 28]          31,290                    True
        MBConv: 3-11                                [32, 40, 28, 28]          [32, 40, 28, 28]          31,290                    True
    Sequential: 2-5                                  [32, 40, 28, 28]          [32, 80, 14, 14]          --                        True
        MBConv: 3-12                                [32, 40, 28, 28]          [32, 80, 14, 14]          37,130                    True
        MBConv: 3-13                                [32, 80, 14, 14]          [32, 80, 14, 14]          102,900                   True
        MBConv: 3-14                                [32, 80, 14, 14]          [32, 80, 14, 14]          102,900                   True
        MBConv: 3-15                                [32, 80, 14, 14]          [32, 80, 14, 14]          102,900                   True
    Sequential: 2-6                                  [32, 80, 14, 14]          [32, 112, 14, 14]         --                        True
        MBConv: 3-16                                [32, 80, 14, 14]          [32, 112, 14, 14]         126,004                   True
        MBConv: 3-17                                [32, 112, 14, 14]         [32, 112, 14, 14]         208,572                   True
        MBConv: 3-18                                [32, 112, 14, 14]         [32, 112, 14, 14]         208,572                   True
        MBConv: 3-19                                [32, 112, 14, 14]         [32, 112, 14, 14]         208,572                   True
    Sequential: 2-7                                  [32, 112, 14, 14]         [32, 192, 7, 7]           --                        True
        MBConv: 3-20                                [32, 112, 14, 14]         [32, 192, 7, 7]           262,492                   True
        MBConv: 3-21                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
        MBConv: 3-22                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
        MBConv: 3-23                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
        MBConv: 3-24                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
    Sequential: 2-8                                  [32, 192, 7, 7]           [32, 320, 7, 7]           --                        True
        MBConv: 3-25                                [32, 192, 7, 7]           [32, 320, 7, 7]           717,232                   True
        MBConv: 3-26                                [32, 320, 7, 7]           [32, 320, 7, 7]           1,563,600                 True
    Conv2dNormActivation: 2-9                        [32, 320, 7, 7]           [32, 1280, 7, 7]          --                        True
        Conv2d: 3-27                                [32, 320, 7, 7]           [32, 1280, 7, 7]          409,600                   True
        BatchNorm2d: 3-28                           [32, 1280, 7, 7]          [32, 1280, 7, 7]          2,560                     True
        SiLU: 3-29                                  [32, 1280, 7, 7]          [32, 1280, 7, 7]          --                        --
AdaptiveAvgPool2d: 1-2                                [32, 1280, 7, 7]          [32, 1280, 1, 1]          --                        --
Sequential: 1-3                                       [32, 1280]                [32, 1000]                --                        True
    Dropout: 2-10                                    [32, 1280]                [32, 1280]                --                        --
    Linear: 2-11                                     [32, 1280]                [32, 1000]                1,281,000                 True
===========================================================================================================================================================
Total params: 7,794,184
Trainable params: 7,794,184
Non-trainable params: 0
Total mult-adds (G): 18.23
===========================================================================================================================================================
Input size (MB): 19.27
Forward/backward pass size (MB): 4786.26
Params size (MB): 31.18
Estimated Total Size (MB): 4836.70
===========================================================================================================================================================</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb45-2">torch.cuda.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb45-3"></span>
<span id="cb45-4">output_shape <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(train_data.classes)</span>
<span id="cb45-5"></span>
<span id="cb45-6">model_1.classifier <span class="op" style="color: #5E5E5E;">=</span> nn.Sequential(</span>
<span id="cb45-7">    nn.Dropout(<span class="fl" style="color: #AD0000;">0.2</span>),</span>
<span id="cb45-8">    nn.Linear(in_features<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1280</span>, out_features<span class="op" style="color: #5E5E5E;">=</span>output_shape, bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb45-9">).to(device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>) </span>
<span id="cb46-2">torch.cuda.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb46-3"></span>
<span id="cb46-4">NUM_EPOCHS <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb46-5"></span>
<span id="cb46-6">loss_fn <span class="op" style="color: #5E5E5E;">=</span> nn.CrossEntropyLoss()</span>
<span id="cb46-7">optimizer <span class="op" style="color: #5E5E5E;">=</span> torch.optim.Adam(params<span class="op" style="color: #5E5E5E;">=</span>model_1.parameters(), lr<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.001</span>)</span>
<span id="cb46-8">accuracy <span class="op" style="color: #5E5E5E;">=</span> Accuracy().to(device)</span>
<span id="cb46-9"></span>
<span id="cb46-10">model_1_results <span class="op" style="color: #5E5E5E;">=</span> train(model_1, train_dl, valid_dl, optimizer, loss_fn, accuracy, epochs<span class="op" style="color: #5E5E5E;">=</span>NUM_EPOCHS)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 1 | train_loss: 1.5270 | train_accuracy: 0.5790 | valid_loss: 0.3069 | valid_accuracy: 0.9281 | 
Epoch: 2 | train_loss: 0.3717 | train_accuracy: 0.8955 | valid_loss: 0.1809 | valid_accuracy: 0.9313 | 
Epoch: 3 | train_loss: 0.1966 | train_accuracy: 0.9451 | valid_loss: 0.1643 | valid_accuracy: 0.9500 | 
Epoch: 4 | train_loss: 0.1269 | train_accuracy: 0.9658 | valid_loss: 0.0710 | valid_accuracy: 0.9875 | 
Epoch: 5 | train_loss: 0.0942 | train_accuracy: 0.9730 | valid_loss: 0.0777 | valid_accuracy: 0.9750 | 
Epoch: 6 | train_loss: 0.0873 | train_accuracy: 0.9751 | valid_loss: 0.1236 | valid_accuracy: 0.9781 | 
Epoch: 7 | train_loss: 0.0633 | train_accuracy: 0.9819 | valid_loss: 0.0655 | valid_accuracy: 0.9781 | 
Epoch: 8 | train_loss: 0.0530 | train_accuracy: 0.9850 | valid_loss: 0.0785 | valid_accuracy: 0.9844 | 
Epoch: 9 | train_loss: 0.0493 | train_accuracy: 0.9845 | valid_loss: 0.1224 | valid_accuracy: 0.9313 | 
Epoch: 10 | train_loss: 0.0466 | train_accuracy: 0.9864 | valid_loss: 0.2084 | valid_accuracy: 0.9125 | </code></pre>
</div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1">plot_loss_curves(model_1_results)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-35-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="with-better-transforms" class="level1">
<h1>With better transforms</h1>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">aug_transforms <span class="op" style="color: #5E5E5E;">=</span> transforms.Compose([</span>
<span id="cb49-2">    transforms.TrivialAugmentWide(<span class="dv" style="color: #AD0000;">20</span>),</span>
<span id="cb49-3">    weights.transforms()</span>
<span id="cb49-4">])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">train_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>train_dir,</span>
<span id="cb50-2">                                  transform<span class="op" style="color: #5E5E5E;">=</span>aug_transforms,</span>
<span id="cb50-3">                                  target_transform<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb50-4"></span>
<span id="cb50-5">valid_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>valid_dir,</span>
<span id="cb50-6">                                  transform<span class="op" style="color: #5E5E5E;">=</span>aug_transforms)</span>
<span id="cb50-7"></span>
<span id="cb50-8">test_data <span class="op" style="color: #5E5E5E;">=</span> datasets.ImageFolder(root<span class="op" style="color: #5E5E5E;">=</span>test_dir,</span>
<span id="cb50-9">                                  transform<span class="op" style="color: #5E5E5E;">=</span>aug_transforms)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">ex <span class="op" style="color: #5E5E5E;">=</span> train_data[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb51-2">plt.imshow(ex.permute(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>))</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f3ae1af8b50&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-38-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">train_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>train_data,</span>
<span id="cb54-2">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb54-3">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb54-4"></span>
<span id="cb54-5">valid_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>valid_data,</span>
<span id="cb54-6">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb54-7">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb54-8"></span>
<span id="cb54-9">test_dl <span class="op" style="color: #5E5E5E;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;">=</span>test_data,</span>
<span id="cb54-10">                     batch_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb54-11">                     shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">model_2 <span class="op" style="color: #5E5E5E;">=</span> torchvision.models.efficientnet_b1(weights<span class="op" style="color: #5E5E5E;">=</span>weights).to(device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">summary(model_2, input_size<span class="op" style="color: #5E5E5E;">=</span> (<span class="dv" style="color: #AD0000;">32</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">224</span>, <span class="dv" style="color: #AD0000;">224</span>), col_names<span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"input_size"</span>, <span class="st" style="color: #20794D;">"output_size"</span>, <span class="st" style="color: #20794D;">"num_params"</span>, <span class="st" style="color: #20794D;">"trainable"</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>===========================================================================================================================================================
Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable
===========================================================================================================================================================
EfficientNet                                            [32, 3, 224, 224]         [32, 1000]                --                        True
Sequential: 1-1                                       [32, 3, 224, 224]         [32, 1280, 7, 7]          --                        True
    Conv2dNormActivation: 2-1                        [32, 3, 224, 224]         [32, 32, 112, 112]        --                        True
        Conv2d: 3-1                                 [32, 3, 224, 224]         [32, 32, 112, 112]        864                       True
        BatchNorm2d: 3-2                            [32, 32, 112, 112]        [32, 32, 112, 112]        64                        True
        SiLU: 3-3                                   [32, 32, 112, 112]        [32, 32, 112, 112]        --                        --
    Sequential: 2-2                                  [32, 32, 112, 112]        [32, 16, 112, 112]        --                        True
        MBConv: 3-4                                 [32, 32, 112, 112]        [32, 16, 112, 112]        1,448                     True
        MBConv: 3-5                                 [32, 16, 112, 112]        [32, 16, 112, 112]        612                       True
    Sequential: 2-3                                  [32, 16, 112, 112]        [32, 24, 56, 56]          --                        True
        MBConv: 3-6                                 [32, 16, 112, 112]        [32, 24, 56, 56]          6,004                     True
        MBConv: 3-7                                 [32, 24, 56, 56]          [32, 24, 56, 56]          10,710                    True
        MBConv: 3-8                                 [32, 24, 56, 56]          [32, 24, 56, 56]          10,710                    True
    Sequential: 2-4                                  [32, 24, 56, 56]          [32, 40, 28, 28]          --                        True
        MBConv: 3-9                                 [32, 24, 56, 56]          [32, 40, 28, 28]          15,350                    True
        MBConv: 3-10                                [32, 40, 28, 28]          [32, 40, 28, 28]          31,290                    True
        MBConv: 3-11                                [32, 40, 28, 28]          [32, 40, 28, 28]          31,290                    True
    Sequential: 2-5                                  [32, 40, 28, 28]          [32, 80, 14, 14]          --                        True
        MBConv: 3-12                                [32, 40, 28, 28]          [32, 80, 14, 14]          37,130                    True
        MBConv: 3-13                                [32, 80, 14, 14]          [32, 80, 14, 14]          102,900                   True
        MBConv: 3-14                                [32, 80, 14, 14]          [32, 80, 14, 14]          102,900                   True
        MBConv: 3-15                                [32, 80, 14, 14]          [32, 80, 14, 14]          102,900                   True
    Sequential: 2-6                                  [32, 80, 14, 14]          [32, 112, 14, 14]         --                        True
        MBConv: 3-16                                [32, 80, 14, 14]          [32, 112, 14, 14]         126,004                   True
        MBConv: 3-17                                [32, 112, 14, 14]         [32, 112, 14, 14]         208,572                   True
        MBConv: 3-18                                [32, 112, 14, 14]         [32, 112, 14, 14]         208,572                   True
        MBConv: 3-19                                [32, 112, 14, 14]         [32, 112, 14, 14]         208,572                   True
    Sequential: 2-7                                  [32, 112, 14, 14]         [32, 192, 7, 7]           --                        True
        MBConv: 3-20                                [32, 112, 14, 14]         [32, 192, 7, 7]           262,492                   True
        MBConv: 3-21                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
        MBConv: 3-22                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
        MBConv: 3-23                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
        MBConv: 3-24                                [32, 192, 7, 7]           [32, 192, 7, 7]           587,952                   True
    Sequential: 2-8                                  [32, 192, 7, 7]           [32, 320, 7, 7]           --                        True
        MBConv: 3-25                                [32, 192, 7, 7]           [32, 320, 7, 7]           717,232                   True
        MBConv: 3-26                                [32, 320, 7, 7]           [32, 320, 7, 7]           1,563,600                 True
    Conv2dNormActivation: 2-9                        [32, 320, 7, 7]           [32, 1280, 7, 7]          --                        True
        Conv2d: 3-27                                [32, 320, 7, 7]           [32, 1280, 7, 7]          409,600                   True
        BatchNorm2d: 3-28                           [32, 1280, 7, 7]          [32, 1280, 7, 7]          2,560                     True
        SiLU: 3-29                                  [32, 1280, 7, 7]          [32, 1280, 7, 7]          --                        --
AdaptiveAvgPool2d: 1-2                                [32, 1280, 7, 7]          [32, 1280, 1, 1]          --                        --
Sequential: 1-3                                       [32, 1280]                [32, 1000]                --                        True
    Dropout: 2-10                                    [32, 1280]                [32, 1280]                --                        --
    Linear: 2-11                                     [32, 1280]                [32, 1000]                1,281,000                 True
===========================================================================================================================================================
Total params: 7,794,184
Trainable params: 7,794,184
Non-trainable params: 0
Total mult-adds (G): 18.23
===========================================================================================================================================================
Input size (MB): 19.27
Forward/backward pass size (MB): 4786.26
Params size (MB): 31.18
Estimated Total Size (MB): 4836.70
===========================================================================================================================================================</code></pre>
</div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">model_2.classifier <span class="op" style="color: #5E5E5E;">=</span> nn.Sequential(</span>
<span id="cb58-2">    nn.Dropout(p<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>, inplace<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>),</span>
<span id="cb58-3">    nn.Linear(<span class="dv" style="color: #AD0000;">1280</span>, out_features<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">len</span>(train_data.classes), bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb58-4">).to(device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>) </span>
<span id="cb59-2">torch.cuda.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb59-3"></span>
<span id="cb59-4">NUM_EPOCHS <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb59-5"></span>
<span id="cb59-6">loss_fn <span class="op" style="color: #5E5E5E;">=</span> nn.CrossEntropyLoss()</span>
<span id="cb59-7">optimizer <span class="op" style="color: #5E5E5E;">=</span> torch.optim.Adam(params<span class="op" style="color: #5E5E5E;">=</span>model_2.parameters(), lr<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.001</span>)</span>
<span id="cb59-8">accuracy <span class="op" style="color: #5E5E5E;">=</span> Accuracy().to(device)</span>
<span id="cb59-9"></span>
<span id="cb59-10">model_2_results <span class="op" style="color: #5E5E5E;">=</span> train(model_2, train_dl, valid_dl, optimizer, loss_fn, accuracy, epochs<span class="op" style="color: #5E5E5E;">=</span>NUM_EPOCHS)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 1 | train_loss: 1.8372 | train_accuracy: 0.4671 | valid_loss: 0.8242 | valid_accuracy: 0.7656 | 
Epoch: 2 | train_loss: 0.6671 | train_accuracy: 0.8002 | valid_loss: 0.2849 | valid_accuracy: 0.9281 | 
Epoch: 3 | train_loss: 0.4505 | train_accuracy: 0.8617 | valid_loss: 0.2810 | valid_accuracy: 0.8750 | 
Epoch: 4 | train_loss: 0.3458 | train_accuracy: 0.8985 | valid_loss: 0.2187 | valid_accuracy: 0.9563 | 
Epoch: 5 | train_loss: 0.2995 | train_accuracy: 0.9148 | valid_loss: 0.1778 | valid_accuracy: 0.9625 | </code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">plot_loss_curves(model_2_results)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-44-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> List, Tuple</span>
<span id="cb62-2"></span>
<span id="cb62-3"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span>
<span id="cb62-4"></span>
<span id="cb62-5"><span class="kw" style="color: #003B4F;">def</span> pred_and_plot_image(model: torch.nn.Module,</span>
<span id="cb62-6">                        image_path: <span class="bu" style="color: null;">str</span>, </span>
<span id="cb62-7">                        class_names: List[<span class="bu" style="color: null;">str</span>],</span>
<span id="cb62-8">                        image_size: Tuple[<span class="bu" style="color: null;">int</span>, <span class="bu" style="color: null;">int</span>] <span class="op" style="color: #5E5E5E;">=</span> (<span class="dv" style="color: #AD0000;">224</span>, <span class="dv" style="color: #AD0000;">224</span>),</span>
<span id="cb62-9">                        transform: torchvision.transforms <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb62-10">                        device: torch.device<span class="op" style="color: #5E5E5E;">=</span>device):</span>
<span id="cb62-11">    </span>
<span id="cb62-12">    img <span class="op" style="color: #5E5E5E;">=</span> Image.<span class="bu" style="color: null;">open</span>(image_path)</span>
<span id="cb62-13"></span>
<span id="cb62-14">    <span class="cf" style="color: #003B4F;">if</span> transform <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb62-15">        image_transform <span class="op" style="color: #5E5E5E;">=</span> transform</span>
<span id="cb62-16">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb62-17">        image_transform <span class="op" style="color: #5E5E5E;">=</span> transforms.Compose([</span>
<span id="cb62-18">            transforms.Resize(image_size),</span>
<span id="cb62-19">            transforms.ToTensor(),</span>
<span id="cb62-20">            transforms.Normalize(mean<span class="op" style="color: #5E5E5E;">=</span>[<span class="fl" style="color: #AD0000;">0.485</span>, <span class="fl" style="color: #AD0000;">0.456</span>, <span class="fl" style="color: #AD0000;">0.406</span>],</span>
<span id="cb62-21">                                 std<span class="op" style="color: #5E5E5E;">=</span>[<span class="fl" style="color: #AD0000;">0.229</span>, <span class="fl" style="color: #AD0000;">0.224</span>, <span class="fl" style="color: #AD0000;">0.225</span>]),</span>
<span id="cb62-22">        ])</span>
<span id="cb62-23"></span>
<span id="cb62-24">    model.to(device)</span>
<span id="cb62-25"></span>
<span id="cb62-26">    model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb62-27">    <span class="cf" style="color: #003B4F;">with</span> torch.inference_mode():</span>
<span id="cb62-28">        transformed_image <span class="op" style="color: #5E5E5E;">=</span> image_transform(img).unsqueeze(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb62-29"></span>
<span id="cb62-30">        target_image_pred <span class="op" style="color: #5E5E5E;">=</span> model(transformed_image.to(device))</span>
<span id="cb62-31"></span>
<span id="cb62-32">    target_image_pred_probs <span class="op" style="color: #5E5E5E;">=</span> torch.softmax(target_image_pred, dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb62-33"></span>
<span id="cb62-34">    target_image_pred_label <span class="op" style="color: #5E5E5E;">=</span> torch.argmax(target_image_pred_probs, dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb62-35"></span>
<span id="cb62-36">    plt.figure()</span>
<span id="cb62-37">    plt.imshow(img)</span>
<span id="cb62-38">    plt.title(<span class="ss" style="color: #20794D;">f"Pred: </span><span class="sc" style="color: #5E5E5E;">{</span>class_names[target_image_pred_label]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> | Prob: </span><span class="sc" style="color: #5E5E5E;">{</span>target_image_pred_probs<span class="sc" style="color: #5E5E5E;">.</span><span class="bu" style="color: null;">max</span>()<span class="sc" style="color: #5E5E5E;">:.3f}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb62-39">    plt.axis(<span class="va" style="color: #111111;">False</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><span class="co" style="color: #5E5E5E;"># Get a random list of image paths from test set</span></span>
<span id="cb63-2"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb63-3">num_images_to_plot <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb63-4">test_image_path_list <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">list</span>(Path(test_dir).glob(<span class="st" style="color: #20794D;">"*/*.jpg"</span>)) <span class="co" style="color: #5E5E5E;"># get list all image paths from test data </span></span>
<span id="cb63-5">test_image_path_sample <span class="op" style="color: #5E5E5E;">=</span> random.sample(population<span class="op" style="color: #5E5E5E;">=</span>test_image_path_list, <span class="co" style="color: #5E5E5E;"># go through all of the test image paths</span></span>
<span id="cb63-6">                                       k<span class="op" style="color: #5E5E5E;">=</span>num_images_to_plot) <span class="co" style="color: #5E5E5E;"># randomly select 'k' image paths to pred and plot</span></span>
<span id="cb63-7"></span>
<span id="cb63-8"><span class="co" style="color: #5E5E5E;"># Make predictions on and plot the images</span></span>
<span id="cb63-9"><span class="cf" style="color: #003B4F;">for</span> image_path <span class="kw" style="color: #003B4F;">in</span> test_image_path_sample:</span>
<span id="cb63-10">    pred_and_plot_image(model<span class="op" style="color: #5E5E5E;">=</span>model_2, </span>
<span id="cb63-11">                        image_path<span class="op" style="color: #5E5E5E;">=</span>image_path,</span>
<span id="cb63-12">                        class_names<span class="op" style="color: #5E5E5E;">=</span>class_names,</span>
<span id="cb63-13">                        <span class="co" style="color: #5E5E5E;"># transform=weights.transforms(), # optionally pass in a specified transform from our pretrained model weights</span></span>
<span id="cb63-14">                        image_size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">224</span>, <span class="dv" style="color: #AD0000;">224</span>))</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-46-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-46-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Counting Cards/counting_cards_files/figure-html/cell-46-output-3.png" class="img-fluid"></p>
</div>
</div>


</section>

 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <category>Computer Vision</category>
  <guid>https://jakegehri.github.io/projects/Counting Cards/counting_cards.html</guid>
  <pubDate>Wed, 16 Nov 2022 05:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/Counting Cards/playing_card_games.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>DNN From Scratch: The nuts and bolts</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/DNN From Scratch/no_hands.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch.nn.functional <span class="im" style="color: #00769E;">as</span> F</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> fastai <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> fastbook <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">data <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(<span class="st" style="color: #20794D;">'train.csv'</span>)</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="43">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">data.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="44">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">data.isna().<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">modes <span class="op" style="color: #5E5E5E;">=</span> data.mode().iloc[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb6-2">modes</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>PassengerId                      1
Survived                       0.0
Pclass                         3.0
Name           Abbing, Mr. Anthony
Sex                           male
Age                           24.0
SibSp                          0.0
Parch                          0.0
Ticket                        1601
Fare                          8.05
Cabin                      B96 B98
Embarked                         S
Name: 0, dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">data.fillna(modes, inplace<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">data.isna().<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>PassengerId    0
Survived       0
Pclass         0
Name           0
Sex            0
Age            0
SibSp          0
Parch          0
Ticket         0
Fare           0
Cabin          0
Embarked       0
dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">data.describe(include<span class="op" style="color: #5E5E5E;">=</span>(np.number))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>446.000000</td>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>28.566970</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>257.353842</td>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>13.199572</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>223.500000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>22.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>446.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>24.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>668.500000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>35.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>891.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">data.describe(include<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">object</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Name</th>
      <th>Sex</th>
      <th>Ticket</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891</td>
      <td>891</td>
      <td>891</td>
      <td>891</td>
      <td>891</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>891</td>
      <td>2</td>
      <td>681</td>
      <td>147</td>
      <td>3</td>
    </tr>
    <tr>
      <th>top</th>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>347082</td>
      <td>B96 B98</td>
      <td>S</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>1</td>
      <td>577</td>
      <td>7</td>
      <td>691</td>
      <td>646</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">data[<span class="st" style="color: #20794D;">'Fare'</span>].hist()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>&lt;AxesSubplot:&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/DNN From Scratch/no_hands_files/figure-html/cell-11-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">data[<span class="st" style="color: #20794D;">'LogFare'</span>] <span class="op" style="color: #5E5E5E;">=</span> np.log(data[<span class="st" style="color: #20794D;">'Fare'</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">data.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>LogFare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>B96 B98</td>
      <td>S</td>
      <td>2.110213</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>4.280593</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>B96 B98</td>
      <td>S</td>
      <td>2.188856</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
      <td>3.990834</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>B96 B98</td>
      <td>S</td>
      <td>2.202765</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">data <span class="op" style="color: #5E5E5E;">=</span> pd.get_dummies(data, columns <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'Pclass'</span>, <span class="st" style="color: #20794D;">'Sex'</span>, <span class="st" style="color: #20794D;">'Embarked'</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">data.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Name</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>LogFare</th>
      <th>Pclass_1</th>
      <th>Pclass_2</th>
      <th>Pclass_3</th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>B96 B98</td>
      <td>2.110213</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>4.280593</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>B96 B98</td>
      <td>2.188856</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>3.990834</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>Allen, Mr. William Henry</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>B96 B98</td>
      <td>2.202765</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">dep_var <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'Survived'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">indep_vars <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'Age'</span>, <span class="st" style="color: #20794D;">'SibSp'</span>, <span class="st" style="color: #20794D;">'Parch'</span>, <span class="st" style="color: #20794D;">'LogFare'</span>, <span class="st" style="color: #20794D;">'Pclass_1'</span>, <span class="st" style="color: #20794D;">'Pclass_2'</span>, <span class="st" style="color: #20794D;">'Pclass_3'</span>, <span class="st" style="color: #20794D;">'Sex_female'</span>, <span class="st" style="color: #20794D;">'Sex_male'</span>, <span class="st" style="color: #20794D;">'Embarked_C'</span>, <span class="st" style="color: #20794D;">'Embarked_Q'</span>, <span class="st" style="color: #20794D;">'Embarked_S'</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="bu" style="color: null;">len</span>(indep_vars)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>12</code></pre>
</div>
</div>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">y <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(data[dep_var].values, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.<span class="bu" style="color: null;">float</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">X <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(data[indep_vars].values, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.<span class="bu" style="color: null;">float</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">vals, indicies <span class="op" style="color: #5E5E5E;">=</span> X.<span class="bu" style="color: null;">max</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">X <span class="op" style="color: #5E5E5E;">=</span> X <span class="op" style="color: #5E5E5E;">/</span> vals</span></code></pre></div>
</div>
<div class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">trn_split, val_split <span class="op" style="color: #5E5E5E;">=</span> RandomSplitter(seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span>)(X)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="bu" style="color: null;">len</span>(trn_split), <span class="bu" style="color: null;">len</span>(val_split)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>(713, 178)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="184">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">X_train, y_train <span class="op" style="color: #5E5E5E;">=</span> X[trn_split], y[trn_split]</span>
<span id="cb30-2">X_val, y_val <span class="op" style="color: #5E5E5E;">=</span> X[val_split], y[val_split]</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="145">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">nips <span class="op" style="color: #5E5E5E;">=</span> X_train.shape[<span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="466">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb32-2"></span>
<span id="cb32-3"><span class="kw" style="color: #003B4F;">def</span> get_coeffs(nips <span class="op" style="color: #5E5E5E;">=</span> nips, l1_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">20</span>, n_classes <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>):</span>
<span id="cb32-4">    layer1 <span class="op" style="color: #5E5E5E;">=</span> (torch.rand(nips, l1_size)<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.5</span>) <span class="op" style="color: #5E5E5E;">/</span> nips</span>
<span id="cb32-5">    layer2 <span class="op" style="color: #5E5E5E;">=</span> (torch.rand(l1_size, n_classes)<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.5</span>)</span>
<span id="cb32-6">    const <span class="op" style="color: #5E5E5E;">=</span> torch.rand(<span class="dv" style="color: #AD0000;">1</span>)[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb32-7">    <span class="cf" style="color: #003B4F;">return</span> layer1.requires_grad_(), layer2.requires_grad_(), const.requires_grad_()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="467">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;">def</span> forward_pass(coeffs, X_train):</span>
<span id="cb33-2">    l1, l2, const <span class="op" style="color: #5E5E5E;">=</span> coeffs</span>
<span id="cb33-3">    acts <span class="op" style="color: #5E5E5E;">=</span> F.relu(X_train<span class="op" style="color: #5E5E5E;">@</span>l1)</span>
<span id="cb33-4">    acts <span class="op" style="color: #5E5E5E;">=</span> acts<span class="op" style="color: #5E5E5E;">@</span>l2 <span class="op" style="color: #5E5E5E;">+</span> const</span>
<span id="cb33-5">    <span class="cf" style="color: #003B4F;">return</span> torch.sigmoid(acts)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="468">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="kw" style="color: #003B4F;">def</span> calc_loss(acts, y_train): <span class="cf" style="color: #003B4F;">return</span> torch.<span class="bu" style="color: null;">abs</span>(acts <span class="op" style="color: #5E5E5E;">-</span> y_train).mean()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="469">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="kw" style="color: #003B4F;">def</span> backprop(coeffs, lr):</span>
<span id="cb35-2">    <span class="cf" style="color: #003B4F;">for</span> layer <span class="kw" style="color: #003B4F;">in</span> coeffs:</span>
<span id="cb35-3">        layer.sub_(layer.grad <span class="op" style="color: #5E5E5E;">*</span> lr)</span>
<span id="cb35-4">        layer.grad.zero_()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="470">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="kw" style="color: #003B4F;">def</span> one_epoch(coeffs, lr):</span>
<span id="cb36-2">    acts <span class="op" style="color: #5E5E5E;">=</span> forward_pass(coeffs, X_train)</span>
<span id="cb36-3">    loss <span class="op" style="color: #5E5E5E;">=</span> calc_loss(acts, y_train)</span>
<span id="cb36-4">    loss.backward()</span>
<span id="cb36-5">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): backprop(coeffs, lr)</span>
<span id="cb36-6">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>loss<span class="sc" style="color: #5E5E5E;">:.3f}</span><span class="ss" style="color: #20794D;">"</span>, end <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"; "</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="kw" style="color: #003B4F;">def</span> acc(coeffs): <span class="cf" style="color: #003B4F;">return</span> (y_val.<span class="bu" style="color: null;">bool</span>()<span class="op" style="color: #5E5E5E;">==</span>(forward_pass(coeffs, X_val)<span class="op" style="color: #5E5E5E;">&gt;</span><span class="fl" style="color: #AD0000;">0.5</span>)).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="487">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="kw" style="color: #003B4F;">def</span> train_model(epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>, lr<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>):</span>
<span id="cb38-2">    torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb38-3">    coeffs <span class="op" style="color: #5E5E5E;">=</span> get_coeffs()</span>
<span id="cb38-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(epochs): one_epoch(coeffs, lr)</span>
<span id="cb38-5">    <span class="cf" style="color: #003B4F;">return</span> coeffs, acc(coeffs)</span>
<span id="cb38-6">    </span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="490">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">_, acc <span class="op" style="color: #5E5E5E;">=</span> train_model()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.548; 0.529; 0.503; 0.466; 0.408; 0.357; 0.330; 0.313; 0.298; 0.286; 0.277; 0.269; 0.261; 0.255; 0.249; 0.244; 0.239; 0.235; 0.231; 0.229; 0.226; 0.224; 0.222; 0.220; 0.219; 0.217; 0.216; 0.215; 0.214; 0.213; 0.212; 0.211; 0.211; 0.210; 0.209; 0.209; 0.208; 0.207; 0.207; 0.206; 0.206; 0.205; 0.205; 0.204; 0.204; 0.204; 0.203; 0.203; 0.203; 0.202; </code></pre>
</div>
</div>
<div class="cell" data-execution_count="491">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">acc</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="491">
<pre><code>tensor(0.8258)</code></pre>
</div>
</div>



 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <guid>https://jakegehri.github.io/projects/DNN From Scratch/no_hands.html</guid>
  <pubDate>Tue, 01 Nov 2022 04:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/DNN From Scratch/DNN_From_Scratch.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Multi-label Classification of Amazonian Land Space</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/Amazon/amazon.html</link>
  <description><![CDATA[ 



<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> pandoc</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> fastbook <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> fastai <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">creds <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'{"username":"jakegehri","key":"3d0213a52bd1816d21037e941bc77569"}'</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># Creates a cred path for kaggle datasets to be downloaded in comand line</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">cred_path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'~/.kaggle/kaggle.json'</span>).expanduser() </span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> cred_path.exists():</span>
<span id="cb3-6">    cred_path.parent.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-7">    cred_path.write_text(creds)</span>
<span id="cb3-8">    cred_path.chmod(<span class="bn" style="color: #AD0000;">0o600</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'./planet/planet'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">path.ls()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="140">
<pre><code>(#4) [Path('planet/planet/train_classes.csv'),Path('planet/planet/test-jpg'),Path('planet/planet/sample_submission.csv'),Path('planet/planet/train-jpg')]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">train <span class="op" style="color: #5E5E5E;">=</span> (path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'train-jpg'</span>).ls()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">train</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(#40479) [Path('planet/planet/train-jpg/train_19921.jpg'),Path('planet/planet/train-jpg/train_24619.jpg'),Path('planet/planet/train-jpg/train_21510.jpg'),Path('planet/planet/train-jpg/train_31089.jpg'),Path('planet/planet/train-jpg/train_33277.jpg'),Path('planet/planet/train-jpg/train_11172.jpg'),Path('planet/planet/train-jpg/train_14671.jpg'),Path('planet/planet/train-jpg/train_29521.jpg'),Path('planet/planet/train-jpg/train_27535.jpg'),Path('planet/planet/train-jpg/train_13323.jpg')...]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">data <span class="op" style="color: #5E5E5E;">=</span> (path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'train_classes.csv'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">df <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(data)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>image_name</th>
      <th>tags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>train_0</td>
      <td>haze primary</td>
    </tr>
    <tr>
      <th>1</th>
      <td>train_1</td>
      <td>agriculture clear primary water</td>
    </tr>
    <tr>
      <th>2</th>
      <td>train_2</td>
      <td>clear primary</td>
    </tr>
    <tr>
      <th>3</th>
      <td>train_3</td>
      <td>clear primary</td>
    </tr>
    <tr>
      <th>4</th>
      <td>train_4</td>
      <td>agriculture clear habitation primary road</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">dblock <span class="op" style="color: #5E5E5E;">=</span> DataBlock()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">dsets <span class="op" style="color: #5E5E5E;">=</span> dblock.datasets(df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">dsets[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(image_name         train_0
 tags          haze primary
 Name: 0, dtype: object,
 image_name         train_0
 tags          haze primary
 Name: 0, dtype: object)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;">def</span> get_x(r): <span class="cf" style="color: #003B4F;">return</span> path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'train-jpg'</span><span class="op" style="color: #5E5E5E;">/</span>(r[<span class="st" style="color: #20794D;">'image_name'</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'.jpg'</span>)</span>
<span id="cb17-2"><span class="kw" style="color: #003B4F;">def</span> get_y(r): <span class="cf" style="color: #003B4F;">return</span> r[<span class="st" style="color: #20794D;">'tags'</span>].split(<span class="st" style="color: #20794D;">' '</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">dblock <span class="op" style="color: #5E5E5E;">=</span> DataBlock(get_x<span class="op" style="color: #5E5E5E;">=</span>get_x, get_y<span class="op" style="color: #5E5E5E;">=</span>get_y)</span>
<span id="cb18-2">dsets <span class="op" style="color: #5E5E5E;">=</span> dblock.datasets(df)</span>
<span id="cb18-3">dsets.train[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(Path('planet/planet/train-jpg/train_1398.jpg'),
 ['agriculture', 'partly_cloudy', 'primary', 'road'])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">dblock <span class="op" style="color: #5E5E5E;">=</span> DataBlock(blocks <span class="op" style="color: #5E5E5E;">=</span> (ImageBlock, MultiCategoryBlock), </span>
<span id="cb20-2">                   get_x<span class="op" style="color: #5E5E5E;">=</span>get_x, get_y<span class="op" style="color: #5E5E5E;">=</span>get_y)</span>
<span id="cb20-3"></span>
<span id="cb20-4">dsets <span class="op" style="color: #5E5E5E;">=</span> dblock.datasets(df)</span>
<span id="cb20-5">dsets.train[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(PILImage mode=RGB size=256x256,
 TensorMultiCategory([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">dblock <span class="op" style="color: #5E5E5E;">=</span> DataBlock(blocks <span class="op" style="color: #5E5E5E;">=</span> (ImageBlock, MultiCategoryBlock), </span>
<span id="cb22-2">                   splitter<span class="op" style="color: #5E5E5E;">=</span>RandomSplitter(seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span>),</span>
<span id="cb22-3">                   get_x<span class="op" style="color: #5E5E5E;">=</span>get_x, get_y<span class="op" style="color: #5E5E5E;">=</span>get_y)</span>
<span id="cb22-4"></span>
<span id="cb22-5">dsets <span class="op" style="color: #5E5E5E;">=</span> dblock.datasets(df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="bu" style="color: null;">len</span>(dsets.train), <span class="bu" style="color: null;">len</span>(dsets.valid)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>(32384, 8095)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">dblock <span class="op" style="color: #5E5E5E;">=</span> DataBlock(blocks <span class="op" style="color: #5E5E5E;">=</span> (ImageBlock, MultiCategoryBlock), </span>
<span id="cb25-2">                   splitter<span class="op" style="color: #5E5E5E;">=</span>RandomSplitter(seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span>),</span>
<span id="cb25-3">                   get_x<span class="op" style="color: #5E5E5E;">=</span>get_x, get_y<span class="op" style="color: #5E5E5E;">=</span>get_y,</span>
<span id="cb25-4">                   item_tfms<span class="op" style="color: #5E5E5E;">=</span>RandomResizedCrop(<span class="dv" style="color: #AD0000;">128</span>, min_scale<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.35</span>)</span>
<span id="cb25-5">                  </span>
<span id="cb25-6">)</span>
<span id="cb25-7"></span>
<span id="cb25-8">dls <span class="op" style="color: #5E5E5E;">=</span> dblock.dataloaders(df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">dls.show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Amazon/amazon_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="experiment-1" class="level1">
<h1>Experiment 1</h1>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, resnet18, metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy_multi)</span>
<span id="cb27-2">learn.fine_tune(<span class="dv" style="color: #AD0000;">6</span>, freeze_epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb27-3">learn.recorder.plot_loss()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e34f27f2cd9d4a99b3d97cf3521daafb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.242502</td>
      <td>0.150174</td>
      <td>0.945827</td>
      <td>00:25</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.147816</td>
      <td>0.126972</td>
      <td>0.951968</td>
      <td>00:20</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.127971</td>
      <td>0.109930</td>
      <td>0.957991</td>
      <td>00:23</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.119986</td>
      <td>0.104264</td>
      <td>0.960476</td>
      <td>00:23</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.109712</td>
      <td>0.098336</td>
      <td>0.962301</td>
      <td>00:38</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.104570</td>
      <td>0.097734</td>
      <td>0.962555</td>
      <td>00:49</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</section>
<section id="experiment-2" class="level1">
<h1>Experiment 2</h1>
<div class="cell" data-execution_count="277">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">learn2 <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, resnet34, metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy_multi)</span>
<span id="cb29-2">learn2.fine_tune(<span class="dv" style="color: #AD0000;">6</span>, freeze_epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb29-3">learn2.recorder.plot_loss()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.244604</td>
      <td>0.147677</td>
      <td>0.947447</td>
      <td>00:51</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.148016</td>
      <td>0.123402</td>
      <td>0.953312</td>
      <td>00:25</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.123248</td>
      <td>0.106454</td>
      <td>0.959452</td>
      <td>00:59</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.118266</td>
      <td>0.104211</td>
      <td>0.960942</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.111732</td>
      <td>0.098766</td>
      <td>0.962381</td>
      <td>00:42</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.105815</td>
      <td>0.096162</td>
      <td>0.963245</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.099851</td>
      <td>0.094583</td>
      <td>0.964037</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.093574</td>
      <td>0.095035</td>
      <td>0.963848</td>
      <td>00:34</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Amazon/amazon_files/figure-html/cell-23-output-5.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="experiment-3" class="level1">
<h1>Experiment 3</h1>
<div class="cell" data-execution_count="270">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">learn3 <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, resnet34, metrics<span class="op" style="color: #5E5E5E;">=</span>partial(accuracy_multi, thresh<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>))</span>
<span id="cb30-2">learn3.fine_tune(<span class="dv" style="color: #AD0000;">6</span>, freeze_epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb30-3">learn3.recorder.plot_loss()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.240184</td>
      <td>0.151341</td>
      <td>0.934862</td>
      <td>00:38</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.151022</td>
      <td>0.122403</td>
      <td>0.939382</td>
      <td>00:27</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.124375</td>
      <td>0.106883</td>
      <td>0.950107</td>
      <td>00:35</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.118021</td>
      <td>0.101975</td>
      <td>0.951757</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.109789</td>
      <td>0.099863</td>
      <td>0.952055</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.104578</td>
      <td>0.096811</td>
      <td>0.951851</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.095859</td>
      <td>0.095459</td>
      <td>0.953784</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.092178</td>
      <td>0.095330</td>
      <td>0.954445</td>
      <td>01:02</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Amazon/amazon_files/figure-html/cell-24-output-5.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="experiment-4" class="level1">
<h1>Experiment 4</h1>
<div class="cell" data-execution_count="275">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">learn4 <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, resnet34, metrics<span class="op" style="color: #5E5E5E;">=</span>partial(accuracy_multi, thresh<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.7</span>))</span>
<span id="cb31-2">learn4.fine_tune(<span class="dv" style="color: #AD0000;">6</span>, freeze_epochs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb31-3">learn4.recorder.plot_loss()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.248779</td>
      <td>0.148406</td>
      <td>0.942892</td>
      <td>00:52</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.147272</td>
      <td>0.123920</td>
      <td>0.950325</td>
      <td>00:37</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.125626</td>
      <td>0.109230</td>
      <td>0.955863</td>
      <td>00:48</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.118446</td>
      <td>0.103957</td>
      <td>0.956015</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.112594</td>
      <td>0.099723</td>
      <td>0.958754</td>
      <td>00:37</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.106374</td>
      <td>0.096328</td>
      <td>0.958689</td>
      <td>00:51</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.099089</td>
      <td>0.094283</td>
      <td>0.960499</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.095276</td>
      <td>0.094695</td>
      <td>0.961879</td>
      <td>00:39</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Amazon/amazon_files/figure-html/cell-25-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="278">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">test_dl <span class="op" style="color: #5E5E5E;">=</span> learn2.dls.test_dl(get_image_files(path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'test-jpg'</span>))</span>
<span id="cb32-2">test_dl.show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Amazon/amazon_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="279">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">preds, _ <span class="op" style="color: #5E5E5E;">=</span> learn2.get_preds(dl<span class="op" style="color: #5E5E5E;">=</span>test_dl)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
<div class="cell" data-execution_count="280">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">thresh <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span></span>
<span id="cb34-2">labelled_preds <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">' '</span>.join([learn2.dls.vocab[i] <span class="cf" style="color: #003B4F;">for</span> i,p <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(pred) <span class="cf" style="color: #003B4F;">if</span> p <span class="op" style="color: #5E5E5E;">&gt;</span> thresh]) <span class="cf" style="color: #003B4F;">for</span> pred <span class="kw" style="color: #003B4F;">in</span> preds]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="281">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">labelled_preds[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="281">
<pre><code>['agriculture clear primary road',
 'bare_ground clear',
 'clear primary',
 'clear primary',
 'clear primary']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="282">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">fnames <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb37-2"></span>
<span id="cb37-3"><span class="cf" style="color: #003B4F;">for</span> name <span class="kw" style="color: #003B4F;">in</span> os.listdir((path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'test-jpg'</span>)):</span>
<span id="cb37-4">    fnames.append(name)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="283">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">fnames[<span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="283">
<pre><code>['test_36099.jpg',
 'test_27503.jpg',
 'test_15453.jpg',
 'test_20695.jpg',
 'test_5439.jpg']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="284">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">learn2.predict((path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'test-jpg'</span><span class="op" style="color: #5E5E5E;">/</span>(fnames[<span class="dv" style="color: #AD0000;">0</span>])))</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="284">
<pre><code>((#4) ['agriculture','clear','primary','road'],
 TensorBase([ True, False, False, False, False,  True, False, False, False, False, False, False,  True,  True, False, False, False]),
 TensorBase([9.0538e-01, 3.7246e-04, 4.8710e-02, 5.2741e-04, 2.3139e-04, 9.9834e-01, 1.1549e-05, 2.1592e-04, 2.8083e-01, 2.6772e-01, 1.3102e-03, 5.9414e-04, 9.9820e-01, 7.1026e-01, 3.3888e-03,
             1.9953e-02, 1.1821e-01]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="285">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">sample <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'sample_submission.csv'</span>)</span>
<span id="cb42-2">sample</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="285">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>image_name</th>
      <th>tags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>test_0</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>1</th>
      <td>test_1</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>2</th>
      <td>test_2</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>3</th>
      <td>test_3</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>4</th>
      <td>test_4</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>61186</th>
      <td>file_9995</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>61187</th>
      <td>file_9996</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>61188</th>
      <td>file_9997</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>61189</th>
      <td>file_9998</td>
      <td>primary clear agriculture road water</td>
    </tr>
    <tr>
      <th>61190</th>
      <td>file_9999</td>
      <td>primary clear agriculture road water</td>
    </tr>
  </tbody>
</table>
<p>61191 rows  2 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="286">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;">'image_name'</span>:fnames, <span class="st" style="color: #20794D;">'tags'</span>:labelled_preds}, columns<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">'image_name'</span>, <span class="st" style="color: #20794D;">'tags'</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="287">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="287">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>image_name</th>
      <th>tags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>test_36099.jpg</td>
      <td>agriculture clear primary road</td>
    </tr>
    <tr>
      <th>1</th>
      <td>test_27503.jpg</td>
      <td>bare_ground clear</td>
    </tr>
    <tr>
      <th>2</th>
      <td>test_15453.jpg</td>
      <td>clear primary</td>
    </tr>
    <tr>
      <th>3</th>
      <td>test_20695.jpg</td>
      <td>clear primary</td>
    </tr>
    <tr>
      <th>4</th>
      <td>test_5439.jpg</td>
      <td>clear primary</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>40664</th>
      <td>test_12322.jpg</td>
      <td>clear primary water</td>
    </tr>
    <tr>
      <th>40665</th>
      <td>test_10596.jpg</td>
      <td>agriculture partly_cloudy primary road</td>
    </tr>
    <tr>
      <th>40666</th>
      <td>test_567.jpg</td>
      <td>partly_cloudy primary</td>
    </tr>
    <tr>
      <th>40667</th>
      <td>test_23428.jpg</td>
      <td>agriculture clear primary</td>
    </tr>
    <tr>
      <th>40668</th>
      <td>test_10099.jpg</td>
      <td>clear primary</td>
    </tr>
  </tbody>
</table>
<p>40669 rows  2 columns</p>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <category>Computer Vision</category>
  <guid>https://jakegehri.github.io/projects/Amazon/amazon.html</guid>
  <pubDate>Wed, 19 Oct 2022 04:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/Amazon/amazon.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Trail Cam Deer, Elk and Moose Classifier</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/Trailcam/trailcam_model.html</link>
  <description><![CDATA[ 



<div class="cell" data-tags="[]" data-execution_count="191">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> fastbook</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> fastbook <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> fastai.vision.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> fastai.vision.widgets <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> timm</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> duckduckgo_search <span class="im" style="color: #00769E;">import</span> ddg_images</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> time <span class="im" style="color: #00769E;">import</span> sleep</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">import</span> gradio</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="131">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> search_images(term, max_images<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">100</span>):</span>
<span id="cb2-2">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Searching for '</span><span class="sc" style="color: #5E5E5E;">{</span>term<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'"</span>)</span>
<span id="cb2-3">    <span class="cf" style="color: #003B4F;">return</span> L(ddg_images(term, max_results<span class="op" style="color: #5E5E5E;">=</span>max_images)).itemgot(<span class="st" style="color: #20794D;">'image'</span>)</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="132">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">searches <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'moose'</span>, <span class="st" style="color: #20794D;">'deer'</span>, <span class="st" style="color: #20794D;">'elk'</span></span>
<span id="cb3-2">path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'trail_cam'</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> searches:</span>
<span id="cb3-5">    dest <span class="op" style="color: #5E5E5E;">=</span> (path<span class="op" style="color: #5E5E5E;">/</span>o)</span>
<span id="cb3-6">    dest.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, parents<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-7">    download_images(dest, urls <span class="op" style="color: #5E5E5E;">=</span> search_images(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>o<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> trail cam photo'</span>))</span>
<span id="cb3-8">    sleep(<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb3-9">    download_images(dest, urls <span class="op" style="color: #5E5E5E;">=</span> search_images(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>o<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> trail cam photo day'</span>))</span>
<span id="cb3-10">    sleep(<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb3-11">    download_images(dest, urls <span class="op" style="color: #5E5E5E;">=</span> search_images(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>o<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> trail cam photo night'</span>))</span>
<span id="cb3-12">    sleep(<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb3-13">    resize_images(path<span class="op" style="color: #5E5E5E;">/</span>o, max_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">400</span>, dest<span class="op" style="color: #5E5E5E;">=</span>path<span class="op" style="color: #5E5E5E;">/</span>o)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Searching for 'moose trail cam photo'
Searching for 'moose trail cam photo day'
Searching for 'moose trail cam photo night'
Searching for 'deer trail cam photo'
Searching for 'deer trail cam photo day'
Searching for 'deer trail cam photo night'
Searching for 'elk trail cam photo'
Searching for 'elk trail cam photo day'
Searching for 'elk trail cam photo night'</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="133">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">fns <span class="op" style="color: #5E5E5E;">=</span> get_image_files(path)</span>
<span id="cb5-2"><span class="bu" style="color: null;">len</span>(fns)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="133">
<pre><code>877</code></pre>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="134">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">failed <span class="op" style="color: #5E5E5E;">=</span> verify_images(fns)</span>
<span id="cb7-2">failed.<span class="bu" style="color: null;">map</span>(Path.unlink)</span>
<span id="cb7-3">fns <span class="op" style="color: #5E5E5E;">=</span> get_image_files(path)</span>
<span id="cb7-4"><span class="bu" style="color: null;">len</span>(failed), <span class="bu" style="color: null;">len</span>(fns)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="134">
<pre><code>(12, 865)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">os.getcwd()</span>
<span id="cb9-2"><span class="cf" style="color: #003B4F;">for</span> i, filename <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(os.listdir(path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'deer'</span>)):</span>
<span id="cb9-3">   os.rename(<span class="st" style="color: #20794D;">"trail_cam/deer/"</span> <span class="op" style="color: #5E5E5E;">+</span> filename, <span class="st" style="color: #20794D;">"trail_cam/deer/deer_"</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">str</span>(i) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">".jpg"</span>)</span>
<span id="cb9-4"><span class="cf" style="color: #003B4F;">for</span> i, filename <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(os.listdir(path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'moose'</span>)):</span>
<span id="cb9-5">   os.rename(<span class="st" style="color: #20794D;">"trail_cam/moose/"</span> <span class="op" style="color: #5E5E5E;">+</span> filename, <span class="st" style="color: #20794D;">"trail_cam/moose/moose_"</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">str</span>(i) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">".jpg"</span>)</span>
<span id="cb9-6"><span class="cf" style="color: #003B4F;">for</span> i, filename <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(os.listdir(path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'elk'</span>)):</span>
<span id="cb9-7">   os.rename(<span class="st" style="color: #20794D;">"trail_cam/elk/"</span> <span class="op" style="color: #5E5E5E;">+</span> filename, <span class="st" style="color: #20794D;">"trail_cam/elk/elk_"</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">str</span>(i) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">".jpg"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">dls <span class="op" style="color: #5E5E5E;">=</span> ImageDataLoaders.from_name_func(<span class="st" style="color: #20794D;">'.'</span>,</span>
<span id="cb10-2">    get_image_files(path), valid_pct<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>, seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span>,</span>
<span id="cb10-3">    label_func<span class="op" style="color: #5E5E5E;">=</span>RegexLabeller(pat <span class="op" style="color: #5E5E5E;">=</span> <span class="vs" style="color: #20794D;">r'^([^/]+)_\d+'</span>),</span>
<span id="cb10-4">    item_tfms<span class="op" style="color: #5E5E5E;">=</span>Resize(<span class="dv" style="color: #AD0000;">224</span>))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">dls.valid.show_batch(max_n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Trailcam/trailcam_model_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="167">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, resnet34, metrics<span class="op" style="color: #5E5E5E;">=</span>error_rate)</span>
<span id="cb12-2">learn.fine_tune(<span class="dv" style="color: #AD0000;">5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.002779</td>
      <td>1.369467</td>
      <td>0.586207</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.426437</td>
      <td>1.002604</td>
      <td>0.425287</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.082575</td>
      <td>0.859882</td>
      <td>0.413793</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.907559</td>
      <td>0.716293</td>
      <td>0.333333</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.748531</td>
      <td>0.688598</td>
      <td>0.252874</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.647351</td>
      <td>0.693779</td>
      <td>0.264368</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="168">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">interp <span class="op" style="color: #5E5E5E;">=</span> ClassificationInterpretation.from_learner(learn)</span>
<span id="cb13-2">interp.plot_confusion_matrix()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Trailcam/trailcam_model_files/figure-html/cell-11-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="151">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">interp.plot_top_losses(<span class="dv" style="color: #AD0000;">6</span>, nrows<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Trailcam/trailcam_model_files/figure-html/cell-12-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="169">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">cleaner <span class="op" style="color: #5E5E5E;">=</span> ImageClassifierCleaner(learn)</span>
<span id="cb15-2">cleaner</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e2de8fc14094e59a7065d3d76c0ad63","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="170">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="cf" style="color: #003B4F;">for</span> idx <span class="kw" style="color: #003B4F;">in</span> cleaner.delete(): cleaner.fns[idx].unlink()</span>
<span id="cb16-2">    </span>
<span id="cb16-3"><span class="cf" style="color: #003B4F;">for</span> idx,cat <span class="kw" style="color: #003B4F;">in</span> cleaner.change(): shutil.move(<span class="bu" style="color: null;">str</span>(cleaner.fns[idx]), path<span class="op" style="color: #5E5E5E;">/</span>cat)</span>
<span id="cb16-4">    </span>
<span id="cb16-5">dls <span class="op" style="color: #5E5E5E;">=</span> ImageDataLoaders.from_name_func(<span class="st" style="color: #20794D;">'.'</span>,</span>
<span id="cb16-6">    get_image_files(path), valid_pct<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>, seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span>,</span>
<span id="cb16-7">    label_func<span class="op" style="color: #5E5E5E;">=</span>RegexLabeller(pat <span class="op" style="color: #5E5E5E;">=</span> <span class="vs" style="color: #20794D;">r'^([^/]+)_\d+'</span>),</span>
<span id="cb16-8">    item_tfms<span class="op" style="color: #5E5E5E;">=</span>Resize(<span class="dv" style="color: #AD0000;">224</span>))</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="171">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, <span class="st" style="color: #20794D;">'convnext_tiny_in22k'</span>, metrics<span class="op" style="color: #5E5E5E;">=</span>error_rate).to_fp16()</span>
<span id="cb17-2">learn.fine_tune(<span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.692869</td>
      <td>3.532001</td>
      <td>0.581395</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.983810</td>
      <td>1.380556</td>
      <td>0.313953</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.885328</td>
      <td>0.899624</td>
      <td>0.232558</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.792400</td>
      <td>0.785097</td>
      <td>0.255814</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.720126</td>
      <td>0.789632</td>
      <td>0.197674</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.623536</td>
      <td>0.744941</td>
      <td>0.186047</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.556991</td>
      <td>0.737408</td>
      <td>0.209302</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.512330</td>
      <td>0.754599</td>
      <td>0.197674</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.464188</td>
      <td>0.772003</td>
      <td>0.197674</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.431808</td>
      <td>0.771565</td>
      <td>0.197674</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.404420</td>
      <td>0.780129</td>
      <td>0.197674</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="184">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;">from</span> fastdownload <span class="im" style="color: #00769E;">import</span> download_url</span>
<span id="cb18-2">urls <span class="op" style="color: #5E5E5E;">=</span> search_images_ddg(<span class="st" style="color: #20794D;">'trail cam deer'</span>)</span>
<span id="cb18-3">urls[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb18-4">download_url(urls[<span class="dv" style="color: #AD0000;">2</span>], <span class="st" style="color: #20794D;">'deer.jpg'</span>)</span>
<span id="cb18-5"></span>
<span id="cb18-6">im <span class="op" style="color: #5E5E5E;">=</span> Image.<span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'deer.jpg'</span>)</span>
<span id="cb18-7">im.to_thumb(<span class="dv" style="color: #AD0000;">190</span>,<span class="dv" style="color: #AD0000;">190</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="196608" class="" max="195476" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.58% [196608/195476 00:00&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="184">
<p><img src="https://jakegehri.github.io/projects/Trailcam/trailcam_model_files/figure-html/cell-16-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="174">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">urls <span class="op" style="color: #5E5E5E;">=</span> search_images_ddg(<span class="st" style="color: #20794D;">'trail cam elk'</span>)</span>
<span id="cb19-2">urls[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb19-3">download_url(urls[<span class="dv" style="color: #AD0000;">0</span>], <span class="st" style="color: #20794D;">'elk.jpg'</span>)</span>
<span id="cb19-4"></span>
<span id="cb19-5">im <span class="op" style="color: #5E5E5E;">=</span> Image.<span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'elk.jpg'</span>)</span>
<span id="cb19-6">im.to_thumb(<span class="dv" style="color: #AD0000;">190</span>,<span class="dv" style="color: #AD0000;">190</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="40960" class="" max="35192" style="width:300px; height:20px; vertical-align: middle;"></progress>
      116.39% [40960/35192 00:00&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="174">
<p><img src="https://jakegehri.github.io/projects/Trailcam/trailcam_model_files/figure-html/cell-17-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="175">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">urls <span class="op" style="color: #5E5E5E;">=</span> search_images_ddg(<span class="st" style="color: #20794D;">'trail cam moose'</span>)</span>
<span id="cb20-2">urls[<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb20-3">download_url(urls[<span class="dv" style="color: #AD0000;">1</span>], <span class="st" style="color: #20794D;">'moose.jpg'</span>)</span>
<span id="cb20-4"></span>
<span id="cb20-5">im <span class="op" style="color: #5E5E5E;">=</span> Image.<span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'moose.jpg'</span>)</span>
<span id="cb20-6">im.to_thumb(<span class="dv" style="color: #AD0000;">190</span>,<span class="dv" style="color: #AD0000;">190</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="270336" class="" max="268163" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.81% [270336/268163 00:00&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="175">
<p><img src="https://jakegehri.github.io/projects/Trailcam/trailcam_model_files/figure-html/cell-18-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="185">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">im <span class="op" style="color: #5E5E5E;">=</span> PILImage.create(<span class="st" style="color: #20794D;">"deer.jpg"</span>)</span>
<span id="cb21-2">im.thumbnail((<span class="dv" style="color: #AD0000;">192</span>, <span class="dv" style="color: #AD0000;">192</span>))</span>
<span id="cb21-3">im</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="185">
<p><img src="https://jakegehri.github.io/projects/Trailcam/trailcam_model_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="186">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">learn.predict(im)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="186">
<pre><code>('deer', TensorBase(0), TensorBase([0.6719, 0.0927, 0.2354]))</code></pre>
</div>
</div>
<section id="pickel-and-export-model-to-be-uploaded-to-gradio" class="level1">
<h1>Pickel and export model to be uploaded to gradio</h1>
<div class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">learn.export(<span class="st" style="color: #20794D;">'model.pkl'</span>)</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="192">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="im" style="color: #00769E;">from</span> fastai.vision.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb25-2"><span class="im" style="color: #00769E;">import</span> gradio <span class="im" style="color: #00769E;">as</span> gr</span>
<span id="cb25-3"></span>
<span id="cb25-4">learn <span class="op" style="color: #5E5E5E;">=</span> load_learner(<span class="st" style="color: #20794D;">'model.pkl'</span>)</span>
<span id="cb25-5">categories <span class="op" style="color: #5E5E5E;">=</span> learn.dls.vocab</span>
<span id="cb25-6"></span>
<span id="cb25-7"><span class="kw" style="color: #003B4F;">def</span> classify_image(img):</span>
<span id="cb25-8">    img <span class="op" style="color: #5E5E5E;">=</span> PILImage.create(img)</span>
<span id="cb25-9">    pred, idx, probs <span class="op" style="color: #5E5E5E;">=</span> learn.predict(img)</span>
<span id="cb25-10">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">dict</span>(<span class="bu" style="color: null;">zip</span>(categories, <span class="bu" style="color: null;">map</span>(<span class="bu" style="color: null;">float</span>,probs)))</span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="193">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">image <span class="op" style="color: #5E5E5E;">=</span> gr.inputs.Image(shape<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">192</span>,<span class="dv" style="color: #AD0000;">192</span>))</span>
<span id="cb26-2">label <span class="op" style="color: #5E5E5E;">=</span> gr.outputs.Label()</span>
<span id="cb26-3">examples <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'deer.jpg'</span>, <span class="st" style="color: #20794D;">'elk.jpg'</span>, <span class="st" style="color: #20794D;">'moose.jpg'</span>]</span>
<span id="cb26-4"></span>
<span id="cb26-5">intf <span class="op" style="color: #5E5E5E;">=</span> gr.Interface(fn<span class="op" style="color: #5E5E5E;">=</span>classify_image, inputs<span class="op" style="color: #5E5E5E;">=</span>image, outputs<span class="op" style="color: #5E5E5E;">=</span>label, examples<span class="op" style="color: #5E5E5E;">=</span>examples)</span>
<span id="cb26-6">intf.launch(inline<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, share<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:256: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components
  warnings.warn(
/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect
  warnings.warn(value)
/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:196: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components
  warnings.warn(
/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.
  warnings.warn(value)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running on local URL:  http://127.0.0.1:7860
Running on public URL: https://27270.gradio.app

This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="193">
<pre><code>(&lt;gradio.routes.App at 0x7f8110cc3040&gt;,
 'http://127.0.0.1:7860/',
 'https://27270.gradio.app')</code></pre>
</div>
</div>


</section>

 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <category>Computer Vision</category>
  <guid>https://jakegehri.github.io/projects/Trailcam/trailcam_model.html</guid>
  <pubDate>Wed, 12 Oct 2022 04:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/Trailcam/trail_cam_project.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Twitter Bot: NLP Emotion Classifier</title>
  <dc:creator>Jake Gehri</dc:creator>
  <link>https://jakegehri.github.io/projects/Twitter Bot/model.html</link>
  <description><![CDATA[ 



<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span> huggingface<span class="op" style="color: #5E5E5E;">-</span>cli login</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:24:28.436709Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:24:28.436309Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:24:28.442511Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:24:28.440786Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:24:28.436658Z&quot;}" data-outputid="ed2b37e1-eaa3-4c76-b5bc-43f532ee565c" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="op" style="color: #5E5E5E;">!</span> pip install datasets</span>
<span id="cb2-2"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> list_datasets</span>
<span id="cb2-3"><span class="im" style="color: #00769E;">import</span> tensorflow <span class="im" style="color: #00769E;">as</span> tf</span>
<span id="cb2-4"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> pipeline, PushToHubCallback</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.1)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)
Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)
Requirement already satisfied: tqdm&gt;=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)
Requirement already satisfied: pyarrow&gt;=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)
Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)
Requirement already satisfied: responses&lt;0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)
Requirement already satisfied: dill&lt;0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)
Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)
Requirement already satisfied: fsspec[http]&gt;=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)
Requirement already satisfied: huggingface-hub&lt;1.0.0,&gt;=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (1.8.1)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (4.0.2)
Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (2.1.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (6.0.2)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (1.2.0)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (22.1.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (4.1.1)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (0.13.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (1.3.1)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&lt;1.0.0,&gt;=0.1.0-&gt;datasets) (6.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&lt;1.0.0,&gt;=0.1.0-&gt;datasets) (3.8.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;datasets) (3.0.9)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (1.25.11)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (2.10)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (2022.6.15)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (3.0.4)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;datasets) (3.8.1)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;datasets) (2.8.2)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;datasets) (2022.2.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;datasets) (1.15.0)</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:48:28.988670Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:48:28.988086Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:48:29.881986Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:48:29.881171Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:48:28.988660Z&quot;}" data-outputid="027fdd30-036a-4e53-cf12-53d5da51cad6" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">all_datasets <span class="op" style="color: #5E5E5E;">=</span> list_datasets()</span>
<span id="cb4-2"><span class="bu" style="color: null;">print</span>(all_datasets[<span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">5</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus']</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:48:46.716475Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:48:46.716108Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:48:46.720996Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:48:46.720155Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:48:46.716447Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:49:16.109008Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:49:16.108188Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:49:16.302966Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:49:16.301967Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:49:16.108985Z&quot;}" data-outputid="6270b862-8d63-40cc-ed9a-73809ea15f0e" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">emotions <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">'emotion'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.
  warnings.warn(message, FutureWarning)</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"11621806475d4354a5c502b7ce12f3e2","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"51cb32d3fae64ed7a2bf28b00eeb21e5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:datasets.builder:Using custom data configuration default</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"083556871dd04ec596bfa70c49bd81de","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"af929b7494444d0cbdcd4834bb48981f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ec3b9f18c647407d8d6af89a343dab7a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"395bdf189a894a1cb99c76fdb0689c8a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e6f765d5c1cb44debfd8b8b5055dd485","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e61b0eec0534e2690432de91a47e218","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"815006b54ba4425dbf03eef7ccd9dd19","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:49:36.859107Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:49:36.858732Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:49:36.870636Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:49:36.869313Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:49:36.859077Z&quot;}" data-outputid="18be657d-93d6-426c-85e2-e9a6b790b2a6" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">train_ds <span class="op" style="color: #5E5E5E;">=</span> emotions[<span class="st" style="color: #20794D;">'train'</span>]</span>
<span id="cb12-2">train_ds</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>Dataset({
    features: ['text', 'label'],
    num_rows: 16000
})</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:49:47.815928Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:49:47.815455Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:49:47.826266Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:49:47.824870Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:49:47.815884Z&quot;}" data-outputid="733ba1d7-0bf0-4538-a0ab-77664edae0bf" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">train_ds[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>{'text': 'i didnt feel humiliated', 'label': 0}</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:50:54.334234Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:50:54.333543Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:50:54.338348Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:50:54.337454Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:50:54.334204Z&quot;}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:51:50.976680Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:51:50.976303Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:51:50.983586Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:51:50.982214Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:51:50.976652Z&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">emotions.set_format(<span class="bu" style="color: null;">type</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'pandas'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:52:19.377309Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:52:19.376810Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:52:19.405915Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:52:19.404678Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:52:19.377278Z&quot;}" data-outputid="23dacb34-92d8-48fd-f1bd-8457f3ef9a1b" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">df <span class="op" style="color: #5E5E5E;">=</span> emotions[<span class="st" style="color: #20794D;">'train'</span>][:]</span>
<span id="cb18-2">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">


  <div id="df-8635b291-53af-49d1-b4e0-d1bfd7582e8e">
    <div class="colab-df-container">
      <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>i didnt feel humiliated</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>i can go from feeling so hopeless to so damned...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>im grabbing a minute to post i feel greedy wrong</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>i am ever feeling nostalgic about the fireplac...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>i am feeling grouchy</td>
      <td>3</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15995</th>
      <td>i just had a very brief time in the beanbag an...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15996</th>
      <td>i am now turning and i feel pathetic that i am...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15997</th>
      <td>i feel strong and good overall</td>
      <td>1</td>
    </tr>
    <tr>
      <th>15998</th>
      <td>i feel like this was such a rude comment and i...</td>
      <td>3</td>
    </tr>
    <tr>
      <th>15999</th>
      <td>i know a lot but i feel so stupid because i ca...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>16000 rows  2 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-8635b291-53af-49d1-b4e0-d1bfd7582e8e')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-8635b291-53af-49d1-b4e0-d1bfd7582e8e button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-8635b291-53af-49d1-b4e0-d1bfd7582e8e');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:54:59.613346Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:54:59.612028Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:54:59.654611Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:54:59.653815Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:54:59.613245Z&quot;}" data-outputid="39daccba-5217-482d-8c62-3746ee725436" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;">def</span> label_int2str(row):</span>
<span id="cb19-2">    <span class="cf" style="color: #003B4F;">return</span> emotions[<span class="st" style="color: #20794D;">'train'</span>].features[<span class="st" style="color: #20794D;">'label'</span>].int2str(row)</span>
<span id="cb19-3">df[<span class="st" style="color: #20794D;">'label_name'</span>] <span class="op" style="color: #5E5E5E;">=</span> df[<span class="st" style="color: #20794D;">'label'</span>].<span class="bu" style="color: null;">apply</span>(label_int2str)</span>
<span id="cb19-4">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">


  <div id="df-1f3104e4-3409-4449-88a5-e6132656e4d8">
    <div class="colab-df-container">
      <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>label</th>
      <th>label_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>i didnt feel humiliated</td>
      <td>0</td>
      <td>sadness</td>
    </tr>
    <tr>
      <th>1</th>
      <td>i can go from feeling so hopeless to so damned...</td>
      <td>0</td>
      <td>sadness</td>
    </tr>
    <tr>
      <th>2</th>
      <td>im grabbing a minute to post i feel greedy wrong</td>
      <td>3</td>
      <td>anger</td>
    </tr>
    <tr>
      <th>3</th>
      <td>i am ever feeling nostalgic about the fireplac...</td>
      <td>2</td>
      <td>love</td>
    </tr>
    <tr>
      <th>4</th>
      <td>i am feeling grouchy</td>
      <td>3</td>
      <td>anger</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1f3104e4-3409-4449-88a5-e6132656e4d8')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1f3104e4-3409-4449-88a5-e6132656e4d8 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1f3104e4-3409-4449-88a5-e6132656e4d8');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T21:58:10.562395Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T21:58:10.561788Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T21:58:10.791804Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T21:58:10.790022Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T21:58:10.562359Z&quot;}" data-outputid="b136d50c-599c-4bbf-88ab-67d5aeffaf1e" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb20-2"></span>
<span id="cb20-3">df[<span class="st" style="color: #20794D;">'label_name'</span>].value_counts(ascending<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>).plot.barh()</span>
<span id="cb20-4">plt.title(<span class="st" style="color: #20794D;">"Frequency of Classes"</span>)</span>
<span id="cb20-5">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Twitter Bot/model_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T22:07:13.771289Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T22:07:13.770002Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T22:07:13.977101Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T22:07:13.976317Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T22:07:13.771249Z&quot;}" data-outputid="66e0e7db-40fe-423a-84c2-63766b23aad2" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">df[<span class="st" style="color: #20794D;">'words_per_tweet'</span>] <span class="op" style="color: #5E5E5E;">=</span> df[<span class="st" style="color: #20794D;">'text'</span>].<span class="bu" style="color: null;">str</span>.split().<span class="bu" style="color: null;">apply</span>(<span class="bu" style="color: null;">len</span>)</span>
<span id="cb21-2">df.boxplot(<span class="st" style="color: #20794D;">'words_per_tweet'</span>, by<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'label_name'</span>, grid<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, showfliers<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb21-3">plt.suptitle(<span class="st" style="color: #20794D;">""</span>)</span>
<span id="cb21-4">plt.xlabel(<span class="st" style="color: #20794D;">""</span>)</span>
<span id="cb21-5">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Twitter Bot/model_files/figure-html/cell-14-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T22:27:24.291408Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T22:27:24.291003Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T22:27:24.297413Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T22:27:24.296338Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T22:27:24.291379Z&quot;}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">emotions.reset_format()</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:24:37.731597Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:24:37.731091Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:24:38.323916Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:24:38.322822Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:24:37.731558Z&quot;}" data-outputid="fd095a3a-84a7-451d-b9a1-e0ba76cca36e" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="op" style="color: #5E5E5E;">!</span> pip install transformers</span>
<span id="cb24-2"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoTokenizer</span>
<span id="cb24-3"></span>
<span id="cb24-4">model_checkpoint <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'distilbert-base-uncased'</span></span>
<span id="cb24-5">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(model_checkpoint)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting transformers
  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)
     || 4.9 MB 34.2 MB/s 
Collecting tokenizers!=0.11.3,&lt;0.13,&gt;=0.11.1
  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)
     || 6.6 MB 56.8 MB/s 
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.9.0-&gt;transformers) (4.1.1)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=20.0-&gt;transformers) (3.0.9)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers) (3.8.1)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (3.0.4)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (1.25.11)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2022.6.15)
Installing collected packages: tokenizers, transformers
Successfully installed tokenizers-0.12.1 transformers-4.22.2</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ab506feb8d424e178f27772906b52fe0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"623e8f408f754327818a41dfd95b0913","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f465b1de2325434c934e11378e569bc4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a5d21490c7284c399bd57c7fa91d0de9","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:29:47.507065Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:29:47.506046Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:29:47.512957Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:29:47.511540Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:29:47.507012Z&quot;}" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;">def</span> tokenize(batch):</span>
<span id="cb26-2">    <span class="cf" style="color: #003B4F;">return</span> tokenizer(batch[<span class="st" style="color: #20794D;">'text'</span>], padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:29:50.094007Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:29:50.093430Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:29:50.101640Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:29:50.100381Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:29:50.093964Z&quot;}" data-outputid="e6689fc1-db23-4c0d-83fc-3d14a2307a01" data-execution_count="20">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="bu" style="color: null;">print</span>(tokenize(emotions[<span class="st" style="color: #20794D;">'train'</span>][<span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">2</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:29:51.680136Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:29:51.679743Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:29:53.114946Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:29:53.113973Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:29:51.680107Z&quot;}" data-outputid="94570890-d1a5-4867-d601-1c3b1b8efa08" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">emotions_encoded <span class="op" style="color: #5E5E5E;">=</span> emotions.<span class="bu" style="color: null;">map</span>(tokenize, batched <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span>, batch_size <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c6db5cbe620b4438a9db7128839c9a20","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5329700dfc07414ea17abd99cb8e5ba8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1b50573fe2bc426dbb98f620e08ddc4e","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:32:16.854608Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:32:16.854188Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:32:17.692440Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:32:17.691759Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:32:16.854579Z&quot;}" data-outputid="cc29f914-54db-4c8d-afc6-f03306f00c6e" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> TFAutoModelForSequenceClassification</span>
<span id="cb30-2"></span>
<span id="cb30-3">num_labels <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">6</span></span>
<span id="cb30-4"></span>
<span id="cb30-5">tf_model <span class="op" style="color: #5E5E5E;">=</span> TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels<span class="op" style="color: #5E5E5E;">=</span>num_labels)</span>
<span id="cb30-6">tf_model</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"913427b83dc94567bc31ac860e20caa5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>&lt;transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification at 0x7f50d851c510&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:33:16.422947Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:33:16.421917Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:33:16.427084Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:33:16.426174Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:33:16.422947Z&quot;}" data-execution_count="23">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="im" style="color: #00769E;">from</span> sklearn.metrics <span class="im" style="color: #00769E;">import</span> accuracy_score, f1_score</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:39:10.445461Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:39:10.444909Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:39:10.451785Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:39:10.449871Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:39:10.445407Z&quot;}" data-execution_count="24">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">tokenizer_columns <span class="op" style="color: #5E5E5E;">=</span> tokenizer.model_input_names</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:41:37.144204Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:41:37.143762Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:41:37.150401Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:41:37.148636Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:41:37.144175Z&quot;}" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">batch_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">64</span></span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:41:38.153296Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:41:38.152922Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:41:38.533966Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:41:38.532419Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:41:38.153267Z&quot;}" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">tf_train_dataset <span class="op" style="color: #5E5E5E;">=</span> emotions_encoded[<span class="st" style="color: #20794D;">'train'</span>].to_tf_dataset(columns <span class="op" style="color: #5E5E5E;">=</span> tokenizer_columns, </span>
<span id="cb36-2">                                                           label_cols <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'label'</span>], </span>
<span id="cb36-3">                                                           shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, batch_size<span class="op" style="color: #5E5E5E;">=</span>batch_size)</span>
<span id="cb36-4"></span>
<span id="cb36-5">tf_validation_dataset <span class="op" style="color: #5E5E5E;">=</span> emotions_encoded[<span class="st" style="color: #20794D;">'validation'</span>].to_tf_dataset(columns <span class="op" style="color: #5E5E5E;">=</span> tokenizer_columns, </span>
<span id="cb36-6">                                                           label_cols <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'label'</span>], </span>
<span id="cb36-7">                                                           shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, batch_size<span class="op" style="color: #5E5E5E;">=</span>batch_size)</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-10-03T23:44:29.545249Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-10-03T23:44:29.544817Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-10-03T23:55:14.065511Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-10-03T23:55:14.064328Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-10-03T23:44:29.545205Z&quot;}" data-outputid="4f1ff79a-bccc-4a12-f9fa-27f085fc9e50" data-execution_count="54">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">callbacks <span class="op" style="color: #5E5E5E;">=</span> [PushToHubCallback(<span class="st" style="color: #20794D;">"model_output/"</span>,</span>
<span id="cb37-2">                               tokenizer<span class="op" style="color: #5E5E5E;">=</span>tokenizer,</span>
<span id="cb37-3">                               hub_model_id<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"twitter-emotion-classifier-BERT"</span>)]</span>
<span id="cb37-4"></span>
<span id="cb37-5">tf_model.<span class="bu" style="color: null;">compile</span>(optimizer<span class="op" style="color: #5E5E5E;">=</span>tf.keras.optimizers.Adam(learning_rate<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">5e-5</span>), </span>
<span id="cb37-6">                 loss <span class="op" style="color: #5E5E5E;">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>),</span>
<span id="cb37-7">                 metrics <span class="op" style="color: #5E5E5E;">=</span> tf.metrics.SparseCategoricalAccuracy())</span>
<span id="cb37-8"></span>
<span id="cb37-9">tf_model.fit(tf_train_dataset, validation_data <span class="op" style="color: #5E5E5E;">=</span> tf_validation_dataset, epochs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span>, callbacks<span class="op" style="color: #5E5E5E;">=</span>callbacks)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Cloning https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT into local empty directory.
WARNING:huggingface_hub.repository:Cloning https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT into local empty directory.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d5181da19ff14f48a3680c891eced30e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ccc77fa1f4ec424baac7206de330351b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6f4d79545e4841c399ff756da1a0f8e0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1bbd8ec2d8ab40f98bf3b86f7c972a40","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1ed209bfda96462c9cc1e61c154e4c47","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"32168bf392074e7396e3fd218a1db5d1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e98b6ff54b4044879cae6b1a1aad1c96","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c4ef8244c8074f7aa6bbef0662db2a86","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"42e9d2358fd44bb48c9cc2ca4e6bd444","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"68993ca3741e450982c9b5ef441f4f46","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4fda354470f6425a894546694168b882","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4d3e8ee6eb6a49debf876f612ef92fdc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/2
  6/250 [..............................] - ETA: 2:05 - loss: 0.1446 - sparse_categorical_accuracy: 0.9245</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1977s vs `on_train_batch_end` time: 0.3150s). Check your callbacks.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>250/250 [==============================] - 163s 624ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1436 - val_sparse_categorical_accuracy: 0.9345
Epoch 2/2
250/250 [==============================] - 136s 545ms/step - loss: 0.0868 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.1442 - val_sparse_categorical_accuracy: 0.9325</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Several commits (2) will be pushed upstream.
WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.
The progress bars may be unreliable.
WARNING:huggingface_hub.repository:The progress bars may be unreliable.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"650588be783c4be18bd8b5152af09baa","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>remote: Scanning LFS files for validity, may be slow...        
remote: LFS file scan complete.        
To https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT
   a929610..8b9eebc  main -&gt; main

WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        
remote: LFS file scan complete.        
To https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT
   a929610..8b9eebc  main -&gt; main
</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>&lt;keras.callbacks.History at 0x7f4f960761d0&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">tf_model.push_to_hub(<span class="st" style="color: #20794D;">"twitter-emotion-classifier-BERT"</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="989b8068-4162-46f3-d598-714c2d8a1ebf" data-execution_count="68">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">classifier <span class="op" style="color: #5E5E5E;">=</span> pipeline(<span class="st" style="color: #20794D;">"text-classification"</span>, model <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"jakegehri/twitter-emotion-classifier-BERT"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9c4337075bfb43bc96ce5c509d6bcd8d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some layers from the model checkpoint at jakegehri/twitter-emotion-classifier-BERT were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at jakegehri/twitter-emotion-classifier-BERT and are newly initialized: ['dropout_98']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"edfdc8e2df484ee5a028d5d79e0903a0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bad515ae189846d9a205494050593e2a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e1ed561bdc94450be8fb227dce2a67a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d9a111fd30844c6d8447545f0a02d0fa","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-outputid="0f240809-4ff1-4e2b-8910-8cea2f4f8846" data-execution_count="152">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1">test_tweet <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"what is going on"</span></span>
<span id="cb48-2">preds <span class="op" style="color: #5E5E5E;">=</span> classifier(test_tweet, top_k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>)</span>
<span id="cb48-3">labels <span class="op" style="color: #5E5E5E;">=</span> emotions[<span class="st" style="color: #20794D;">'train'</span>].features[<span class="st" style="color: #20794D;">'label'</span>].names</span>
<span id="cb48-4">emotion_int <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(preds[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'label'</span>].replace(<span class="st" style="color: #20794D;">"_"</span>,<span class="st" style="color: #20794D;">" "</span>).split()[<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb48-5">labels[emotion_int]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="152">
<pre><code>'anger'</code></pre>
</div>
</div>
<div class="cell" data-outputid="9c7f28b6-34c6-4b6d-8010-9244e9f27a96" data-execution_count="153">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">preds</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>[{'label': 'LABEL_3', 'score': 0.6134325861930847},
 {'label': 'LABEL_4', 'score': 0.3628736138343811},
 {'label': 'LABEL_1', 'score': 0.01299766730517149},
 {'label': 'LABEL_0', 'score': 0.008490157313644886},
 {'label': 'LABEL_5', 'score': 0.0016536037437617779},
 {'label': 'LABEL_2', 'score': 0.0005523563013412058}]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="154">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">rank <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb52-2"></span>
<span id="cb52-3"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> preds:</span>
<span id="cb52-4">  label <span class="op" style="color: #5E5E5E;">=</span> i[<span class="st" style="color: #20794D;">'label'</span>]</span>
<span id="cb52-5">  rank.append(<span class="bu" style="color: null;">int</span>(i[<span class="st" style="color: #20794D;">'label'</span>].replace(<span class="st" style="color: #20794D;">"_"</span>,<span class="st" style="color: #20794D;">" "</span>).split()[<span class="dv" style="color: #AD0000;">1</span>]))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">re_rank <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb53-2"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> rank:</span>
<span id="cb53-3">  re_rank.append(labels[i])</span></code></pre></div>
</div>
<div class="cell" data-outputid="84500616-d6fc-46a5-e3fb-e90a045a5e27" data-execution_count="156">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">re_rank</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="156">
<pre><code>['anger', 'fear', 'joy', 'sadness', 'surprise', 'love']</code></pre>
</div>
</div>
<div class="cell" data-outputid="02fd8797-454e-45a1-8d6c-792c472e41c5" data-execution_count="157">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">preds_df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(preds)</span>
<span id="cb56-2">plt.bar(re_rank, <span class="dv" style="color: #AD0000;">100</span> <span class="op" style="color: #5E5E5E;">*</span> preds_df[<span class="st" style="color: #20794D;">'score'</span>], color <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'C0'</span>)</span>
<span id="cb56-3">plt.title(<span class="ss" style="color: #20794D;">f'"</span><span class="sc" style="color: #5E5E5E;">{</span>test_tweet<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"'</span>)</span>
<span id="cb56-4">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://jakegehri.github.io/projects/Twitter Bot/model_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>



 ]]></description>
  <category>Python</category>
  <category>Deep Learning</category>
  <category>NLP</category>
  <guid>https://jakegehri.github.io/projects/Twitter Bot/model.html</guid>
  <pubDate>Fri, 07 Oct 2022 04:00:00 GMT</pubDate>
  <media:content url="https://jakegehri.github.io/projects/Twitter Bot/Twitter.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
