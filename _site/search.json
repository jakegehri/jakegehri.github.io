[
  {
    "objectID": "projects/Amazon/amazon.html",
    "href": "projects/Amazon/amazon.html",
    "title": "Multi-label Classification of Amazonian Land Space",
    "section": "",
    "text": "import pandoc\nfrom fastbook import *\nfrom fastai import *\n\n\ncreds = '{\"username\":\"jakegehri\",\"key\":\"3d0213a52bd1816d21037e941bc77569\"}'\n\n\n# Creates a cred path for kaggle datasets to be downloaded in comand line\n\ncred_path = Path('~/.kaggle/kaggle.json').expanduser() \n\nif not cred_path.exists():\n    cred_path.parent.mkdir(exist_ok=True)\n    cred_path.write_text(creds)\n    cred_path.chmod(0o600)\n\n\npath = Path('./planet/planet')\n\n\npath.ls()\n\n(#4) [Path('planet/planet/train_classes.csv'),Path('planet/planet/test-jpg'),Path('planet/planet/sample_submission.csv'),Path('planet/planet/train-jpg')]\n\n\n\ntrain = (path/'train-jpg').ls()\n\n\ntrain\n\n(#40479) [Path('planet/planet/train-jpg/train_19921.jpg'),Path('planet/planet/train-jpg/train_24619.jpg'),Path('planet/planet/train-jpg/train_21510.jpg'),Path('planet/planet/train-jpg/train_31089.jpg'),Path('planet/planet/train-jpg/train_33277.jpg'),Path('planet/planet/train-jpg/train_11172.jpg'),Path('planet/planet/train-jpg/train_14671.jpg'),Path('planet/planet/train-jpg/train_29521.jpg'),Path('planet/planet/train-jpg/train_27535.jpg'),Path('planet/planet/train-jpg/train_13323.jpg')...]\n\n\n\ndata = (path/'train_classes.csv')\n\n\ndf = pd.read_csv(data)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      image_name\n      tags\n    \n  \n  \n    \n      0\n      train_0\n      haze primary\n    \n    \n      1\n      train_1\n      agriculture clear primary water\n    \n    \n      2\n      train_2\n      clear primary\n    \n    \n      3\n      train_3\n      clear primary\n    \n    \n      4\n      train_4\n      agriculture clear habitation primary road\n    \n  \n\n\n\n\n\ndblock = DataBlock()\n\n\ndsets = dblock.datasets(df)\n\n\ndsets[0]\n\n(image_name         train_0\n tags          haze primary\n Name: 0, dtype: object,\n image_name         train_0\n tags          haze primary\n Name: 0, dtype: object)\n\n\n\ndef get_x(r): return path/'train-jpg'/(r['image_name'] + '.jpg')\ndef get_y(r): return r['tags'].split(' ')\n\n\ndblock = DataBlock(get_x=get_x, get_y=get_y)\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n(Path('planet/planet/train-jpg/train_1398.jpg'),\n ['agriculture', 'partly_cloudy', 'primary', 'road'])\n\n\n\ndblock = DataBlock(blocks = (ImageBlock, MultiCategoryBlock), \n                   get_x=get_x, get_y=get_y)\n\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n(PILImage mode=RGB size=256x256,\n TensorMultiCategory([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.]))\n\n\n\ndblock = DataBlock(blocks = (ImageBlock, MultiCategoryBlock), \n                   splitter=RandomSplitter(seed=42),\n                   get_x=get_x, get_y=get_y)\n\ndsets = dblock.datasets(df)\n\n\nlen(dsets.train), len(dsets.valid)\n\n(32384, 8095)\n\n\n\ndblock = DataBlock(blocks = (ImageBlock, MultiCategoryBlock), \n                   splitter=RandomSplitter(seed=42),\n                   get_x=get_x, get_y=get_y,\n                   item_tfms=RandomResizedCrop(128, min_scale=0.35)\n                  \n)\n\ndls = dblock.dataloaders(df)\n\n\ndls.show_batch()\n\n\n\n\n\nExperiment 1\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy_multi)\nlearn.fine_tune(6, freeze_epochs=2)\nlearn.recorder.plot_loss()\n\n/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.242502\n      0.150174\n      0.945827\n      00:25\n    \n    \n      1\n      0.147816\n      0.126972\n      0.951968\n      00:20\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.127971\n      0.109930\n      0.957991\n      00:23\n    \n    \n      1\n      0.119986\n      0.104264\n      0.960476\n      00:23\n    \n    \n      2\n      0.109712\n      0.098336\n      0.962301\n      00:38\n    \n    \n      3\n      0.104570\n      0.097734\n      0.962555\n      00:49\n    \n  \n\n\n\n\n\nExperiment 2\n\nlearn2 = vision_learner(dls, resnet34, metrics=accuracy_multi)\nlearn2.fine_tune(6, freeze_epochs=2)\nlearn2.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.244604\n      0.147677\n      0.947447\n      00:51\n    \n    \n      1\n      0.148016\n      0.123402\n      0.953312\n      00:25\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.123248\n      0.106454\n      0.959452\n      00:59\n    \n    \n      1\n      0.118266\n      0.104211\n      0.960942\n      00:34\n    \n    \n      2\n      0.111732\n      0.098766\n      0.962381\n      00:42\n    \n    \n      3\n      0.105815\n      0.096162\n      0.963245\n      00:34\n    \n    \n      4\n      0.099851\n      0.094583\n      0.964037\n      00:34\n    \n    \n      5\n      0.093574\n      0.095035\n      0.963848\n      00:34\n    \n  \n\n\n\n\n\n\n\n\nExperiment 3\n\nlearn3 = vision_learner(dls, resnet34, metrics=partial(accuracy_multi, thresh=0.2))\nlearn3.fine_tune(6, freeze_epochs=2)\nlearn3.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.240184\n      0.151341\n      0.934862\n      00:38\n    \n    \n      1\n      0.151022\n      0.122403\n      0.939382\n      00:27\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.124375\n      0.106883\n      0.950107\n      00:35\n    \n    \n      1\n      0.118021\n      0.101975\n      0.951757\n      00:34\n    \n    \n      2\n      0.109789\n      0.099863\n      0.952055\n      00:34\n    \n    \n      3\n      0.104578\n      0.096811\n      0.951851\n      00:34\n    \n    \n      4\n      0.095859\n      0.095459\n      0.953784\n      00:34\n    \n    \n      5\n      0.092178\n      0.095330\n      0.954445\n      01:02\n    \n  \n\n\n\n\n\n\n\n\nExperiment 4\n\nlearn4 = vision_learner(dls, resnet34, metrics=partial(accuracy_multi, thresh=0.7))\nlearn4.fine_tune(6, freeze_epochs=2)\nlearn4.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.248779\n      0.148406\n      0.942892\n      00:52\n    \n    \n      1\n      0.147272\n      0.123920\n      0.950325\n      00:37\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.125626\n      0.109230\n      0.955863\n      00:48\n    \n    \n      1\n      0.118446\n      0.103957\n      0.956015\n      00:34\n    \n    \n      2\n      0.112594\n      0.099723\n      0.958754\n      00:37\n    \n    \n      3\n      0.106374\n      0.096328\n      0.958689\n      00:51\n    \n    \n      4\n      0.099089\n      0.094283\n      0.960499\n      00:34\n    \n    \n      5\n      0.095276\n      0.094695\n      0.961879\n      00:39\n    \n  \n\n\n\n\n\n\n\ntest_dl = learn2.dls.test_dl(get_image_files(path/'test-jpg'))\ntest_dl.show_batch()\n\n\n\n\n\npreds, _ = learn2.get_preds(dl=test_dl)\n\n\n\n\n\n\n\n\n\nthresh = 0.5\nlabelled_preds = [' '.join([learn2.dls.vocab[i] for i,p in enumerate(pred) if p > thresh]) for pred in preds]\n\n\nlabelled_preds[:5]\n\n['agriculture clear primary road',\n 'bare_ground clear',\n 'clear primary',\n 'clear primary',\n 'clear primary']\n\n\n\nfnames = []\n\nfor name in os.listdir((path/'test-jpg')):\n    fnames.append(name)\n\n\nfnames[0:5]\n\n['test_36099.jpg',\n 'test_27503.jpg',\n 'test_15453.jpg',\n 'test_20695.jpg',\n 'test_5439.jpg']\n\n\n\nlearn2.predict((path/'test-jpg'/(fnames[0])))\n\n\n\n\n\n\n\n\n((#4) ['agriculture','clear','primary','road'],\n TensorBase([ True, False, False, False, False,  True, False, False, False, False, False, False,  True,  True, False, False, False]),\n TensorBase([9.0538e-01, 3.7246e-04, 4.8710e-02, 5.2741e-04, 2.3139e-04, 9.9834e-01, 1.1549e-05, 2.1592e-04, 2.8083e-01, 2.6772e-01, 1.3102e-03, 5.9414e-04, 9.9820e-01, 7.1026e-01, 3.3888e-03,\n             1.9953e-02, 1.1821e-01]))\n\n\n\nsample = pd.read_csv(path/'sample_submission.csv')\nsample\n\n\n\n\n\n  \n    \n      \n      image_name\n      tags\n    \n  \n  \n    \n      0\n      test_0\n      primary clear agriculture road water\n    \n    \n      1\n      test_1\n      primary clear agriculture road water\n    \n    \n      2\n      test_2\n      primary clear agriculture road water\n    \n    \n      3\n      test_3\n      primary clear agriculture road water\n    \n    \n      4\n      test_4\n      primary clear agriculture road water\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      61186\n      file_9995\n      primary clear agriculture road water\n    \n    \n      61187\n      file_9996\n      primary clear agriculture road water\n    \n    \n      61188\n      file_9997\n      primary clear agriculture road water\n    \n    \n      61189\n      file_9998\n      primary clear agriculture road water\n    \n    \n      61190\n      file_9999\n      primary clear agriculture road water\n    \n  \n\n61191 rows × 2 columns\n\n\n\n\ndf = pd.DataFrame({'image_name':fnames, 'tags':labelled_preds}, columns=['image_name', 'tags'])\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      image_name\n      tags\n    \n  \n  \n    \n      0\n      test_36099.jpg\n      agriculture clear primary road\n    \n    \n      1\n      test_27503.jpg\n      bare_ground clear\n    \n    \n      2\n      test_15453.jpg\n      clear primary\n    \n    \n      3\n      test_20695.jpg\n      clear primary\n    \n    \n      4\n      test_5439.jpg\n      clear primary\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      40664\n      test_12322.jpg\n      clear primary water\n    \n    \n      40665\n      test_10596.jpg\n      agriculture partly_cloudy primary road\n    \n    \n      40666\n      test_567.jpg\n      partly_cloudy primary\n    \n    \n      40667\n      test_23428.jpg\n      agriculture clear primary\n    \n    \n      40668\n      test_10099.jpg\n      clear primary\n    \n  \n\n40669 rows × 2 columns"
  },
  {
    "objectID": "projects/Trailcam/trailcam_model.html",
    "href": "projects/Trailcam/trailcam_model.html",
    "title": "Trail Cam Deer, Elk and Moose Classifier",
    "section": "",
    "text": "import fastbook\nfrom fastbook import *\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport timm\nfrom duckduckgo_search import ddg_images\nfrom time import sleep\nimport os\nimport gradio\n\n\ndef search_images(term, max_images=100):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\nsearches = 'moose', 'deer', 'elk'\npath = Path('trail_cam')\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls = search_images(f'{o} trail cam photo'))\n    sleep(10)\n    download_images(dest, urls = search_images(f'{o} trail cam photo day'))\n    sleep(10)\n    download_images(dest, urls = search_images(f'{o} trail cam photo night'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'moose trail cam photo'\nSearching for 'moose trail cam photo day'\nSearching for 'moose trail cam photo night'\nSearching for 'deer trail cam photo'\nSearching for 'deer trail cam photo day'\nSearching for 'deer trail cam photo night'\nSearching for 'elk trail cam photo'\nSearching for 'elk trail cam photo day'\nSearching for 'elk trail cam photo night'\n\n\n\nfns = get_image_files(path)\nlen(fns)\n\n877\n\n\n\nfailed = verify_images(fns)\nfailed.map(Path.unlink)\nfns = get_image_files(path)\nlen(failed), len(fns)\n\n(12, 865)\n\n\n\nos.getcwd()\nfor i, filename in enumerate(os.listdir(path/'deer')):\n   os.rename(\"trail_cam/deer/\" + filename, \"trail_cam/deer/deer_\" + str(i) + \".jpg\")\nfor i, filename in enumerate(os.listdir(path/'moose')):\n   os.rename(\"trail_cam/moose/\" + filename, \"trail_cam/moose/moose_\" + str(i) + \".jpg\")\nfor i, filename in enumerate(os.listdir(path/'elk')):\n   os.rename(\"trail_cam/elk/\" + filename, \"trail_cam/elk/elk_\" + str(i) + \".jpg\")\n\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=RegexLabeller(pat = r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224))\n\n\ndls.valid.show_batch(max_n=4)\n\n\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(5)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      2.002779\n      1.369467\n      0.586207\n      00:07\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.426437\n      1.002604\n      0.425287\n      00:03\n    \n    \n      1\n      1.082575\n      0.859882\n      0.413793\n      00:03\n    \n    \n      2\n      0.907559\n      0.716293\n      0.333333\n      00:03\n    \n    \n      3\n      0.748531\n      0.688598\n      0.252874\n      00:03\n    \n    \n      4\n      0.647351\n      0.693779\n      0.264368\n      00:03\n    \n  \n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(6, nrows=1)\n\n\n\n\n\n\n\n\n\n\n\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\n    \nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n    \ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=RegexLabeller(pat = r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224))\n\n\nlearn = vision_learner(dls, 'convnext_tiny_in22k', metrics=error_rate).to_fp16()\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.692869\n      3.532001\n      0.581395\n      00:03\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.983810\n      1.380556\n      0.313953\n      00:03\n    \n    \n      1\n      0.885328\n      0.899624\n      0.232558\n      00:03\n    \n    \n      2\n      0.792400\n      0.785097\n      0.255814\n      00:03\n    \n    \n      3\n      0.720126\n      0.789632\n      0.197674\n      00:03\n    \n    \n      4\n      0.623536\n      0.744941\n      0.186047\n      00:03\n    \n    \n      5\n      0.556991\n      0.737408\n      0.209302\n      00:03\n    \n    \n      6\n      0.512330\n      0.754599\n      0.197674\n      00:03\n    \n    \n      7\n      0.464188\n      0.772003\n      0.197674\n      00:03\n    \n    \n      8\n      0.431808\n      0.771565\n      0.197674\n      00:03\n    \n    \n      9\n      0.404420\n      0.780129\n      0.197674\n      00:03\n    \n  \n\n\n\n\nfrom fastdownload import download_url\nurls = search_images_ddg('trail cam deer')\nurls[0]\ndownload_url(urls[2], 'deer.jpg')\n\nim = Image.open('deer.jpg')\nim.to_thumb(190,190)\n\n\n\n\n\n\n    \n      \n      100.58% [196608/195476 00:00<00:00]\n    \n    \n\n\n\n\n\n\nurls = search_images_ddg('trail cam elk')\nurls[0]\ndownload_url(urls[0], 'elk.jpg')\n\nim = Image.open('elk.jpg')\nim.to_thumb(190,190)\n\n\n\n\n\n\n    \n      \n      116.39% [40960/35192 00:00<00:00]\n    \n    \n\n\n\n\n\n\nurls = search_images_ddg('trail cam moose')\nurls[1]\ndownload_url(urls[1], 'moose.jpg')\n\nim = Image.open('moose.jpg')\nim.to_thumb(190,190)\n\n\n\n\n\n\n    \n      \n      100.81% [270336/268163 00:00<00:00]\n    \n    \n\n\n\n\n\n\nim = PILImage.create(\"deer.jpg\")\nim.thumbnail((192, 192))\nim\n\n\n\n\n\nlearn.predict(im)\n\n\n\n\n\n\n\n\n('deer', TensorBase(0), TensorBase([0.6719, 0.0927, 0.2354]))\n\n\n\nPickel and export model to be uploaded to gradio\n\nlearn.export('model.pkl')\n\n\nfrom fastai.vision.all import *\nimport gradio as gr\n\nlearn = load_learner('model.pkl')\ncategories = learn.dls.vocab\n\ndef classify_image(img):\n    img = PILImage.create(img)\n    pred, idx, probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n\nimage = gr.inputs.Image(shape=(192,192))\nlabel = gr.outputs.Label()\nexamples = ['deer.jpg', 'elk.jpg', 'moose.jpg']\n\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False, share=True)\n\n/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:256: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  warnings.warn(\n/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n  warnings.warn(value)\n/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:196: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  warnings.warn(\n/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n  warnings.warn(value)\n\n\nRunning on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://27270.gradio.app\n\nThis share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n\n\n(<gradio.routes.App at 0x7f8110cc3040>,\n 'http://127.0.0.1:7860/',\n 'https://27270.gradio.app')"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Multi-label Classification of Amazonian Land Space\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\nComputer Vision\n\n\n\n\nProject\n\n\n\n\n\n\nOct 19, 2022\n\n\nJake Gehri\n\n\n\n\n\n\n  \n\n\n\n\nTrail Cam Deer, Elk and Moose Classifier\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\nComputer Vision\n\n\n\n\nProject\n\n\n\n\n\n\nOct 12, 2022\n\n\nJake Gehri\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  }
]