[
  {
    "objectID": "projects/Amazon/amazon.html",
    "href": "projects/Amazon/amazon.html",
    "title": "Multi-label Classification of Amazonian Land Space",
    "section": "",
    "text": "import pandoc\nfrom fastbook import *\nfrom fastai import *\n\n\ncreds = '{\"username\":\"jakegehri\",\"key\":\"3d0213a52bd1816d21037e941bc77569\"}'\n\n\n# Creates a cred path for kaggle datasets to be downloaded in comand line\n\ncred_path = Path('~/.kaggle/kaggle.json').expanduser() \n\nif not cred_path.exists():\n    cred_path.parent.mkdir(exist_ok=True)\n    cred_path.write_text(creds)\n    cred_path.chmod(0o600)\n\n\npath = Path('./planet/planet')\n\n\npath.ls()\n\n(#4) [Path('planet/planet/train_classes.csv'),Path('planet/planet/test-jpg'),Path('planet/planet/sample_submission.csv'),Path('planet/planet/train-jpg')]\n\n\n\ntrain = (path/'train-jpg').ls()\n\n\ntrain\n\n(#40479) [Path('planet/planet/train-jpg/train_19921.jpg'),Path('planet/planet/train-jpg/train_24619.jpg'),Path('planet/planet/train-jpg/train_21510.jpg'),Path('planet/planet/train-jpg/train_31089.jpg'),Path('planet/planet/train-jpg/train_33277.jpg'),Path('planet/planet/train-jpg/train_11172.jpg'),Path('planet/planet/train-jpg/train_14671.jpg'),Path('planet/planet/train-jpg/train_29521.jpg'),Path('planet/planet/train-jpg/train_27535.jpg'),Path('planet/planet/train-jpg/train_13323.jpg')...]\n\n\n\ndata = (path/'train_classes.csv')\n\n\ndf = pd.read_csv(data)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      image_name\n      tags\n    \n  \n  \n    \n      0\n      train_0\n      haze primary\n    \n    \n      1\n      train_1\n      agriculture clear primary water\n    \n    \n      2\n      train_2\n      clear primary\n    \n    \n      3\n      train_3\n      clear primary\n    \n    \n      4\n      train_4\n      agriculture clear habitation primary road\n    \n  \n\n\n\n\n\ndblock = DataBlock()\n\n\ndsets = dblock.datasets(df)\n\n\ndsets[0]\n\n(image_name         train_0\n tags          haze primary\n Name: 0, dtype: object,\n image_name         train_0\n tags          haze primary\n Name: 0, dtype: object)\n\n\n\ndef get_x(r): return path/'train-jpg'/(r['image_name'] + '.jpg')\ndef get_y(r): return r['tags'].split(' ')\n\n\ndblock = DataBlock(get_x=get_x, get_y=get_y)\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n(Path('planet/planet/train-jpg/train_1398.jpg'),\n ['agriculture', 'partly_cloudy', 'primary', 'road'])\n\n\n\ndblock = DataBlock(blocks = (ImageBlock, MultiCategoryBlock), \n                   get_x=get_x, get_y=get_y)\n\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n(PILImage mode=RGB size=256x256,\n TensorMultiCategory([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.]))\n\n\n\ndblock = DataBlock(blocks = (ImageBlock, MultiCategoryBlock), \n                   splitter=RandomSplitter(seed=42),\n                   get_x=get_x, get_y=get_y)\n\ndsets = dblock.datasets(df)\n\n\nlen(dsets.train), len(dsets.valid)\n\n(32384, 8095)\n\n\n\ndblock = DataBlock(blocks = (ImageBlock, MultiCategoryBlock), \n                   splitter=RandomSplitter(seed=42),\n                   get_x=get_x, get_y=get_y,\n                   item_tfms=RandomResizedCrop(128, min_scale=0.35)\n                  \n)\n\ndls = dblock.dataloaders(df)\n\n\ndls.show_batch()\n\n\n\n\n\nExperiment 1\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy_multi)\nlearn.fine_tune(6, freeze_epochs=2)\nlearn.recorder.plot_loss()\n\n/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.242502\n      0.150174\n      0.945827\n      00:25\n    \n    \n      1\n      0.147816\n      0.126972\n      0.951968\n      00:20\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.127971\n      0.109930\n      0.957991\n      00:23\n    \n    \n      1\n      0.119986\n      0.104264\n      0.960476\n      00:23\n    \n    \n      2\n      0.109712\n      0.098336\n      0.962301\n      00:38\n    \n    \n      3\n      0.104570\n      0.097734\n      0.962555\n      00:49\n    \n  \n\n\n\n\n\nExperiment 2\n\nlearn2 = vision_learner(dls, resnet34, metrics=accuracy_multi)\nlearn2.fine_tune(6, freeze_epochs=2)\nlearn2.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.244604\n      0.147677\n      0.947447\n      00:51\n    \n    \n      1\n      0.148016\n      0.123402\n      0.953312\n      00:25\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.123248\n      0.106454\n      0.959452\n      00:59\n    \n    \n      1\n      0.118266\n      0.104211\n      0.960942\n      00:34\n    \n    \n      2\n      0.111732\n      0.098766\n      0.962381\n      00:42\n    \n    \n      3\n      0.105815\n      0.096162\n      0.963245\n      00:34\n    \n    \n      4\n      0.099851\n      0.094583\n      0.964037\n      00:34\n    \n    \n      5\n      0.093574\n      0.095035\n      0.963848\n      00:34\n    \n  \n\n\n\n\n\n\n\n\nExperiment 3\n\nlearn3 = vision_learner(dls, resnet34, metrics=partial(accuracy_multi, thresh=0.2))\nlearn3.fine_tune(6, freeze_epochs=2)\nlearn3.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.240184\n      0.151341\n      0.934862\n      00:38\n    \n    \n      1\n      0.151022\n      0.122403\n      0.939382\n      00:27\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.124375\n      0.106883\n      0.950107\n      00:35\n    \n    \n      1\n      0.118021\n      0.101975\n      0.951757\n      00:34\n    \n    \n      2\n      0.109789\n      0.099863\n      0.952055\n      00:34\n    \n    \n      3\n      0.104578\n      0.096811\n      0.951851\n      00:34\n    \n    \n      4\n      0.095859\n      0.095459\n      0.953784\n      00:34\n    \n    \n      5\n      0.092178\n      0.095330\n      0.954445\n      01:02\n    \n  \n\n\n\n\n\n\n\n\nExperiment 4\n\nlearn4 = vision_learner(dls, resnet34, metrics=partial(accuracy_multi, thresh=0.7))\nlearn4.fine_tune(6, freeze_epochs=2)\nlearn4.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.248779\n      0.148406\n      0.942892\n      00:52\n    \n    \n      1\n      0.147272\n      0.123920\n      0.950325\n      00:37\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.125626\n      0.109230\n      0.955863\n      00:48\n    \n    \n      1\n      0.118446\n      0.103957\n      0.956015\n      00:34\n    \n    \n      2\n      0.112594\n      0.099723\n      0.958754\n      00:37\n    \n    \n      3\n      0.106374\n      0.096328\n      0.958689\n      00:51\n    \n    \n      4\n      0.099089\n      0.094283\n      0.960499\n      00:34\n    \n    \n      5\n      0.095276\n      0.094695\n      0.961879\n      00:39\n    \n  \n\n\n\n\n\n\n\ntest_dl = learn2.dls.test_dl(get_image_files(path/'test-jpg'))\ntest_dl.show_batch()\n\n\n\n\n\npreds, _ = learn2.get_preds(dl=test_dl)\n\n\n\n\n\n\n\n\n\nthresh = 0.5\nlabelled_preds = [' '.join([learn2.dls.vocab[i] for i,p in enumerate(pred) if p > thresh]) for pred in preds]\n\n\nlabelled_preds[:5]\n\n['agriculture clear primary road',\n 'bare_ground clear',\n 'clear primary',\n 'clear primary',\n 'clear primary']\n\n\n\nfnames = []\n\nfor name in os.listdir((path/'test-jpg')):\n    fnames.append(name)\n\n\nfnames[0:5]\n\n['test_36099.jpg',\n 'test_27503.jpg',\n 'test_15453.jpg',\n 'test_20695.jpg',\n 'test_5439.jpg']\n\n\n\nlearn2.predict((path/'test-jpg'/(fnames[0])))\n\n\n\n\n\n\n\n\n((#4) ['agriculture','clear','primary','road'],\n TensorBase([ True, False, False, False, False,  True, False, False, False, False, False, False,  True,  True, False, False, False]),\n TensorBase([9.0538e-01, 3.7246e-04, 4.8710e-02, 5.2741e-04, 2.3139e-04, 9.9834e-01, 1.1549e-05, 2.1592e-04, 2.8083e-01, 2.6772e-01, 1.3102e-03, 5.9414e-04, 9.9820e-01, 7.1026e-01, 3.3888e-03,\n             1.9953e-02, 1.1821e-01]))\n\n\n\nsample = pd.read_csv(path/'sample_submission.csv')\nsample\n\n\n\n\n\n  \n    \n      \n      image_name\n      tags\n    \n  \n  \n    \n      0\n      test_0\n      primary clear agriculture road water\n    \n    \n      1\n      test_1\n      primary clear agriculture road water\n    \n    \n      2\n      test_2\n      primary clear agriculture road water\n    \n    \n      3\n      test_3\n      primary clear agriculture road water\n    \n    \n      4\n      test_4\n      primary clear agriculture road water\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      61186\n      file_9995\n      primary clear agriculture road water\n    \n    \n      61187\n      file_9996\n      primary clear agriculture road water\n    \n    \n      61188\n      file_9997\n      primary clear agriculture road water\n    \n    \n      61189\n      file_9998\n      primary clear agriculture road water\n    \n    \n      61190\n      file_9999\n      primary clear agriculture road water\n    \n  \n\n61191 rows × 2 columns\n\n\n\n\ndf = pd.DataFrame({'image_name':fnames, 'tags':labelled_preds}, columns=['image_name', 'tags'])\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      image_name\n      tags\n    \n  \n  \n    \n      0\n      test_36099.jpg\n      agriculture clear primary road\n    \n    \n      1\n      test_27503.jpg\n      bare_ground clear\n    \n    \n      2\n      test_15453.jpg\n      clear primary\n    \n    \n      3\n      test_20695.jpg\n      clear primary\n    \n    \n      4\n      test_5439.jpg\n      clear primary\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      40664\n      test_12322.jpg\n      clear primary water\n    \n    \n      40665\n      test_10596.jpg\n      agriculture partly_cloudy primary road\n    \n    \n      40666\n      test_567.jpg\n      partly_cloudy primary\n    \n    \n      40667\n      test_23428.jpg\n      agriculture clear primary\n    \n    \n      40668\n      test_10099.jpg\n      clear primary\n    \n  \n\n40669 rows × 2 columns"
  },
  {
    "objectID": "projects/Trailcam/trailcam_model.html",
    "href": "projects/Trailcam/trailcam_model.html",
    "title": "Trail Cam Deer, Elk and Moose Classifier",
    "section": "",
    "text": "import fastbook\nfrom fastbook import *\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport timm\nfrom duckduckgo_search import ddg_images\nfrom time import sleep\nimport os\nimport gradio\n\n\ndef search_images(term, max_images=100):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\nsearches = 'moose', 'deer', 'elk'\npath = Path('trail_cam')\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls = search_images(f'{o} trail cam photo'))\n    sleep(10)\n    download_images(dest, urls = search_images(f'{o} trail cam photo day'))\n    sleep(10)\n    download_images(dest, urls = search_images(f'{o} trail cam photo night'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'moose trail cam photo'\nSearching for 'moose trail cam photo day'\nSearching for 'moose trail cam photo night'\nSearching for 'deer trail cam photo'\nSearching for 'deer trail cam photo day'\nSearching for 'deer trail cam photo night'\nSearching for 'elk trail cam photo'\nSearching for 'elk trail cam photo day'\nSearching for 'elk trail cam photo night'\n\n\n\nfns = get_image_files(path)\nlen(fns)\n\n877\n\n\n\nfailed = verify_images(fns)\nfailed.map(Path.unlink)\nfns = get_image_files(path)\nlen(failed), len(fns)\n\n(12, 865)\n\n\n\nos.getcwd()\nfor i, filename in enumerate(os.listdir(path/'deer')):\n   os.rename(\"trail_cam/deer/\" + filename, \"trail_cam/deer/deer_\" + str(i) + \".jpg\")\nfor i, filename in enumerate(os.listdir(path/'moose')):\n   os.rename(\"trail_cam/moose/\" + filename, \"trail_cam/moose/moose_\" + str(i) + \".jpg\")\nfor i, filename in enumerate(os.listdir(path/'elk')):\n   os.rename(\"trail_cam/elk/\" + filename, \"trail_cam/elk/elk_\" + str(i) + \".jpg\")\n\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=RegexLabeller(pat = r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224))\n\n\ndls.valid.show_batch(max_n=4)\n\n\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(5)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      2.002779\n      1.369467\n      0.586207\n      00:07\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.426437\n      1.002604\n      0.425287\n      00:03\n    \n    \n      1\n      1.082575\n      0.859882\n      0.413793\n      00:03\n    \n    \n      2\n      0.907559\n      0.716293\n      0.333333\n      00:03\n    \n    \n      3\n      0.748531\n      0.688598\n      0.252874\n      00:03\n    \n    \n      4\n      0.647351\n      0.693779\n      0.264368\n      00:03\n    \n  \n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(6, nrows=1)\n\n\n\n\n\n\n\n\n\n\n\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\n    \nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n    \ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=RegexLabeller(pat = r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224))\n\n\nlearn = vision_learner(dls, 'convnext_tiny_in22k', metrics=error_rate).to_fp16()\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.692869\n      3.532001\n      0.581395\n      00:03\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.983810\n      1.380556\n      0.313953\n      00:03\n    \n    \n      1\n      0.885328\n      0.899624\n      0.232558\n      00:03\n    \n    \n      2\n      0.792400\n      0.785097\n      0.255814\n      00:03\n    \n    \n      3\n      0.720126\n      0.789632\n      0.197674\n      00:03\n    \n    \n      4\n      0.623536\n      0.744941\n      0.186047\n      00:03\n    \n    \n      5\n      0.556991\n      0.737408\n      0.209302\n      00:03\n    \n    \n      6\n      0.512330\n      0.754599\n      0.197674\n      00:03\n    \n    \n      7\n      0.464188\n      0.772003\n      0.197674\n      00:03\n    \n    \n      8\n      0.431808\n      0.771565\n      0.197674\n      00:03\n    \n    \n      9\n      0.404420\n      0.780129\n      0.197674\n      00:03\n    \n  \n\n\n\n\nfrom fastdownload import download_url\nurls = search_images_ddg('trail cam deer')\nurls[0]\ndownload_url(urls[2], 'deer.jpg')\n\nim = Image.open('deer.jpg')\nim.to_thumb(190,190)\n\n\n\n\n\n\n    \n      \n      100.58% [196608/195476 00:00<00:00]\n    \n    \n\n\n\n\n\n\nurls = search_images_ddg('trail cam elk')\nurls[0]\ndownload_url(urls[0], 'elk.jpg')\n\nim = Image.open('elk.jpg')\nim.to_thumb(190,190)\n\n\n\n\n\n\n    \n      \n      116.39% [40960/35192 00:00<00:00]\n    \n    \n\n\n\n\n\n\nurls = search_images_ddg('trail cam moose')\nurls[1]\ndownload_url(urls[1], 'moose.jpg')\n\nim = Image.open('moose.jpg')\nim.to_thumb(190,190)\n\n\n\n\n\n\n    \n      \n      100.81% [270336/268163 00:00<00:00]\n    \n    \n\n\n\n\n\n\nim = PILImage.create(\"deer.jpg\")\nim.thumbnail((192, 192))\nim\n\n\n\n\n\nlearn.predict(im)\n\n\n\n\n\n\n\n\n('deer', TensorBase(0), TensorBase([0.6719, 0.0927, 0.2354]))\n\n\n\nPickel and export model to be uploaded to gradio\n\nlearn.export('model.pkl')\n\n\nfrom fastai.vision.all import *\nimport gradio as gr\n\nlearn = load_learner('model.pkl')\ncategories = learn.dls.vocab\n\ndef classify_image(img):\n    img = PILImage.create(img)\n    pred, idx, probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n\nimage = gr.inputs.Image(shape=(192,192))\nlabel = gr.outputs.Label()\nexamples = ['deer.jpg', 'elk.jpg', 'moose.jpg']\n\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False, share=True)\n\n/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:256: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  warnings.warn(\n/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n  warnings.warn(value)\n/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:196: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  warnings.warn(\n/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n  warnings.warn(value)\n\n\nRunning on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://27270.gradio.app\n\nThis share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n\n\n(<gradio.routes.App at 0x7f8110cc3040>,\n 'http://127.0.0.1:7860/',\n 'https://27270.gradio.app')"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "DNN From Scratch: The nuts and bolts\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\nPyTorch\n\n\n\n\nAchieving 83% accuracy on the Titanic Kaggle competition dataset with a DNN built from scratch.\n\n\n\n\n\n\nNov 1, 2022\n\n\nJake Gehri\n\n\n\n\n\n\n  \n\n\n\n\nMulti-label Classification of Amazonian Land Space\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\nComputer Vision\n\n\n\n\nProject\n\n\n\n\n\n\nOct 19, 2022\n\n\nJake Gehri\n\n\n\n\n\n\n  \n\n\n\n\nTrail Cam Deer, Elk and Moose Classifier\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\nComputer Vision\n\n\n\n\nProject\n\n\n\n\n\n\nOct 12, 2022\n\n\nJake Gehri\n\n\n\n\n\n\n  \n\n\n\n\nTwitter Bot: NLP Emotion Classifier\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\nNLP\n\n\n\n\nBuilding and deploying an emotion classifying twitter bot that responds to users who prompt the bot with a # of interest. Bot uses a pretrained BERT encoder fine tuned on a tweet emotion dataset.\n\n\n\n\n\n\nOct 7, 2022\n\n\nJake Gehri\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jake Gehri",
    "section": "",
    "text": "Yale University New Haven, CT\nB.A. in Economics | August 2018 - May 2022  B.A. in Global Affairs | August 2018 - May 2022\n\n\n\nRothschild & Co., New York, NY | July 2022 – Present Analyst, Investment Banking Division, Financial Sponsors Group \nPharos Global Health Advisors, Boston, MA | August 2021 – January 2022  Financial Consultant"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/DNN From Scratch/no_hands.html",
    "href": "projects/DNN From Scratch/no_hands.html",
    "title": "DNN From Scratch: The nuts and bolts",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport numpy as np\nimport torch.nn.functional as F\nfrom fastai import *\nfrom fastbook import *\n\n\ndata = pd.read_csv('train.csv')\n\n\ndata.head()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      NaN\n      S\n    \n    \n      1\n      2\n      1\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      female\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      C\n    \n    \n      2\n      3\n      1\n      3\n      Heikkinen, Miss. Laina\n      female\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      NaN\n      S\n    \n    \n      3\n      4\n      1\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      female\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      S\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      NaN\n      S\n    \n  \n\n\n\n\n\ndata.isna().sum()\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\nmodes = data.mode().iloc[0]\nmodes\n\nPassengerId                      1\nSurvived                       0.0\nPclass                         3.0\nName           Abbing, Mr. Anthony\nSex                           male\nAge                           24.0\nSibSp                          0.0\nParch                          0.0\nTicket                        1601\nFare                          8.05\nCabin                      B96 B98\nEmbarked                         S\nName: 0, dtype: object\n\n\n\ndata.fillna(modes, inplace=True)\n\n\ndata.isna().sum()\n\nPassengerId    0\nSurvived       0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nCabin          0\nEmbarked       0\ndtype: int64\n\n\n\ndata.describe(include=(np.number))\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      28.566970\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      13.199572\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      22.000000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      24.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      35.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\ndata.describe(include=object)\n\n\n\n\n\n  \n    \n      \n      Name\n      Sex\n      Ticket\n      Cabin\n      Embarked\n    \n  \n  \n    \n      count\n      891\n      891\n      891\n      891\n      891\n    \n    \n      unique\n      891\n      2\n      681\n      147\n      3\n    \n    \n      top\n      Braund, Mr. Owen Harris\n      male\n      347082\n      B96 B98\n      S\n    \n    \n      freq\n      1\n      577\n      7\n      691\n      646\n    \n  \n\n\n\n\n\ndata['Fare'].hist()\n\n<AxesSubplot:>\n\n\n\n\n\n\ndata['LogFare'] = np.log(data['Fare'] + 1)\n\n\ndata.head()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n      LogFare\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      B96 B98\n      S\n      2.110213\n    \n    \n      1\n      2\n      1\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      female\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      C\n      4.280593\n    \n    \n      2\n      3\n      1\n      3\n      Heikkinen, Miss. Laina\n      female\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      B96 B98\n      S\n      2.188856\n    \n    \n      3\n      4\n      1\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      female\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      S\n      3.990834\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      B96 B98\n      S\n      2.202765\n    \n  \n\n\n\n\n\ndata = pd.get_dummies(data, columns = ['Pclass', 'Sex', 'Embarked'])\n\n\ndata.head()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Name\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      LogFare\n      Pclass_1\n      Pclass_2\n      Pclass_3\n      Sex_female\n      Sex_male\n      Embarked_C\n      Embarked_Q\n      Embarked_S\n    \n  \n  \n    \n      0\n      1\n      0\n      Braund, Mr. Owen Harris\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      B96 B98\n      2.110213\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      1\n    \n    \n      1\n      2\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      4.280593\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n    \n    \n      2\n      3\n      1\n      Heikkinen, Miss. Laina\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      B96 B98\n      2.188856\n      0\n      0\n      1\n      1\n      0\n      0\n      0\n      1\n    \n    \n      3\n      4\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      3.990834\n      1\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n    \n    \n      4\n      5\n      0\n      Allen, Mr. William Henry\n      35.0\n      0\n      0\n      373450\n      8.0500\n      B96 B98\n      2.202765\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      1\n    \n  \n\n\n\n\n\ndep_var = ['Survived']\n\n\nindep_vars = ['Age', 'SibSp', 'Parch', 'LogFare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n\n\nlen(indep_vars)\n\n12\n\n\n\ny = torch.tensor(data[dep_var].values, dtype=torch.float)\n\n\nX = torch.tensor(data[indep_vars].values, dtype=torch.float)\n\n\nvals, indicies = X.max(dim=0)\n\n\nX = X / vals\n\n\ntrn_split, val_split = RandomSplitter(seed=42)(X)\n\n\nlen(trn_split), len(val_split)\n\n(713, 178)\n\n\n\nX_train, y_train = X[trn_split], y[trn_split]\nX_val, y_val = X[val_split], y[val_split]\n\n\nnips = X_train.shape[1]\n\n\ntorch.manual_seed(42)\n\ndef get_coeffs(nips = nips, l1_size = 20, n_classes = 1):\n    layer1 = (torch.rand(nips, l1_size)-0.5) / nips\n    layer2 = (torch.rand(l1_size, n_classes)-0.5)\n    const = torch.rand(1)[0]\n    return layer1.requires_grad_(), layer2.requires_grad_(), const.requires_grad_()\n\n\ndef forward_pass(coeffs, X_train):\n    l1, l2, const = coeffs\n    acts = F.relu(X_train@l1)\n    acts = acts@l2 + const\n    return torch.sigmoid(acts)\n\n\ndef calc_loss(acts, y_train): return torch.abs(acts - y_train).mean()\n\n\ndef backprop(coeffs, lr):\n    for layer in coeffs:\n        layer.sub_(layer.grad * lr)\n        layer.grad.zero_()\n\n\ndef one_epoch(coeffs, lr):\n    acts = forward_pass(coeffs, X_train)\n    loss = calc_loss(acts, y_train)\n    loss.backward()\n    with torch.no_grad(): backprop(coeffs, lr)\n    print(f\"{loss:.3f}\", end = \"; \")\n\n\ndef acc(coeffs): return (y_val.bool()==(forward_pass(coeffs, X_val)>0.5)).float().mean()\n\n\ndef train_model(epochs=50, lr=2):\n    torch.manual_seed(42)\n    coeffs = get_coeffs()\n    for i in range(epochs): one_epoch(coeffs, lr)\n    return coeffs, acc(coeffs)\n    \n\n\n_, acc = train_model()\n\n0.548; 0.529; 0.503; 0.466; 0.408; 0.357; 0.330; 0.313; 0.298; 0.286; 0.277; 0.269; 0.261; 0.255; 0.249; 0.244; 0.239; 0.235; 0.231; 0.229; 0.226; 0.224; 0.222; 0.220; 0.219; 0.217; 0.216; 0.215; 0.214; 0.213; 0.212; 0.211; 0.211; 0.210; 0.209; 0.209; 0.208; 0.207; 0.207; 0.206; 0.206; 0.205; 0.205; 0.204; 0.204; 0.204; 0.203; 0.203; 0.203; 0.202; \n\n\n\nacc\n\ntensor(0.8258)"
  },
  {
    "objectID": "projects/Twitter Bot/model.html",
    "href": "projects/Twitter Bot/model.html",
    "title": "Twitter Bot: NLP Emotion Classifier",
    "section": "",
    "text": "! huggingface-cli login\n\n\n! pip install datasets\nfrom datasets import list_datasets\nimport tensorflow as tf\nfrom transformers import pipeline, PushToHubCallback\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nRequirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\nRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\nRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\nRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\n\n\nall_datasets = list_datasets()\nprint(all_datasets[0:5])\n\n['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus']\n\n\n\nfrom datasets import load_dataset\n\n\nemotions = load_dataset('emotion')\n\n/usr/local/lib/python3.7/dist-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n  warnings.warn(message, FutureWarning)\n\n\n\n\n\n\n\n\nWARNING:datasets.builder:Using custom data configuration default\n\n\nDownloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n\n\n\n\n\n\ntrain_ds = emotions['train']\ntrain_ds\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 16000\n})\n\n\n\ntrain_ds[0]\n\n{'text': 'i didnt feel humiliated', 'label': 0}\n\n\n\nimport pandas as pd\n\n\nemotions.set_format(type = 'pandas')\n\n\ndf = emotions['train'][:]\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      text\n      label\n    \n  \n  \n    \n      0\n      i didnt feel humiliated\n      0\n    \n    \n      1\n      i can go from feeling so hopeless to so damned...\n      0\n    \n    \n      2\n      im grabbing a minute to post i feel greedy wrong\n      3\n    \n    \n      3\n      i am ever feeling nostalgic about the fireplac...\n      2\n    \n    \n      4\n      i am feeling grouchy\n      3\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      15995\n      i just had a very brief time in the beanbag an...\n      0\n    \n    \n      15996\n      i am now turning and i feel pathetic that i am...\n      0\n    \n    \n      15997\n      i feel strong and good overall\n      1\n    \n    \n      15998\n      i feel like this was such a rude comment and i...\n      3\n    \n    \n      15999\n      i know a lot but i feel so stupid because i ca...\n      0\n    \n  \n\n16000 rows × 2 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndef label_int2str(row):\n    return emotions['train'].features['label'].int2str(row)\ndf['label_name'] = df['label'].apply(label_int2str)\ndf.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      text\n      label\n      label_name\n    \n  \n  \n    \n      0\n      i didnt feel humiliated\n      0\n      sadness\n    \n    \n      1\n      i can go from feeling so hopeless to so damned...\n      0\n      sadness\n    \n    \n      2\n      im grabbing a minute to post i feel greedy wrong\n      3\n      anger\n    \n    \n      3\n      i am ever feeling nostalgic about the fireplac...\n      2\n      love\n    \n    \n      4\n      i am feeling grouchy\n      3\n      anger\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nimport matplotlib.pyplot as plt\n\ndf['label_name'].value_counts(ascending=True).plot.barh()\nplt.title(\"Frequency of Classes\")\nplt.show()\n\n\n\n\n\ndf['words_per_tweet'] = df['text'].str.split().apply(len)\ndf.boxplot('words_per_tweet', by='label_name', grid=False, showfliers=False)\nplt.suptitle(\"\")\nplt.xlabel(\"\")\nplt.show()\n\n/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n\n\n\n\n\n\nemotions.reset_format()\n\n\n! pip install transformers\nfrom transformers import AutoTokenizer\n\nmodel_checkpoint = 'distilbert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting transformers\n  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n     |████████████████████████████████| 4.9 MB 34.2 MB/s \nCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n     |████████████████████████████████| 6.6 MB 56.8 MB/s \nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\nRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\nInstalling collected packages: tokenizers, transformers\nSuccessfully installed tokenizers-0.12.1 transformers-4.22.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef tokenize(batch):\n    return tokenizer(batch['text'], padding=True, truncation=True)\n\n\nprint(tokenize(emotions['train'][0:2]))\n\n{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n\n\n\nemotions_encoded = emotions.map(tokenize, batched = True, batch_size = None)\n\n\n\n\n\n\n\n\n\n\n\nfrom transformers import TFAutoModelForSequenceClassification\n\nnum_labels = 6\n\ntf_model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\ntf_model\n\n\n\n\nSome layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification at 0x7f50d851c510>\n\n\n\nfrom sklearn.metrics import accuracy_score, f1_score\n\n\ntokenizer_columns = tokenizer.model_input_names\n\n\nbatch_size = 64\n\n\ntf_train_dataset = emotions_encoded['train'].to_tf_dataset(columns = tokenizer_columns, \n                                                           label_cols = ['label'], \n                                                           shuffle=True, batch_size=batch_size)\n\ntf_validation_dataset = emotions_encoded['validation'].to_tf_dataset(columns = tokenizer_columns, \n                                                           label_cols = ['label'], \n                                                           shuffle=True, batch_size=batch_size)\n\n\ncallbacks = [PushToHubCallback(\"model_output/\",\n                               tokenizer=tokenizer,\n                               hub_model_id=\"twitter-emotion-classifier-BERT\")]\n\ntf_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), \n                 loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                 metrics = tf.metrics.SparseCategoricalAccuracy())\n\ntf_model.fit(tf_train_dataset, validation_data = tf_validation_dataset, epochs = 2, callbacks=callbacks)\n\nCloning https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT into local empty directory.\nWARNING:huggingface_hub.repository:Cloning https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT into local empty directory.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 1/2\n  6/250 [..............................] - ETA: 2:05 - loss: 0.1446 - sparse_categorical_accuracy: 0.9245\n\n\nWARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1977s vs `on_train_batch_end` time: 0.3150s). Check your callbacks.\n\n\n250/250 [==============================] - 163s 624ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1436 - val_sparse_categorical_accuracy: 0.9345\nEpoch 2/2\n250/250 [==============================] - 136s 545ms/step - loss: 0.0868 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.1442 - val_sparse_categorical_accuracy: 0.9325\n\n\nSeveral commits (2) will be pushed upstream.\nWARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\nThe progress bars may be unreliable.\nWARNING:huggingface_hub.repository:The progress bars may be unreliable.\n\n\n\n\n\nremote: Scanning LFS files for validity, may be slow...        \nremote: LFS file scan complete.        \nTo https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT\n   a929610..8b9eebc  main -> main\n\nWARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \nremote: LFS file scan complete.        \nTo https://huggingface.co/jakegehri/twitter-emotion-classifier-BERT\n   a929610..8b9eebc  main -> main\n\n\n\n<keras.callbacks.History at 0x7f4f960761d0>\n\n\n\ntf_model.push_to_hub(\"twitter-emotion-classifier-BERT\")\n\n\nclassifier = pipeline(\"text-classification\", model = \"jakegehri/twitter-emotion-classifier-BERT\")\n\n\n\n\nSome layers from the model checkpoint at jakegehri/twitter-emotion-classifier-BERT were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at jakegehri/twitter-emotion-classifier-BERT and are newly initialized: ['dropout_98']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest_tweet = \"what is going on\"\npreds = classifier(test_tweet, top_k=6)\nlabels = emotions['train'].features['label'].names\nemotion_int = int(preds[0]['label'].replace(\"_\",\" \").split()[1])\nlabels[emotion_int]\n\n'anger'\n\n\n\npreds\n\n[{'label': 'LABEL_3', 'score': 0.6134325861930847},\n {'label': 'LABEL_4', 'score': 0.3628736138343811},\n {'label': 'LABEL_1', 'score': 0.01299766730517149},\n {'label': 'LABEL_0', 'score': 0.008490157313644886},\n {'label': 'LABEL_5', 'score': 0.0016536037437617779},\n {'label': 'LABEL_2', 'score': 0.0005523563013412058}]\n\n\n\nrank = []\n\nfor i in preds:\n  label = i['label']\n  rank.append(int(i['label'].replace(\"_\",\" \").split()[1]))\n\n\nre_rank = []\nfor i in rank:\n  re_rank.append(labels[i])\n\n\nre_rank\n\n['anger', 'fear', 'joy', 'sadness', 'surprise', 'love']\n\n\n\npreds_df = pd.DataFrame(preds)\nplt.bar(re_rank, 100 * preds_df['score'], color = 'C0')\nplt.title(f'\"{test_tweet}\"')\nplt.show()"
  }
]